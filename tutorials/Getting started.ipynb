{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Getting started: initializing, adding data, and saving your SwanGraph "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, if you haven't already, make sure to [install Swan](https://github.com/fairliereese/swan_vis/wiki#installation).\n",
    "After installing, you'll be able to run Swan from Python.\n",
    "\n",
    "Then, download the data and the reference transcriptome annotation from [here](https://hpc.oit.uci.edu/~freese/swan_files/). The bash commands to do so are given below.\n",
    "\n",
    "Skip to section: \n",
    "* [Example data download](#data_download)\n",
    "* [Starting and initializing your SwanGraph](#init)\n",
    "* [Add transcript models (GTF) and abundance info](#gtf_ab)\n",
    "* [Saving and loading your SwanGraph](#save_load)\n",
    "* [Adding transcript models (GTF) and abundance info separately](#gtf_ab_sep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"data_download\"></a> Download example data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mkdir data\n",
    "# mkdir figures\n",
    "# cd data/\n",
    "\n",
    "# # gencode v29 human annotation\n",
    "# wget https://hpc.oit.uci.edu/~freese/swan_files/gencode.v29.annotation.gtf\n",
    "\n",
    "# # hepg2 data\n",
    "# wget https://hpc.oit.uci.edu/~freese/swan_files/hepg2_1_talon.gtf\n",
    "# wget https://hpc.oit.uci.edu/~freese/swan_files/hepg2_2_talon.gtf\n",
    "\n",
    "# # hffc6 data\n",
    "# wget https://hpc.oit.uci.edu/~freese/swan_files/hffc6_1_talon.gtf\n",
    "# wget https://hpc.oit.uci.edu/~freese/swan_files/hffc6_2_talon.gtf\n",
    "# wget https://hpc.oit.uci.edu/~freese/swan_files/hffc6_3_talon.gtf\n",
    "\n",
    "# # abundance file\n",
    "# wget https://hpc.oit.uci.edu/~freese/swan_files/all_talon_abundance_filtered.tsv\n",
    "\n",
    "# # example saved SwanGraph\n",
    "# wget https://hpc.oit.uci.edu/~freese/swan_files/swan.p\n",
    "\n",
    "\n",
    "# # talon database\n",
    "# wget https://hpc.oit.uci.edu/~freese/swan_files/talon.db\n",
    "# cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_gtf = 'data/gencode.v29.annotation.gtf'\n",
    "hep_1_gtf = 'data/hepg2_1_talon.gtf'\n",
    "hep_2_gtf = 'data/hepg2_2_talon.gtf'\n",
    "hff_1_gtf = 'data/hffc6_1_talon.gtf'\n",
    "hff_2_gtf = 'data/hffc6_2_talon.gtf'\n",
    "hff_3_gtf = 'data/hffc6_3_talon.gtf'\n",
    "ab_file = 'data/all_talon_abundance_filtered.tsv'\n",
    "\n",
    "talon_db = 'data/talon.db'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"init\"></a>Starting up Swan and initializing your SwanGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import swan_vis as swan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize an empty SwanGraph and add the transcriptome annotation to the SwanGraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding dataset annotation to the SwanGraph.\n"
     ]
    }
   ],
   "source": [
    "sg = swan.SwanGraph()\n",
    "sg.add_annotation(annot_gtf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"gtf_ab\"></a>Adding transcript models (GTF) and abundance information at the same time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add each dataset to the SwanGraph, along with the corresponding abundance information from the abundance matrix. The `count_cols` variable refers to the column name in the abundance file that corresponds to the counts for the input dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding dataset HepG2_1 to the SwanGraph.\n",
      "Adding dataset HepG2_2 to the SwanGraph.\n",
      "Adding dataset HFFc6_1 to the SwanGraph.\n",
      "Adding dataset HFFc6_2 to the SwanGraph.\n",
      "Adding dataset HFFc6_3 to the SwanGraph.\n"
     ]
    }
   ],
   "source": [
    "sg.add_dataset('HepG2_1', hep_1_gtf,\n",
    "\tcounts_file=ab_file,\n",
    "\tcount_cols='hepg2_1')\n",
    "sg.add_dataset('HepG2_2', hep_2_gtf,\n",
    "\tcounts_file=ab_file,\n",
    "\tcount_cols='hepg2_2')\n",
    "sg.add_dataset('HFFc6_1', hff_1_gtf,\n",
    "\tcounts_file=ab_file,\n",
    "\tcount_cols='hffc6_1')\n",
    "sg.add_dataset('HFFc6_2', hff_2_gtf,\n",
    "\tcounts_file=ab_file,\n",
    "\tcount_cols='hffc6_2')\n",
    "sg.add_dataset('HFFc6_3', hff_3_gtf,\n",
    "\tcounts_file=ab_file,\n",
    "\tcount_cols='hffc6_3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <a name=\"save_load\"></a>Saving and loading your SwanGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following this, you can save your SwanGraph so you can easily work with it again without re-adding all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving graph as swan.p\n"
     ]
    }
   ],
   "source": [
    "sg.save_graph('swan')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And you can reload the graph again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph from swan.p loaded\n"
     ]
    }
   ],
   "source": [
    "sg = swan.SwanGraph('swan.p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <a name=\"gtf_ab_sep\"></a>Adding transcript models (GTF) and abundance information separately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Swan can also run without abundance information, although many of Swan's analysis functions depend on abundance information. To load just the transcript models, simply just leave out the `counts_file` and `count_cols` arguments to the `add_dataset()` function as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding dataset annotation to the SwanGraph.\n",
      "Adding dataset HepG2_1 to the SwanGraph.\n",
      "Adding dataset HepG2_2 to the SwanGraph.\n",
      "Adding dataset HFFc6_1 to the SwanGraph.\n",
      "Adding dataset HFFc6_2 to the SwanGraph.\n",
      "Adding dataset HFFc6_3 to the SwanGraph.\n"
     ]
    }
   ],
   "source": [
    "sg = swan.SwanGraph()\n",
    "sg.add_annotation(annot_gtf)\n",
    "sg.add_dataset('HepG2_1', hep_1_gtf)\n",
    "sg.add_dataset('HepG2_2', hep_2_gtf)\n",
    "sg.add_dataset('HFFc6_1', hff_1_gtf)\n",
    "sg.add_dataset('HFFc6_2', hff_2_gtf)\n",
    "sg.add_dataset('HFFc6_3', hff_3_gtf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have just added transcript models to the graph via `add_dataset()` and wish to add abundance information, this can be done using the `add_abundance()` function as seen below. Here, the string passed to `count_cols` is the column in the abundance file that corresponds to the dataset, and the argument passed to `dataset_name` is the name of the dataset that has already been added to the SwanGraph in the previous code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg.add_abundance(ab_file, count_cols='hepg2_1', dataset_name='HepG2_1')\n",
    "sg.add_abundance(ab_file, count_cols='hepg2_2', dataset_name='HepG2_2')\n",
    "sg.add_abundance(ab_file, count_cols='hffc6_1', dataset_name='HFFc6_1')\n",
    "sg.add_abundance(ab_file, count_cols='hffc6_2', dataset_name='HFFc6_2')\n",
    "sg.add_abundance(ab_file, count_cols='hffc6_3', dataset_name='HFFc6_3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"db_ab\"></a> Adding transcript models (TALON db) and abundance information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Swan is also directly compatible with TALON databases and can pull transcript models directly from them. There are future plans to expand on this compatibility, making the transition between TALON and Swan even smoother."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding dataset HepG2_1 to the SwanGraph.\n",
      "Getting transcripts for data/talon.db from hepg2_1\n"
     ]
    },
    {
     "ename": "OperationalError",
     "evalue": "near \"WHERE\": syntax error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-942dfe9ced7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m sg.add_dataset('HepG2_1', talon_db, 'hepg2_1',\n\u001b[1;32m      2\u001b[0m         \u001b[0mcounts_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mab_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \tcount_cols='hepg2_1')\n\u001b[0m\u001b[1;32m      4\u001b[0m sg.add_dataset('HepG2_2', talon_db, 'hepg2_2',\n\u001b[1;32m      5\u001b[0m         \u001b[0mcounts_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mab_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/swan_vis/swangraph.py\u001b[0m in \u001b[0;36madd_dataset\u001b[0;34m(self, col, fname, dname, counts_file, count_cols, tid_col, include_isms)\u001b[0m\n\u001b[1;32m    103\u001b[0m                                 \u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_dfs_gtf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                         \u001b[0;32melif\u001b[0m \u001b[0mftype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'db'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m                                 \u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_dfs_db\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_dfs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/swan_vis/swangraph.py\u001b[0m in \u001b[0;36mcreate_dfs_db\u001b[0;34m(self, db, dname)\u001b[0m\n\u001b[1;32m    617\u001b[0m                         \u001b[0mq\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"\"\" WHERE dataset='{}'\"\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m                 \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetchall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m                 \u001b[0mtalon_tids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtalon_gids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperationalError\u001b[0m: near \"WHERE\": syntax error"
     ]
    }
   ],
   "source": [
    "sg.add_dataset('HepG2_1', talon_db, 'hepg2_1',\n",
    "\tcounts_file=ab_file,\n",
    "\tcount_cols='hepg2_1')\n",
    "sg.add_dataset('HepG2_2', talon_db, 'hepg2_2',\n",
    "\tcounts_file=ab_file,\n",
    "\tcount_cols='hepg2_2')\n",
    "sg.add_dataset('HFFc6_1', talon_db, 'hffc6_1',\n",
    "\tcounts_file=ab_file,\n",
    "\tcount_cols='hffc6_1')\n",
    "sg.add_dataset('HFFc6_2', talon_db, 'hffc6_2',\n",
    "\tcounts_file=ab_file,\n",
    "\tcount_cols='hffc6_2')\n",
    "sg.add_dataset('HFFc6_3', talon_db, 'hffc6_3',\n",
    "\tcounts_file=ab_file,\n",
    "\tcount_cols='hffc6_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
