{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Getting started: initializing, adding data, and saving your SwanGraph "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, if you haven't already, make sure to [install Swan](https://github.com/fairliereese/swan_vis/wiki#installation).\n",
    "After installing, you'll be able to run Swan from Python.\n",
    "\n",
    "Then, download the data and the reference transcriptome annotation from [here](https://hpc.oit.uci.edu/~freese/swan_files/). The bash commands to do so are given below.\n",
    "\n",
    "Swan offers two main ways for loading transcriptomes. You can either load models from [a properly-formatted GTF](getting_started.md#adding-transcript-models-gtf-and-abundance-information-at-the-same-time), or from a [TALON db](getting_started.md#adding-transcript-models-talon-db-and-abundance-information).\n",
    "Please see the [input file format documentation](../faqs/file_formats.md) for specifics on how these files should be formatted.\n",
    "\n",
    "We've provided three examples on how to add data to your SwanGraph in the following tutorial. You only need to run one!\n",
    "1. [Using a GTF and abundance table together](#gtf_ab)\n",
    "2. [Using a GTF and abundance table separately](#gtf_ab_sep)\n",
    "3. [Using a TALON database and abundance table together](#db_ab)\n",
    "\n",
    "Other sections: \n",
    "* [Example data download](#data_download)\n",
    "* [Starting and initializing your SwanGraph](#init)\n",
    "* [Saving and loading your SwanGraph](#save_load)\n",
    "\n",
    "This page can also be read from top to bottom, just know that you may be running things more than once!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"data_download\"></a> Download example data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # run this block in your bash terminal\n",
    "# mkdir data\n",
    "# mkdir figures\n",
    "# cd data/\n",
    "\n",
    "# # download files\n",
    "# wget http://crick.bio.uci.edu/freese/swan_files.tgz\n",
    "    \n",
    "# # expand files \n",
    "# tar xzf swan_files.tgz\n",
    "# mv swan_files/* .\n",
    "# rm -r swan_files/\n",
    "\n",
    "# # download reference annotation\n",
    "# wget ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_29/gencode.v29.annotation.gtf.gz\n",
    "# gunzip gencode.v29.annotation.gtf.gz\n",
    "\n",
    "# cd ../"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"init\"></a>Starting up Swan and initializing your SwanGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of the code should be done in the Python shell, or run from a `.py` file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import swan_vis as swan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_gtf = 'data/gencode.v29.annotation.gtf'\n",
    "hep_1_gtf = 'data/hepg2_1_talon.gtf'\n",
    "hep_2_gtf = 'data/hepg2_2_talon.gtf'\n",
    "hff_1_gtf = 'data/hffc6_1_talon.gtf'\n",
    "hff_2_gtf = 'data/hffc6_2_talon.gtf'\n",
    "hff_3_gtf = 'data/hffc6_3_talon.gtf'\n",
    "ab_file = 'data/all_talon_abundance_filtered.tsv'\n",
    "talon_db = 'data/talon.db'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize an empty SwanGraph and add the transcriptome annotation to the SwanGraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding dataset annotation to the SwanGraph.\n"
     ]
    }
   ],
   "source": [
    "# initialize a new SwanGraph\n",
    "sg = swan.SwanGraph() \n",
    "\n",
    "# add an annotation transcriptome \n",
    "sg.add_annotation(annot_gtf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"gtf_ab\"></a>Adding transcript models (GTF) and abundance information at the same time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add each dataset to the SwanGraph, along with the corresponding abundance information from the abundance matrix. The `count_cols` variable refers to the column name in the abundance file that corresponds to the counts for the input dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding dataset HepG2_1 to the SwanGraph.\n",
      "Adding dataset HepG2_2 to the SwanGraph.\n",
      "Adding dataset HFFc6_1 to the SwanGraph.\n",
      "Adding dataset HFFc6_2 to the SwanGraph.\n",
      "Adding dataset HFFc6_3 to the SwanGraph.\n"
     ]
    }
   ],
   "source": [
    "# add a dataset's transcriptome and abundance information to\n",
    "# the SwanGraph\n",
    "sg.add_dataset('HepG2_1', hep_1_gtf,\n",
    "\tcounts_file=ab_file,\n",
    "\tcount_cols='hepg2_1')\n",
    "sg.add_dataset('HepG2_2', hep_2_gtf,\n",
    "\tcounts_file=ab_file,\n",
    "\tcount_cols='hepg2_2')\n",
    "sg.add_dataset('HFFc6_1', hff_1_gtf,\n",
    "\tcounts_file=ab_file,\n",
    "\tcount_cols='hffc6_1')\n",
    "sg.add_dataset('HFFc6_2', hff_2_gtf,\n",
    "\tcounts_file=ab_file,\n",
    "\tcount_cols='hffc6_2')\n",
    "sg.add_dataset('HFFc6_3', hff_3_gtf,\n",
    "\tcounts_file=ab_file,\n",
    "\tcount_cols='hffc6_3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <a name=\"save_load\"></a>Saving and loading your SwanGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following this, you can save your SwanGraph so you can easily work with it again without re-adding all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving graph as swan.p\n"
     ]
    }
   ],
   "source": [
    "# save the SwanGraph as a Python pickle file\n",
    "sg.save_graph('swan')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And you can reload the graph again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph from swan.p loaded\n"
     ]
    }
   ],
   "source": [
    "# load up a saved SwanGraph from a pickle file\n",
    "sg = swan.SwanGraph('swan.p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <a name=\"gtf_ab_sep\"></a>Adding transcript models (GTF) and abundance information separately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Swan can also run without abundance information, although many of Swan's analysis functions depend on abundance information. To load just the transcript models, simply just leave out the `counts_file` and `count_cols` arguments to the `add_dataset()` function as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for this new example, create a new empty SwanGraph\n",
    "sg = swan.SwanGraph()\n",
    "# and add the annotation transcriptome to it\n",
    "sg.add_annotation(annot_gtf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding dataset annotation to the SwanGraph.\n",
      "Adding dataset HepG2_1 to the SwanGraph.\n",
      "Adding dataset HepG2_2 to the SwanGraph.\n",
      "Adding dataset HFFc6_1 to the SwanGraph.\n",
      "Adding dataset HFFc6_2 to the SwanGraph.\n",
      "Adding dataset HFFc6_3 to the SwanGraph.\n"
     ]
    }
   ],
   "source": [
    "# add transcriptome datasets from GTF files without\n",
    "# corresponding abundance information\n",
    "sg.add_dataset('HepG2_1', hep_1_gtf)\n",
    "sg.add_dataset('HepG2_2', hep_2_gtf)\n",
    "sg.add_dataset('HFFc6_1', hff_1_gtf)\n",
    "sg.add_dataset('HFFc6_2', hff_2_gtf)\n",
    "sg.add_dataset('HFFc6_3', hff_3_gtf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have just added transcript models to the graph via `add_dataset()` and wish to add abundance information, this can be done using the `add_abundance()` function as seen below. Here, the string passed to `count_cols` is the column in the abundance file that corresponds to the dataset, and the argument passed to `dataset_name` is the name of the dataset that has already been added to the SwanGraph in the previous code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add abundance information corresponding to each of the datasets\n",
    "# we've already added to the SwanGraph\n",
    "# dataset_name must be a dataset that is already present in the SwanGraph\n",
    "sg.add_abundance(ab_file, count_cols='hepg2_1', dataset_name='HepG2_1')\n",
    "sg.add_abundance(ab_file, count_cols='hepg2_2', dataset_name='HepG2_2')\n",
    "sg.add_abundance(ab_file, count_cols='hffc6_1', dataset_name='HFFc6_1')\n",
    "sg.add_abundance(ab_file, count_cols='hffc6_2', dataset_name='HFFc6_2')\n",
    "sg.add_abundance(ab_file, count_cols='hffc6_3', dataset_name='HFFc6_3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"db_ab\"></a> Adding transcript models (TALON db) and abundance information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Swan is also directly compatible with TALON databases and can pull transcript models directly from them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for this new example, create a new empty SwanGraph\n",
    "sg = swan.SwanGraph()\n",
    "# and add the annotation transcriptome to it\n",
    "sg.add_annotation(annot_gtf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hepg2_whitelist='data/hepg2_whitelist.csv'\n",
    "hffc6_whitelist='data/hffc6_whitelist.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding dataset HepG2_1 to the SwanGraph.\n",
      "Adding dataset HepG2_2 to the SwanGraph.\n",
      "Adding dataset Hffc6_1 to the SwanGraph.\n",
      "Adding dataset Hffc6_2 to the SwanGraph.\n",
      "Adding dataset Hffc6_3 to the SwanGraph.\n"
     ]
    }
   ],
   "source": [
    "# add datasets directly from a TALON database and abundance\n",
    "# information from an abundance table\n",
    "# whitelist option is output from the talon_filter_transcripts\n",
    "# step, which filters novel isoforms based on their reproducibility\n",
    "# and for those that exhibit internal priming\n",
    "sg.add_dataset('HepG2_1', talon_db,\n",
    "    dataset_name='hepg2_1',\n",
    "    whitelist=hepg2_whitelist,\n",
    "\tcounts_file=ab_file,\n",
    "\tcount_cols='hepg2_1')\n",
    "sg.add_dataset('HepG2_2', talon_db,\n",
    "    dataset_name='hepg2_2',\n",
    "    whitelist=hepg2_whitelist,\n",
    "\tcounts_file=ab_file,\n",
    "\tcount_cols='hepg2_2')\n",
    "\n",
    "sg.add_dataset('Hffc6_1', talon_db,\n",
    "    dataset_name='hffc6_1',\n",
    "    whitelist=hffc6_whitelist,\n",
    "\tcounts_file=ab_file,\n",
    "\tcount_cols='hffc6_1')\n",
    "sg.add_dataset('Hffc6_2', talon_db,\n",
    "    dataset_name='hffc6_2',\n",
    "    whitelist=hffc6_whitelist,\n",
    "\tcounts_file=ab_file,\n",
    "\tcount_cols='hffc6_2')\n",
    "sg.add_dataset('Hffc6_3', talon_db,\n",
    "    dataset_name='hffc6_3',\n",
    "    whitelist=hffc6_whitelist,\n",
    "\tcounts_file=ab_file,\n",
    "\tcount_cols='hffc6_3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
