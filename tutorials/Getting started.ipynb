{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Getting started: initializing, adding data, and saving your SwanGraph "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, if you haven't already, make sure to [install Swan](https://github.com/fairliereese/swan_vis/wiki#installation).\n",
    "After installing, you'll be able to run Swan from Python.\n",
    "\n",
    "Then, download the data and the reference transcriptome annotation from [here](https://hpc.oit.uci.edu/~freese/swan_files/). The bash commands to do so are given below.\n",
    "\n",
    "Swan offers two main ways for loading transcriptomes. You can either load models from [a properly-formatted GTF](getting_started.md#adding-transcript-models-gtf-and-abundance-information-at-the-same-time), or from a [TALON db](getting_started.md#adding-transcript-models-talon-db-and-abundance-information).\n",
    "Please see the [input file format documentation](../faqs/file_formats.md) for specifics on how these files should be formatted.\n",
    "\n",
    "We've provided four examples on different ways you can add data to your SwanGraph in the following tutorial. You only need to run one!\n",
    "1. [Using a GTF and abundance table together](#gtf_ab)\n",
    "2. [Using a GTF and abundance table separately](#gtf_ab_sep)\n",
    "3. [Using a TALON database and abundance table together](#db_ab)\n",
    "4. [Batch adding datasets](#batch)\n",
    "\n",
    "Other sections: \n",
    "* [Example data download](#data_download)\n",
    "* [Starting and initializing your SwanGraph](#init)\n",
    "* [Saving and loading your SwanGraph](#save_load)\n",
    "\n",
    "This page can also be read from top to bottom, just know that you may be running things more than once!\n",
    "\n",
    "Running this tutorial (with only one of the dataset addition options) on my laptop took around 7 minutes and 5 GB of RAM. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"data_download\"></a> Download example data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # run this block in your bash terminal\n",
    "# mkdir data\n",
    "# mkdir figures\n",
    "# cd data/\n",
    "\n",
    "# # download files\n",
    "# wget http://crick.bio.uci.edu/freese/swan_files.tgz\n",
    "    \n",
    "# # expand files \n",
    "# tar xzf swan_files.tgz\n",
    "# mv swan_files/* .\n",
    "# rm -r swan_files/\n",
    "\n",
    "# # download reference annotation\n",
    "# wget ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_29/gencode.v29.annotation.gtf.gz\n",
    "# gunzip gencode.v29.annotation.gtf.gz\n",
    "\n",
    "# cd ../"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, if you wish to use a smaller example dataset (just chr20), run the following. The rest of the commands in the tutorial will work with the smaller data too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # run this block in your bash terminal\n",
    "# mkdir data\n",
    "# mkdir figures\n",
    "# cd data/\n",
    "\n",
    "# # download files\n",
    "# wget http://crick.bio.uci.edu/freese/swan_files_mini.tgz\n",
    "    \n",
    "# # expand files \n",
    "# tar xzf swan_files_mini.tgz\n",
    "# mv swan_files_mini/* .\n",
    "# rm -r swan_files_mini/\n",
    "\n",
    "# cd ../"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"init\"></a>Starting up Swan and initializing your SwanGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of the code should be done in the Python shell, or run from a `.py` file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fairliereese/miniconda3/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version.  The public classes are available in the top-level namespace.\n",
      "  from pandas.core.index import RangeIndex\n"
     ]
    }
   ],
   "source": [
    "import swan_vis as swan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_gtf = 'data/gencode.v29.annotation.gtf'\n",
    "hep_1_gtf = 'data/hepg2_1_talon.gtf'\n",
    "hep_2_gtf = 'data/hepg2_2_talon.gtf'\n",
    "hff_1_gtf = 'data/hffc6_1_talon.gtf'\n",
    "hff_2_gtf = 'data/hffc6_2_talon.gtf'\n",
    "hff_3_gtf = 'data/hffc6_3_talon.gtf'\n",
    "ab_file = 'data/all_talon_abundance_filtered.tsv'\n",
    "talon_db = 'data/talon.db'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize an empty SwanGraph and add the transcriptome annotation to the SwanGraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding dataset annotation to the SwanGraph.\n"
     ]
    }
   ],
   "source": [
    "# initialize a new SwanGraph\n",
    "sg = swan.SwanGraph() \n",
    "\n",
    "# add an annotation transcriptome \n",
    "sg.add_annotation(annot_gtf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"gtf_ab\"></a>Adding transcript models (GTF) and abundance information at the same time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add each dataset to the SwanGraph, along with the corresponding abundance information from the abundance matrix. The `count_cols` variable refers to the column name in the abundance file that corresponds to the counts for the input dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding dataset HepG2_1 to the SwanGraph.\n",
      "Adding dataset HepG2_2 to the SwanGraph.\n",
      "Adding dataset HFFc6_1 to the SwanGraph.\n",
      "Adding dataset HFFc6_2 to the SwanGraph.\n",
      "Adding dataset HFFc6_3 to the SwanGraph.\n"
     ]
    }
   ],
   "source": [
    "# add a dataset's transcriptome and abundance information to\n",
    "# the SwanGraph\n",
    "sg.add_dataset('HepG2_1', hep_1_gtf,\n",
    "\tcounts_file=ab_file,\n",
    "\tcount_cols='hepg2_1')\n",
    "sg.add_dataset('HepG2_2', hep_2_gtf,\n",
    "\tcounts_file=ab_file,\n",
    "\tcount_cols='hepg2_2')\n",
    "sg.add_dataset('HFFc6_1', hff_1_gtf,\n",
    "\tcounts_file=ab_file,\n",
    "\tcount_cols='hffc6_1')\n",
    "sg.add_dataset('HFFc6_2', hff_2_gtf,\n",
    "\tcounts_file=ab_file,\n",
    "\tcount_cols='hffc6_2')\n",
    "sg.add_dataset('HFFc6_3', hff_3_gtf,\n",
    "\tcounts_file=ab_file,\n",
    "\tcount_cols='hffc6_3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <a name=\"save_load\"></a>Saving and loading your SwanGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following this, you can save your SwanGraph so you can easily work with it again without re-adding all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving graph as swan.p\n"
     ]
    }
   ],
   "source": [
    "# save the SwanGraph as a Python pickle file\n",
    "sg.save_graph('swan')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And you can reload the graph again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph from swan.p loaded\n"
     ]
    }
   ],
   "source": [
    "# load up a saved SwanGraph from a pickle file\n",
    "sg = swan.SwanGraph('swan.p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <a name=\"gtf_ab_sep\"></a>Adding transcript models (GTF) and abundance information separately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Swan can also run without abundance information, although many of Swan's analysis functions depend on abundance information. To load just the transcript models, simply just leave out the `counts_file` and `count_cols` arguments to the `add_dataset()` function as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for this new example, create a new empty SwanGraph\n",
    "sg = swan.SwanGraph()\n",
    "# and add the annotation transcriptome to it\n",
    "sg.add_annotation(annot_gtf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding dataset annotation to the SwanGraph.\n",
      "Adding dataset HepG2_1 to the SwanGraph.\n",
      "Adding dataset HepG2_2 to the SwanGraph.\n",
      "Adding dataset HFFc6_1 to the SwanGraph.\n",
      "Adding dataset HFFc6_2 to the SwanGraph.\n",
      "Adding dataset HFFc6_3 to the SwanGraph.\n"
     ]
    }
   ],
   "source": [
    "# add transcriptome datasets from GTF files without\n",
    "# corresponding abundance information\n",
    "sg.add_dataset('HepG2_1', hep_1_gtf)\n",
    "sg.add_dataset('HepG2_2', hep_2_gtf)\n",
    "sg.add_dataset('HFFc6_1', hff_1_gtf)\n",
    "sg.add_dataset('HFFc6_2', hff_2_gtf)\n",
    "sg.add_dataset('HFFc6_3', hff_3_gtf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have just added transcript models to the graph via `add_dataset()` and wish to add abundance information, this can be done using the `add_abundance()` function as seen below. Here, the string passed to `count_cols` is the column in the abundance file that corresponds to the dataset, and the argument passed to `dataset_name` is the name of the dataset that has already been added to the SwanGraph in the previous code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add abundance information corresponding to each of the datasets\n",
    "# we've already added to the SwanGraph\n",
    "# dataset_name must be a dataset that is already present in the SwanGraph\n",
    "sg.add_abundance(ab_file, count_cols='hepg2_1', dataset_name='HepG2_1')\n",
    "sg.add_abundance(ab_file, count_cols='hepg2_2', dataset_name='HepG2_2')\n",
    "sg.add_abundance(ab_file, count_cols='hffc6_1', dataset_name='HFFc6_1')\n",
    "sg.add_abundance(ab_file, count_cols='hffc6_2', dataset_name='HFFc6_2')\n",
    "sg.add_abundance(ab_file, count_cols='hffc6_3', dataset_name='HFFc6_3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"db_ab\"></a> Adding transcript models (TALON db) and abundance information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Swan is also directly compatible with TALON databases and can pull transcript models directly from them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for this new example, create a new empty SwanGraph\n",
    "sg = swan.SwanGraph()\n",
    "# and add the annotation transcriptome to it\n",
    "sg.add_annotation(annot_gtf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hepg2_whitelist='data/hepg2_whitelist.csv'\n",
    "hffc6_whitelist='data/hffc6_whitelist.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding dataset HepG2_1 to the SwanGraph.\n",
      "Adding dataset HepG2_2 to the SwanGraph.\n",
      "Adding dataset Hffc6_1 to the SwanGraph.\n",
      "Adding dataset Hffc6_2 to the SwanGraph.\n",
      "Adding dataset Hffc6_3 to the SwanGraph.\n"
     ]
    }
   ],
   "source": [
    "# add datasets directly from a TALON database and abundance\n",
    "# information from an abundance table\n",
    "# whitelist option is output from the talon_filter_transcripts\n",
    "# step, which filters novel isoforms based on their reproducibility\n",
    "# and for those that exhibit internal priming\n",
    "sg.add_dataset('HepG2_1', talon_db,\n",
    "    dataset_name='hepg2_1',\n",
    "    whitelist=hepg2_whitelist,\n",
    "\tcounts_file=ab_file,\n",
    "\tcount_cols='hepg2_1')\n",
    "sg.add_dataset('HepG2_2', talon_db,\n",
    "    dataset_name='hepg2_2',\n",
    "    whitelist=hepg2_whitelist,\n",
    "\tcounts_file=ab_file,\n",
    "\tcount_cols='hepg2_2')\n",
    "\n",
    "sg.add_dataset('Hffc6_1', talon_db,\n",
    "    dataset_name='hffc6_1',\n",
    "    whitelist=hffc6_whitelist,\n",
    "\tcounts_file=ab_file,\n",
    "\tcount_cols='hffc6_1')\n",
    "sg.add_dataset('Hffc6_2', talon_db,\n",
    "    dataset_name='hffc6_2',\n",
    "    whitelist=hffc6_whitelist,\n",
    "\tcounts_file=ab_file,\n",
    "\tcount_cols='hffc6_2')\n",
    "sg.add_dataset('Hffc6_3', talon_db,\n",
    "    dataset_name='hffc6_3',\n",
    "    whitelist=hffc6_whitelist,\n",
    "\tcounts_file=ab_file,\n",
    "\tcount_cols='hffc6_3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"batch\"></a> Batch adding datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wish to add multiple datasets to the SwanGraph with a single command, you can use the `add_datasets()` function with a config file. The format of the config file is detailed [here](TODO). You can provide datasets from both a TALON db or a GTF in the config file, as well as the annotation dataset. Below is an example of a config file that contains an annotation to be added to the SwanGraph, as well datasets from GTF files and from a TALON db."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>col</th>\n",
       "      <th>counts_file</th>\n",
       "      <th>count_cols</th>\n",
       "      <th>tid_col</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>whitelist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/gencode.v29.annotation.gtf</td>\n",
       "      <td>annotation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/talon.db</td>\n",
       "      <td>HepG2_1</td>\n",
       "      <td>data/all_talon_abundance_filtered.tsv</td>\n",
       "      <td>hepg2_1</td>\n",
       "      <td>annot_transcript_id</td>\n",
       "      <td>hepg2_1</td>\n",
       "      <td>data/hepg2_whitelist.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/talon.db</td>\n",
       "      <td>HepG2_2</td>\n",
       "      <td>data/all_talon_abundance_filtered.tsv</td>\n",
       "      <td>hepg2_2</td>\n",
       "      <td>annot_transcript_id</td>\n",
       "      <td>hepg2_2</td>\n",
       "      <td>data/hepg2_whitelist.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/hffc6_1_talon.gtf</td>\n",
       "      <td>HFFc6_1</td>\n",
       "      <td>data/all_talon_abundance_filtered.tsv</td>\n",
       "      <td>hffc6_1</td>\n",
       "      <td>annot_transcript_id</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/hffc6_2_talon.gtf</td>\n",
       "      <td>HFFc6_2</td>\n",
       "      <td>data/all_talon_abundance_filtered.tsv</td>\n",
       "      <td>hffc6_2</td>\n",
       "      <td>annot_transcript_id</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>data/hffc6_3_talon.gtf</td>\n",
       "      <td>HFFc6_3</td>\n",
       "      <td>data/all_talon_abundance_filtered.tsv</td>\n",
       "      <td>hffc6_3</td>\n",
       "      <td>annot_transcript_id</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             fname         col  \\\n",
       "0  data/gencode.v29.annotation.gtf  annotation   \n",
       "1                    data/talon.db     HepG2_1   \n",
       "2                    data/talon.db     HepG2_2   \n",
       "3           data/hffc6_1_talon.gtf     HFFc6_1   \n",
       "4           data/hffc6_2_talon.gtf     HFFc6_2   \n",
       "5           data/hffc6_3_talon.gtf     HFFc6_3   \n",
       "\n",
       "                             counts_file count_cols              tid_col  \\\n",
       "0                                    NaN        NaN                  NaN   \n",
       "1  data/all_talon_abundance_filtered.tsv    hepg2_1  annot_transcript_id   \n",
       "2  data/all_talon_abundance_filtered.tsv    hepg2_2  annot_transcript_id   \n",
       "3  data/all_talon_abundance_filtered.tsv    hffc6_1  annot_transcript_id   \n",
       "4  data/all_talon_abundance_filtered.tsv    hffc6_2  annot_transcript_id   \n",
       "5  data/all_talon_abundance_filtered.tsv    hffc6_3  annot_transcript_id   \n",
       "\n",
       "  dataset_name                 whitelist  \n",
       "0          NaN                       NaN  \n",
       "1      hepg2_1  data/hepg2_whitelist.csv  \n",
       "2      hepg2_2  data/hepg2_whitelist.csv  \n",
       "3          NaN                       NaN  \n",
       "4          NaN                       NaN  \n",
       "5          NaN                       NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "config_df = pd.read_csv('config.csv', sep='\\t')\n",
    "config_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the header columns in the config file are equivalent to arguments you would pass into the `add_dataset()` function, and unneccessary arguments based on the input file type (TALON db vs. GTF) can be left blank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for this new example, create a new empty SwanGraph\n",
    "sg = swan.SwanGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Adding dataset annotation to the SwanGraph\n",
      "\n",
      "Adding dataset HepG2_1 to the SwanGraph\n",
      "\n",
      "Adding dataset HepG2_2 to the SwanGraph\n",
      "\n",
      "Adding dataset HFFc6_1 to the SwanGraph\n",
      "\n",
      "Adding dataset HFFc6_2 to the SwanGraph\n",
      "\n",
      "Adding dataset HFFc6_3 to the SwanGraph\n"
     ]
    }
   ],
   "source": [
    "# add each dataset from the config file with the corresponding input\n",
    "# settings to the SwanGraph\n",
    "sg.add_datasets('config.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
