{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "sustainable-stewart",
   "metadata": {},
   "outputs": [],
   "source": [
    "import swan_vis as swan\n",
    "import pandas as pd\n",
    "import anndata\n",
    "import scanpy as sc\n",
    "from scipy import sparse\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "opposed-parks",
   "metadata": {},
   "outputs": [],
   "source": [
    "# added \n",
    "# utils.py\n",
    "def calc_total_counts(adata, obs_col='dataset', layer='counts'):\n",
    "    \n",
    "    # turn into a sparse dataframe\n",
    "    cols = adata.var.index.tolist()\n",
    "    inds = adata.obs[obs_col].tolist()\n",
    "    data = adata.layers[layer]\n",
    "    data = scipy.sparse.csr_matrix(data)\n",
    "    df = pd.DataFrame.sparse.from_spmatrix(data, index=inds, columns=cols)\n",
    "    df.index.name = obs_col \n",
    "\n",
    "    # add up values on condition (row)\n",
    "    df = df.groupby(level=0).sum()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "instrumental-merchandise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# added\n",
    "# utils.py\n",
    "def calc_tpm(adata, obs_col='dataset'):\n",
    "    \n",
    "    # calculate tpm using scanpy\n",
    "    d = sc.pp.normalize_total(adata,\n",
    "                              layer='counts',\n",
    "                              target_sum=1e6,\n",
    "                              key_added='total_counts',\n",
    "                              inplace=False)\n",
    "    adata.obs['total_counts'] = d['norm_factor']\n",
    "    \n",
    "    # turn into a sparse dataframe\n",
    "    cols = adata.var.index.tolist()\n",
    "    inds = adata.obs[obs_col].tolist()\n",
    "    data = d['X']\n",
    "    data = scipy.sparse.csr_matrix(data)\n",
    "    df = pd.DataFrame.sparse.from_spmatrix(data, index=inds, columns=cols)\n",
    "    df.index.name = obs_col    \n",
    "\n",
    "    # average across tpm\n",
    "    if obs_col != 'dataset':\n",
    "        df.reset_index(inplace=True)\n",
    "        df = df.groupby(obs_col).mean()\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "distinct-galaxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# added\n",
    "# swangraph.py\n",
    "def add_abundance(sg, counts_file):\n",
    "    \"\"\"\n",
    "    Adds abundance from a counts matrix to the SwanGraph. Transcripts in the\n",
    "    SwanGraph but not in the counts matrix will be assigned 0 counts.\n",
    "    Transcripts in the abundance matrix but not in the SwanGraph will not\n",
    "    have expression added.\n",
    "\n",
    "    Parameters:\n",
    "        counts_file (str): Path to TSV expression file where first column is\n",
    "            the transcript ID and following columns name the added datasets and\n",
    "            their counts in each dataset, OR to a TALON abundance matrix.\n",
    "    \"\"\"\n",
    "\n",
    "    # read in abundance file\n",
    "    swan.check_file_loc(counts_file, 'abundance matrix')\n",
    "    try:\n",
    "        df = pd.read_csv(counts_file, sep='\\t')\n",
    "    except:\n",
    "        raise ValueError('Problem reading expression matrix {}'.format(counts_file))\n",
    "\n",
    "    # check if abundance matrix is a talon abundance matrix\n",
    "    cols = ['gene_ID', 'transcript_ID', 'annot_gene_id', 'annot_transcript_id',\n",
    "        'annot_gene_name', 'annot_transcript_name', 'n_exons', 'length',\n",
    "        'gene_novelty', 'transcript_novelty', 'ISM_subtype']\n",
    "    if df.columns.tolist()[:11] == cols:\n",
    "        df = swan.reformat_talon_abundance(counts_file)\n",
    "\n",
    "    # rename transcript ID column\n",
    "    col = df.columns[0]\n",
    "    df.rename({col: 'tid'}, axis=1, inplace=True)\n",
    "\n",
    "    # limit to just the transcripts already in the graph\n",
    "    sg_tids = sg.t_df.tid.tolist()\n",
    "    ab_tids = df.tid.tolist()\n",
    "    tids = list(set(sg_tids)&set(ab_tids))\n",
    "    df = df.loc[df.tid.isin(tids)]\n",
    "    \n",
    "    # transpose to get adata format\n",
    "    df.set_index('tid', inplace=True)\n",
    "    df = df.T\n",
    "    \n",
    "    # get adata components - obs, var, and X\n",
    "    var = df.columns.to_frame()\n",
    "    var.columns = ['tid']\n",
    "    obs = df.index.to_frame()\n",
    "    obs.columns = ['dataset']\n",
    "    X = sparse.csr_matrix(df.to_numpy())\n",
    "    \n",
    "    # create transcript-level adata object and filter out unexpressed transcripts\n",
    "    adata = anndata.AnnData(var=var, obs=obs, X=X)\n",
    "    genes, _  = sc.pp.filter_genes(adata, min_counts=1, inplace=False)\n",
    "    adata = adata[:, genes]\n",
    "    adata.layers['counts'] = adata.X\n",
    "\n",
    "    # add each dataset to list of \"datasets\", check if any are already there!\n",
    "    datasets = adata.obs.dataset.tolist()\n",
    "    for d in datasets:\n",
    "        if d in sg.datasets:\n",
    "            raise ValueError('Dataset {} already present in the SwanGraph.'.format(d))\n",
    "    sg.datasets.extend(datasets)\n",
    "\n",
    "    print()\n",
    "    if len(datasets) <= 5:\n",
    "        print('Adding abundance for datasets {} to SwanGraph.'.format(', '.join(datasets)))\n",
    "    else:\n",
    "        mini_datasets = datasets[:5]\n",
    "        n = len(datasets) - len(mini_datasets)\n",
    "        print('Adding abundance for datasets {}... (and {} more) to SwanGraph'.format(', '.join(mini_datasets), n))\n",
    "\n",
    "    # if there is preexisting abundance data in the SwanGraph, concatenate\n",
    "    # otherwise, adata is the new transcript level adata\n",
    "    if not sg.has_abundance():\n",
    "\n",
    "        # create transcript-level adata object\n",
    "        sg.adata = adata\n",
    "\n",
    "        # add counts as layers\n",
    "        sg.adata.layers['counts'] = sg.adata.X\n",
    "        print('Calculating transcript TPM...')\n",
    "        sg.adata.layers['tpm'] = sparse.csr_matrix(calc_tpm(sg.adata).to_numpy())\n",
    "\n",
    "        if not sg.sc:\n",
    "            print('Calculating PI...') \n",
    "            sg.adata.layers['pi'] = sparse.csr_matrix(calc_pi(sg.adata, sg.t_df)[0].to_numpy())\n",
    "    else:\n",
    "        \n",
    "        # first set current layer to be counts\n",
    "        sg.adata.X = sg.adata.layers['counts']\n",
    "        \n",
    "        # concatenate existing adata with new one\n",
    "        # outer join to add all new transcripts (that are from added\n",
    "        # annotation or transcriptome) to the abundance\n",
    "        uns = sg.adata.uns\n",
    "        sg.adata = sg.adata.concatenate(adata, join='outer', index_unique=None)\n",
    "        sg.adata.uns = uns\n",
    "        \n",
    "        # recalculate pi and tpm\n",
    "        print('Calculating transcript TPM...')\n",
    "        sg.adata.layers['tpm'] = sparse.csr_matrix(calc_tpm(sg.adata).to_numpy())\n",
    "\n",
    "        if not sg.sc:\n",
    "            print('Calculating PI...')\n",
    "            sg.adata.layers['pi'] = sparse.csr_matrix(calc_pi(sg.adata, sg.t_df)[0].to_numpy())\n",
    "\n",
    "    # add abundance for edges, TSS per gene, and TES per gene\n",
    "    sg = create_edge_adata(sg)\n",
    "    print('Calculating TSS usage...')\n",
    "    sg = create_end_adata(sg, kind='tss')\n",
    "    print('Calculating TES usage...')\n",
    "    sg = create_end_adata(sg, kind='tes')\n",
    "\n",
    "    # set abundance flag to true\n",
    "    sg.abundance = True\n",
    "    \n",
    "    return sg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "fundamental-berkeley",
   "metadata": {},
   "outputs": [],
   "source": [
    "# added\n",
    "# swangraph.py\n",
    "def create_end_adata(sg, kind):\n",
    "    \"\"\"\n",
    "    Create a tss / tes-level adata object. Enables calculating tss / tes\n",
    "    usage across samples.\n",
    "\n",
    "    Parameters:\n",
    "        kind (str): Choose from 'tss' or 'tes'\n",
    "    \"\"\"\n",
    "\n",
    "    df = swan.get_ends(sg.t_df, kind)\n",
    "\n",
    "    # get a mergeable transcript expression df\n",
    "    tid = sg.adata.var.index.tolist()\n",
    "    obs = sg.adata.obs.index.tolist()\n",
    "    data = sg.adata.layers['counts'].transpose()\n",
    "    t_exp_df = pd.DataFrame.sparse.from_spmatrix(columns=obs, data=data, index=tid)\n",
    "    t_exp_df = t_exp_df.merge(sg.t_df, how='left',\n",
    "        left_index=True, right_index=True)\n",
    "\n",
    "    # merge counts per transcript with end expression\n",
    "    df = df.merge(t_exp_df, how='left',\n",
    "        left_index=True, right_index=True)\n",
    "\n",
    "    # sort based on vertex id\n",
    "    df.sort_index(inplace=True, ascending=True)\n",
    "\n",
    "    # set index to gene ID, gene name, and vertex id \n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df.set_index(['gid', 'gname', 'vertex_id'], inplace=True)\n",
    "    df = df[sg.datasets]\n",
    "\n",
    "    # groupby on gene and assign each unique TSS / gene combo an ID\n",
    "    id_col = '{}_id'.format(kind)\n",
    "    name_col = '{}_name'.format(kind)\n",
    "    df.reset_index(inplace=True)\n",
    "    df = df.groupby(['gid', 'gname', 'vertex_id']).sum().reset_index()\n",
    "    df['end_gene_num'] = df.sort_values(['gid', 'vertex_id'],\n",
    "                    ascending=[True, True])\\\n",
    "                    .groupby(['gid']) \\\n",
    "                    .cumcount() + 1\n",
    "    df[id_col] = df['gid']+'_'+df['end_gene_num'].astype(str)\n",
    "    df[name_col] = df['gname']+'_'+df['end_gene_num'].astype(str)\n",
    "    df.drop('end_gene_num', axis=1, inplace=True)\n",
    "\n",
    "    # obs, var, and X tables for new data\n",
    "    var_cols = ['gid', 'gname', 'vertex_id', id_col, name_col]\n",
    "    var = df[var_cols]\n",
    "    var.set_index('{}_id'.format(kind), inplace=True)\n",
    "    df.drop(var_cols, axis=1, inplace=True)\n",
    "    df = df[sg.adata.obs.index.tolist()]\n",
    "    X = sparse.csr_matrix(df.transpose().values)\n",
    "    obs = sg.adata.obs\n",
    "    \n",
    "    # create anndata\n",
    "    adata = anndata.AnnData(var=var, obs=obs, X=X)\n",
    "    \n",
    "    # add counts and tpm as layers\n",
    "    adata.layers['counts'] = adata.X\n",
    "    adata.layers['tpm'] = sparse.csr_matrix(calc_tpm(adata).to_numpy())\n",
    "    if not sg.sc:\n",
    "        adata.layers['pi'] = sparse.csr_matrix(calc_pi(adata,\n",
    "                adata.var)[0].to_numpy())\n",
    "\n",
    "    # assign adata and clean up unstructured data if needed\n",
    "    if kind == 'tss':\n",
    "        if sg.has_abundance():\n",
    "            adata.uns = sg.tss_adata.uns\n",
    "        sg.tss_adata = adata\n",
    "        \n",
    "    elif kind == 'tes':\n",
    "        if sg.has_abundance():\n",
    "            adata.uns = sg.tss_adata.uns\n",
    "        sg.tes_adata = adata\n",
    "    \n",
    "    return sg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "stunning-participation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# added\n",
    "# swangraph.py\n",
    "def create_edge_adata(sg):\n",
    "    \"\"\"\n",
    "    Create an edge-level adata object. Enables calculating edge usage across\n",
    "    samples.\n",
    "    \"\"\"\n",
    "\n",
    "    # get table what edges are in each transcript\n",
    "    edge_exp_df = swan.pivot_path_list(sg.t_df, 'path')\n",
    "\n",
    "    # get a mergeable transcript expression df\n",
    "    tid = sg.adata.var.index.tolist()\n",
    "    obs = sg.adata.obs.index.tolist()\n",
    "    data = sg.adata.layers['counts'].transpose()\n",
    "    t_exp_df = pd.DataFrame.sparse.from_spmatrix(columns=obs,\n",
    "                                                 data=data,\n",
    "                                                 index=tid)\n",
    "\n",
    "    # merge counts per transcript with edges\n",
    "    edge_exp_df = edge_exp_df.merge(t_exp_df, how='left',\n",
    "        left_index=True, right_index=True)\n",
    "\n",
    "    # sum the counts per transcript / edge / dataset\n",
    "    edge_exp_df = edge_exp_df.groupby('edge_id').sum()\n",
    "\n",
    "    # order based on order of edges in sg.edge_df\n",
    "    edge_exp_df = edge_exp_df.merge(sg.edge_df[['v1', 'v2']],\n",
    "        how='left', left_index=True, right_index=True)\n",
    "    edge_exp_df.sort_values(by=['v1', 'v2'], inplace=True)\n",
    "    edge_exp_df.drop(['v1', 'v2'], axis=1, inplace=True)\n",
    "    \n",
    "    # drop edges that are unexpressed\n",
    "    edge_exp_df = edge_exp_df.loc[edge_exp_df.sum(1) > 0]\n",
    "\n",
    "    # obs, var, and X tables for new data\n",
    "    var = edge_exp_df.index.to_frame()\n",
    "    X = sparse.csr_matrix(edge_exp_df.transpose().values)\n",
    "    obs = sg.adata.obs\n",
    "\n",
    "    # create edge-level adata object\n",
    "    adata = anndata.AnnData(var=var, obs=obs, X=X)\n",
    "\n",
    "    # add counts and tpm as layers\n",
    "    adata.layers['counts'] = adata.X\n",
    "    adata.layers['tpm'] = sparse.csr_matrix(calc_tpm(adata).to_numpy())\n",
    "    # can't make pi for edges unless I make a new edge for \n",
    "    # each gene that the edge is in\n",
    "    # could just have sg.edge_adata var separate from sg.edge_df for now tho\n",
    "#     sg.edge_adata.layers['pi'] = sparse.csr_matrix(calc_pi(sg.adata, sg.edge_df)[0].to_numpy())\n",
    "\n",
    "    # assign adata and clean up unstructured data if needed\n",
    "    if sg.has_abundance():\n",
    "        adata.uns = sg.edge_adata.uns\n",
    "    sg.edge_adata = adata\n",
    "    \n",
    "    return sg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "informed-bridges",
   "metadata": {},
   "outputs": [],
   "source": [
    "# added\n",
    "# utils.py\n",
    "def calc_pi(adata, t_df, obs_col='dataset'):\n",
    "\n",
    "    # calculate cumulative counts across obs_col\n",
    "    id_col = adata.var.index.name\n",
    "    conditions = adata.obs[obs_col].unique().tolist()\n",
    "    df = calc_total_counts(adata, obs_col=obs_col)\n",
    "    df = df.transpose()\n",
    "    # we use ints to index edges and locs\n",
    "    if id_col == 'vertex_id' or id_col == 'edge_id':\n",
    "        df.index = df.index.astype('int')\n",
    "\n",
    "    sums = df.copy(deep=True)\n",
    "    sums = sums[conditions]\n",
    "    sums = sums.transpose()\n",
    "\n",
    "    # add gid\n",
    "    df = df.merge(t_df['gid'], how='left', left_index=True, right_index=True)\n",
    "    t_counts = df.melt(id_vars=['gid'],\n",
    "                       value_vars=conditions,\n",
    "                       var_name=obs_col,\n",
    "                       value_name='t_counts',\n",
    "                       ignore_index=False)\n",
    "    t_counts.index.name = id_col\n",
    "    t_counts.reset_index(inplace=True)\n",
    "\n",
    "    # calculate total number of reads per gene per condition\n",
    "    temp = df.copy(deep=True)\n",
    "    temp.reset_index(drop=True, inplace=True)\n",
    "    totals = temp.groupby('gid').sum().reset_index()\n",
    "\n",
    "    # merge back in\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename({'index':id_col}, axis=1, inplace=True)\n",
    "    df = df.merge(totals, on='gid', suffixes=('_t_counts', None))\n",
    "    del totals\n",
    "\n",
    "    df = df.melt(id_vars=['gid'], \n",
    "                 value_vars=conditions, \n",
    "                 var_name=obs_col,\n",
    "                 value_name='gene_counts')\n",
    "    df = df.drop_duplicates()\n",
    "    df = t_counts.merge(df, how='left', on=['gid', obs_col])\n",
    "\n",
    "\n",
    "    df['pi'] = (df.t_counts/df.gene_counts)*100\n",
    "    df = df.pivot(columns=obs_col, index=id_col, values='pi')\n",
    "\n",
    "    # order based on order in adata\n",
    "    ids = adata.var.index.tolist()\n",
    "    df = df.loc[ids]\n",
    "    cols = adata.obs[obs_col].unique().tolist()\n",
    "    df = df[cols]\n",
    "\n",
    "    # convert to sparse\n",
    "    df = df.transpose()\n",
    "    df = pd.DataFrame.sparse.from_spmatrix(data=sparse.csr_matrix(df.values),\n",
    "                                           index=df.index.tolist(),\n",
    "                                           columns=df.columns)\n",
    "    return df, sums\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "involved-helicopter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Adding annotation to the SwanGraph\n",
      "\n",
      "Adding transcriptome to the SwanGraph\n",
      "\n",
      "Adding abundance for datasets dataset1, dataset2 to SwanGraph.\n",
      "Calculating transcript TPM...\n",
      "Calculating PI...\n",
      "df\n",
      "       dataset1  dataset2\n",
      "test1       5.0       5.0\n",
      "test2      10.0       0.0\n",
      "test3       0.0      10.0\n",
      "test4      10.0      10.0\n",
      "test5       5.0       5.0\n",
      "t_df\n",
      "             tname        gid        gname               path    tid  \\\n",
      "tid                                                                    \n",
      "test1  test1_tname  test1_gid  test1_gname    [0, 1, 2, 3, 4]  test1   \n",
      "test2  test2_tname  test2_gid  test2_gname    [5, 6, 7, 8, 9]  test2   \n",
      "test3  test3_tname  test2_gid  test2_gname  [5, 6, 14, 15, 9]  test3   \n",
      "test4  test4_tname  test4_gid  test4_gname               [10]  test4   \n",
      "test5  test5_tname  test2_gid  test2_gname        [5, 11, 12]  test5   \n",
      "\n",
      "                    loc_path  annotation    novelty  \n",
      "tid                                                  \n",
      "test1     [0, 1, 2, 3, 4, 5]        True      Known  \n",
      "test2  [12, 11, 10, 8, 7, 6]        True      Known  \n",
      "test3  [12, 11, 10, 9, 7, 6]       False  Undefined  \n",
      "test4                 [6, 7]        True      Known  \n",
      "test5         [12, 11, 8, 7]        True      Known  \n",
      "Calculating TSS usage...\n",
      "df\n",
      "             dataset1  dataset2\n",
      "test1_gid_1       5.0       5.0\n",
      "test2_gid_1      15.0      15.0\n",
      "test4_gid_1      10.0      10.0\n",
      "t_df\n",
      "                   gid        gname  vertex_id       tss_name\n",
      "tss_id                                                       \n",
      "test1_gid_1  test1_gid  test1_gname          0  test1_gname_1\n",
      "test2_gid_1  test2_gid  test2_gname         12  test2_gname_1\n",
      "test4_gid_1  test4_gid  test4_gname          6  test4_gname_1\n",
      "Calculating TES usage...\n",
      "df\n",
      "             dataset1  dataset2\n",
      "test1_gid_1       5.0       5.0\n",
      "test2_gid_1      10.0      10.0\n",
      "test2_gid_2       5.0       5.0\n",
      "test4_gid_1      10.0      10.0\n",
      "t_df\n",
      "                   gid        gname  vertex_id       tes_name\n",
      "tes_id                                                       \n",
      "test1_gid_1  test1_gid  test1_gname          5  test1_gname_1\n",
      "test2_gid_1  test2_gid  test2_gname          6  test2_gname_1\n",
      "test2_gid_2  test2_gid  test2_gname          7  test2_gname_2\n",
      "test4_gid_1  test4_gid  test4_gname          7  test4_gname_1\n",
      "                   gid        gname  vertex_id       tss_name\n",
      "tss_id                                                       \n",
      "test1_gid_1  test1_gid  test1_gname          0  test1_gname_1\n",
      "test2_gid_1  test2_gid  test2_gname         12  test2_gname_1\n",
      "test4_gid_1  test4_gid  test4_gname          6  test4_gname_1\n",
      "tid\n",
      "test1       [0, 1, 2, 3, 4, 5]\n",
      "test2    [12, 11, 10, 8, 7, 6]\n",
      "test3    [12, 11, 10, 9, 7, 6]\n",
      "test4                   [6, 7]\n",
      "test5           [12, 11, 8, 7]\n",
      "test6    [13, 11, 10, 8, 7, 6]\n",
      "Name: loc_path, dtype: object\n",
      "         tid\n",
      "tid         \n",
      "test1  test1\n",
      "test2  test2\n",
      "test3  test3\n",
      "test4  test4\n",
      "test5  test5\n",
      "[[ 5. 10.  0. 10.  5.]\n",
      " [ 5.  0. 10. 10.  5.]]\n",
      "                   gid        gname  vertex_id       tss_name\n",
      "tss_id                                                       \n",
      "test1_gid_1  test1_gid  test1_gname          0  test1_gname_1\n",
      "test2_gid_1  test2_gid  test2_gname         12  test2_gname_1\n",
      "test4_gid_1  test4_gid  test4_gname          6  test4_gname_1\n",
      "[[ 5. 15. 10.]\n",
      " [ 5. 15. 10.]]\n",
      "[[166666.69 500000.03 333333.38]\n",
      " [166666.69 500000.03 333333.38]]\n",
      "[[100. 100. 100.]\n",
      " [100. 100. 100.]]\n",
      "                   gid        gname  vertex_id       tes_name\n",
      "tes_id                                                       \n",
      "test1_gid_1  test1_gid  test1_gname          5  test1_gname_1\n",
      "test2_gid_1  test2_gid  test2_gname          6  test2_gname_1\n",
      "test2_gid_2  test2_gid  test2_gname          7  test2_gname_2\n",
      "test4_gid_1  test4_gid  test4_gname          7  test4_gname_1\n",
      "             gid    tid               loc_path\n",
      "tid                                           \n",
      "test1  test1_gid  test1     [0, 1, 2, 3, 4, 5]\n",
      "test2  test2_gid  test2  [12, 11, 10, 8, 7, 6]\n",
      "test3  test2_gid  test3  [12, 11, 10, 9, 7, 6]\n",
      "test4  test4_gid  test4                 [6, 7]\n",
      "test5  test2_gid  test5         [12, 11, 8, 7]\n",
      "test6  test2_gid  test6  [13, 11, 10, 8, 7, 6]\n",
      "         tid\n",
      "tid         \n",
      "test1  test1\n",
      "test2  test2\n",
      "test3  test3\n",
      "test4  test4\n",
      "test5  test5\n",
      "[[ 5. 10.  0. 10.  5.]\n",
      " [ 5.  0. 10. 10.  5.]]\n",
      "                   gid        gname  vertex_id       tes_name\n",
      "tes_id                                                       \n",
      "test1_gid_1  test1_gid  test1_gname          5  test1_gname_1\n",
      "test2_gid_1  test2_gid  test2_gname          6  test2_gname_1\n",
      "test2_gid_2  test2_gid  test2_gname          7  test2_gname_2\n",
      "test4_gid_1  test4_gid  test4_gname          7  test4_gname_1\n",
      "[[ 5. 10.  5. 10.]\n",
      " [ 5. 10.  5. 10.]]\n",
      "[[166666.69 333333.38 166666.69 333333.38]\n",
      " [166666.69 333333.38 166666.69 333333.38]]\n",
      "[[100.        66.66667   33.333336 100.      ]\n",
      " [100.        66.66667   33.333336 100.      ]]\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fairliereese/miniconda3/lib/python3.7/site-packages/anndata/_core/anndata.py:120: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n"
     ]
    }
   ],
   "source": [
    "sg = swan.SwanGraph()\n",
    "sg.add_annotation('../testing/files/test_full_annotation.gtf')\n",
    "sg.add_transcriptome('../testing/files/test_full.gtf')\n",
    "sg = add_abundance(sg, '../testing/files/test_ab_talon_1.tsv')\n",
    "\n",
    "print(sg.tss_adata.var.head())\n",
    "print(sg.t_df.loc_path)\n",
    "print(sg.adata.var.head())\n",
    "print(sg.adata.layers['counts'].toarray())\n",
    "print(sg.tss_adata.var.head())\n",
    "print(sg.tss_adata.layers['counts'].toarray())\n",
    "print(sg.tss_adata.layers['tpm'].toarray())\n",
    "print(sg.tss_adata.layers['pi'].toarray())\n",
    "\n",
    "print(sg.tes_adata.var.head())\n",
    "print(sg.t_df[['gid', 'tid', 'loc_path']])\n",
    "print(sg.adata.var.head())\n",
    "print(sg.adata.layers['counts'].toarray())\n",
    "print(sg.tes_adata.var)\n",
    "print(sg.tes_adata.layers['counts'].toarray())\n",
    "print(sg.tes_adata.layers['tpm'].toarray())\n",
    "print(sg.tes_adata.layers['pi'].toarray())\n",
    "\n",
    "print(type(sg.tes_adata.layers['counts']))\n",
    "print(type(sg.tes_adata.layers['tpm']))\n",
    "print(type(sg.tes_adata.layers['pi']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floppy-chinese",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_add_abundance_3\n",
    "sg = swan.SwanGraph()\n",
    "sg.add_annotation('../testing/files/test_full_annotation.gtf')\n",
    "sg.add_transcriptome('../testing/files/test_full.gtf')\n",
    "\n",
    "sg = add_abundance(sg, '../testing/files/test_ab_talon_1.tsv')\n",
    "print(sg.t_df.index.tolist())\n",
    "print(sg.adata.var.index.tolist())\n",
    "print(sg.adata.layers['counts'].toarray())\n",
    "print(sg.adata.layers['tpm'].toarray())\n",
    "print(sg.adata.layers['pi'].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "advised-dryer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Adding annotation to the SwanGraph\n",
      "\n",
      "Adding transcriptome to the SwanGraph\n",
      "\n",
      "Adding abundance for datasets dataset1 to SwanGraph.\n",
      "Calculating transcript TPM...\n",
      "Calculating PI...\n",
      "\n",
      "Adding abundance for datasets dataset2 to SwanGraph.\n",
      "Calculating transcript TPM...\n",
      "Calculating PI...\n",
      "['test1', 'test2', 'test3', 'test4', 'test5', 'test6']\n",
      "['test1', 'test2', 'test3', 'test4', 'test5']\n",
      "[[ 5. 10.  0. 10.  5.]\n",
      " [ 5.  0. 10. 10.  5.]]\n",
      "[[166666.69 333333.38      0.   333333.38 166666.69]\n",
      " [166666.69      0.   333333.38 333333.38 166666.69]]\n",
      "[[100.        66.66667    0.       100.        33.333336]\n",
      " [100.         0.        66.66667  100.        33.333336]]\n"
     ]
    }
   ],
   "source": [
    "# test_add_abundance_2\n",
    "sg = swan.SwanGraph()\n",
    "sg.add_annotation('../testing/files/test_full_annotation.gtf')\n",
    "sg.add_transcriptome('../testing/files/test_full.gtf')\n",
    "\n",
    "sg = add_abundance(sg, '../testing/files/test_ab_dataset1.tsv')\n",
    "sg = add_abundance(sg, '../testing/files/test_ab_dataset2.tsv')\n",
    "\n",
    "print(sg.t_df.index.tolist())\n",
    "print(sg.adata.var.index.tolist())\n",
    "print(sg.adata.layers['counts'].toarray())\n",
    "print(sg.adata.layers['tpm'].toarray())\n",
    "print(sg.adata.layers['pi'].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "english-authentication",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Adding annotation to the SwanGraph\n",
      "\n",
      "Adding transcriptome to the SwanGraph\n",
      "\n",
      "Adding abundance for datasets dataset1, dataset2 to SwanGraph.\n",
      "Calculating transcript TPM...\n",
      "Calculating PI...\n",
      "['test1', 'test2', 'test3', 'test4', 'test5', 'test6']\n",
      "['test1', 'test2', 'test3', 'test4', 'test5']\n",
      "[[ 5. 10.  0. 10.  5.]\n",
      " [ 5.  0. 10. 10.  5.]]\n",
      "[[166666.69 333333.38      0.   333333.38 166666.69]\n",
      " [166666.69      0.   333333.38 333333.38 166666.69]]\n",
      "[[100.        66.66667    0.       100.        33.333336]\n",
      " [100.         0.        66.66667  100.        33.333336]]\n"
     ]
    }
   ],
   "source": [
    "# test_add_abundance_1\n",
    "sg = swan.SwanGraph()\n",
    "sg.add_annotation('../testing/files/test_full_annotation.gtf')\n",
    "sg.add_transcriptome('../testing/files/test_full.gtf')\n",
    "sg = add_abundance(sg, '../testing/files/test_ab_1.tsv')\n",
    "\n",
    "print(sg.t_df.index.tolist())\n",
    "print(sg.adata.var.index.tolist())\n",
    "print(sg.adata.layers['counts'].toarray())\n",
    "print(sg.adata.layers['tpm'].toarray())\n",
    "print(sg.adata.layers['pi'].toarray())\n",
    "\n",
    "\n",
    "# looks good but tests still needa be updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "negative-immunology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Adding transcriptome to the SwanGraph\n",
      "\n",
      "Adding abundance for datasets dataset1, dataset2 to SwanGraph.\n",
      "Calculating transcript TPM...\n",
      "Calculating PI...\n",
      "Calculating TSS usage...\n",
      "Calculating TES usage...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>tid</th>\n",
       "      <th>test1</th>\n",
       "      <th>test2</th>\n",
       "      <th>test3</th>\n",
       "      <th>test4</th>\n",
       "      <th>test5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c1</th>\n",
       "      <td>100.0</td>\n",
       "      <td>33.333336</td>\n",
       "      <td>33.333336</td>\n",
       "      <td>100.0</td>\n",
       "      <td>33.333336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "tid  test1      test2      test3  test4      test5\n",
       "c1   100.0  33.333336  33.333336  100.0  33.333336"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_calc_pi_2\n",
    "sg = swan.SwanGraph()\n",
    "sg.add_transcriptome('../testing/files/test_full.gtf')\n",
    "sg = add_abundance(sg, '../testing/files/test_ab_1.tsv')\n",
    "sg.adata.obs['cluster'] = 'c1'\n",
    "test_df, test_sums = calc_pi(sg.adata, sg.t_df, obs_col='cluster')\n",
    "\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "excited-slave",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Adding transcriptome to the SwanGraph\n",
      "\n",
      "Adding abundance for datasets dataset1, dataset2 to SwanGraph.\n",
      "Calculating transcript TPM...\n",
      "Calculating PI...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>tid</th>\n",
       "      <th>test1</th>\n",
       "      <th>test2</th>\n",
       "      <th>test3</th>\n",
       "      <th>test4</th>\n",
       "      <th>test5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dataset1</th>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666672</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>33.333336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset2</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>66.666672</td>\n",
       "      <td>100.0</td>\n",
       "      <td>33.333336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "tid       test1      test2      test3  test4      test5\n",
       "dataset1  100.0  66.666672   0.000000  100.0  33.333336\n",
       "dataset2  100.0   0.000000  66.666672  100.0  33.333336"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_calc_pi_1\n",
    "sg = swan.SwanGraph()\n",
    "sg.add_transcriptome('../testing/files/test_full.gtf')\n",
    "sg = add_abundance(sg, '../testing/files/test_ab_1.tsv')\n",
    "test_df, test_sums = calc_pi(sg.adata, sg.t_df, obs_col='dataset')\n",
    "\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "ceramic-swing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in graph from test_mousewg.p\n"
     ]
    }
   ],
   "source": [
    "sg = swan.read('test_mousewg.p')\n",
    "ab = '/Users/fairliereese/mortazavi_lab/data/mousewg/lr_bulk/talon/mouse_talon_abundance_filtered.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "former-eleven",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Adding abundance for datasets gastroc_14d_f_2, gastroc_14d_f_1, heart_18-20mo_m_1, heart_18-20mo_m_2, heart_18-20mo_f_1... (and 86 more) to SwanGraph\n",
      "Calculating transcript TPM...\n"
     ]
    }
   ],
   "source": [
    "# test adding de novo\n",
    "sg = add_abundance(sg, ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "suspended-reproduction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Adding transcriptome to the SwanGraph\n",
      "\n",
      "Adding abundance for datasets dataset1, dataset2 to SwanGraph.\n",
      "Calculating transcript TPM...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test1</th>\n",
       "      <th>test2</th>\n",
       "      <th>test3</th>\n",
       "      <th>test4</th>\n",
       "      <th>test5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dataset1</th>\n",
       "      <td>166666.671875</td>\n",
       "      <td>333333.34375</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>333333.34375</td>\n",
       "      <td>166666.671875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset2</th>\n",
       "      <td>166666.671875</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>333333.34375</td>\n",
       "      <td>333333.34375</td>\n",
       "      <td>166666.671875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  test1         test2         test3         test4  \\\n",
       "dataset                                                             \n",
       "dataset1  166666.671875  333333.34375       0.00000  333333.34375   \n",
       "dataset2  166666.671875       0.00000  333333.34375  333333.34375   \n",
       "\n",
       "                  test5  \n",
       "dataset                  \n",
       "dataset1  166666.671875  \n",
       "dataset2  166666.671875  "
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_calc_tpm_1\n",
    "sg = swan.SwanGraph()\n",
    "sg.add_transcriptome('../testing/files/test_full.gtf')\n",
    "sg = add_abundance(sg, '../testing/files/test_ab_1.tsv')\n",
    "sg.adata.obs['cluster'] = ['c1', 'c1']\n",
    "\n",
    "df = calc_tpm(sg.adata)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "outdoor-southeast",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[166666.67, 333333.34,      0.  , 333333.34, 166666.67],\n",
       "       [166666.67,      0.  , 333333.34, 333333.34, 166666.67]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sg.adata.layers['tpm'].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "aggregate-findings",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Adding transcriptome to the SwanGraph\n",
      "\n",
      "Adding abundance for datasets dataset1, dataset2 to SwanGraph.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test1</th>\n",
       "      <th>test2</th>\n",
       "      <th>test3</th>\n",
       "      <th>test4</th>\n",
       "      <th>test5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c1</th>\n",
       "      <td>166666.671875</td>\n",
       "      <td>166666.671875</td>\n",
       "      <td>166666.671875</td>\n",
       "      <td>333333.34375</td>\n",
       "      <td>166666.671875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 test1          test2          test3         test4  \\\n",
       "cluster                                                              \n",
       "c1       166666.671875  166666.671875  166666.671875  333333.34375   \n",
       "\n",
       "                 test5  \n",
       "cluster                 \n",
       "c1       166666.671875  "
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_calc_tpm_2\n",
    "sg = swan.SwanGraph()\n",
    "sg.add_transcriptome('../testing/files/test_full.gtf')\n",
    "sg = add_abundance(sg, '../testing/files/test_ab_1.tsv')\n",
    "sg.adata.obs['cluster'] = ['c1', 'c1']\n",
    "\n",
    "df = calc_tpm(sg.adata, obs_col='cluster')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "developmental-special",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Adding transcriptome to the SwanGraph\n",
      "\n",
      "Adding abundance for datasets dataset1, dataset2 to SwanGraph.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test1</th>\n",
       "      <th>test2</th>\n",
       "      <th>test3</th>\n",
       "      <th>test4</th>\n",
       "      <th>test5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dataset1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          test1  test2  test3  test4  test5\n",
       "dataset                                    \n",
       "dataset1    5.0   10.0    0.0   10.0    5.0\n",
       "dataset2    5.0    0.0   10.0   10.0    5.0"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_calc_total_counts_1\n",
    "sg = swan.SwanGraph()\n",
    "sg.add_transcriptome('../testing/files/test_full.gtf')\n",
    "sg = add_abundance(sg, '../testing/files/test_ab_1.tsv')\n",
    "sg.adata.obs['cluster'] = ['c1', 'c1']\n",
    "\n",
    "df = calc_total_counts(sg.adata)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "hired-viewer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Adding transcriptome to the SwanGraph\n",
      "\n",
      "Adding abundance for datasets dataset1, dataset2 to SwanGraph.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test1</th>\n",
       "      <th>test2</th>\n",
       "      <th>test3</th>\n",
       "      <th>test4</th>\n",
       "      <th>test5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         test1  test2  test3  test4  test5\n",
       "cluster                                   \n",
       "c1        10.0   10.0   10.0   20.0   10.0"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_calc_total_counts_2\n",
    "sg = swan.SwanGraph()\n",
    "sg.add_transcriptome('../testing/files/test_full.gtf')\n",
    "sg = add_abundance(sg, '../testing/files/test_ab_1.tsv')\n",
    "sg.adata.obs['cluster'] = ['c1', 'c1']\n",
    "\n",
    "df = calc_total_counts(sg.adata, obs_col='cluster')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funky-martin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test merging when incoming adata has duplicate dataset names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "responsible-helena",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test merging when adding new dataset adds new transcript id to the adata - already tested with test_add_abundance_2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
