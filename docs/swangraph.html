<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.8.1" />
<title>swan_vis.swangraph API documentation</title>
<meta name="description" content="" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>swan_vis.swangraph</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import networkx as nx
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib as mpl
import os
import math
import copy
from collections import defaultdict
import sqlite3
import pickle
import anndata
import diffxpy.api as de
from multiprocessing import Pool
from itertools import repeat
from swan_vis.utils import *
from swan_vis.talon_utils import *
from swan_vis.graph import *
from swan_vis.plottedgraph import PlottedGraph
from swan_vis.report import Report

class SwanGraph(Graph):
        &#34;&#34;&#34; 
        A graph class to represent a transcriptome and perform
        plotting and analysis from it

                Attributes:
                        datasets (list of str):
                                Names of datasets in the Graph
                        counts (list of str):
                                Names of columns holding counts in the Graph
                        tpm (list of str):
                                Names of columns holding tpm values in the Graph
                        loc_df (pandas DataFrame): 
                                DataFrame of all unique observed genomic 
                                coordinates in the transcriptome
                        edge_df (pandas DataFrame):
                                DataFrame of all unique observed exonic or intronic
                                combinations of splice sites in the transcriptome
                        t_df (pandas DataFrame): 
                                DataFrame of all unique transcripts found 
                                in the transcriptome
                        pg (swan PlottedGraph):
                                The PlottedGraph holds the information from the most 
                                recently made plot
                        deg_test (pandas DataFrame): 
                                A summary table of the results of a differential gene
                                expression test
                        deg_test_groups (list of str, len 2):
                                The configuration of groupings used to run the differential
                                gene expression test
                                det_test (pandas DataFrame): 
                                A summary table of the results of a differential transcript
                                expression test
                        det_test_groups (list of str, len 2):
                                The configuration of groupings used to run the differential
                                transcript expression test
        &#34;&#34;&#34;

        def __init__(self, file=None):

                if not file:
                        super().__init__()

                        # only a SwanGraph should have a plotted graph
                        self.pg = PlottedGraph()

                        # only a SwanGraph should have DEG and DET data
                        self.deg_test = pd.DataFrame()
                        self.deg_test_groups = &#39;&#39;
                        self.det_test = pd.DataFrame()
                        self.det_test_groups = &#39;&#39;

                else:
                        check_file_loc(file, &#39;SwanGraph&#39;)
                        self.load_graph(file)

        ###########################################################################
        ############## Related to adding datasets and merging #####################
        ###########################################################################

        def add_annotation(self, fname):
                &#34;&#34;&#34;
                Adds an annotation from input fname to the SwanGraph.

                        Parameters:

                                fname (str): Path to annotation GTF
                &#34;&#34;&#34;

                # column name for annotation 
                col = &#39;annotation&#39;

                # use the add_dataset function to add stuff to graph
                self.add_dataset(col, fname, include_isms=True)

                # call all transcripts from the annotation &#34;Known&#34;
                self.t_df.loc[self.t_df.annotation == True, &#39;novelty&#39;] = &#39;Known&#39;
                self.t_df.novelty.fillna(&#39;Undefined&#39;, inplace=True)

        def add_dataset(self, col, fname,
                                        dataset_name=None,
                                        whitelist=None,
                                        annot=None,
                                        counts_file=None, count_cols=None, 
                                        tid_col=&#39;annot_transcript_id&#39;,
                                        include_isms=False):
                &#34;&#34;&#34;
                Add transcripts from a dataset from either a GTF or a TALON database.

                        Parameters:

                                col (str): Name of column to add data to in the SwanGraph
                                fname (str): Path to GTF or TALON db

                                Only for loading from TALON
                                dataset_name (str): Dataset name in TALON db to add transcripts from
                                        Default=None
                                whitelist (str): TALON whitelist of transcripts to add.
                                        Default: None
                                annot (str): TALON annotation name in database to 
                                        add transcripts from
                                        Default: None

                                Only if also adding abundance:
                                counts_file (str): Path to tsv counts matrix
                                        Default=None
                                count_cols (str or list of str): Column names in counts_file to use
                                        Default=None
                                tid_col (str): Column name in counts_file containing transcript id
                                        Default=&#39;annot_transcript_id&#39;

                                include_isms (bool): Include ISMs from input dataset
                                        Default=False
                &#34;&#34;&#34;

                # make sure that input dataset name is not
                # already in any of the df col spaces
                if col in self.datasets:
                        raise Exception(&#39;Dataset {} is already in the graph. &#39;
                                &#39;Provide a different name.&#39;.format(col))
                if col in self.loc_df.columns:
                        raise Exception(&#39;Dataset name {} conflicts with preexisting &#39;
                                &#39;column in loc_df. Choose a different name.&#39;.format(col))
                if col in self.edge_df.columns:
                        raise Exception(&#39;Dataset name {} conflicts with preexisting &#39;
                                &#39;column in edge_df. Choose a different name.&#39;.format(col))
                if col in self.t_df.columns:
                        raise Exception(&#39;Dataset name {} conflicts with preexisting &#39;
                                &#39;column in t_df. Choose a different name.&#39;.format(col))

                # are we dealing with a gtf or a db?
                ftype = gtf_or_db(fname)

                print(&#39;Adding dataset {} to the SwanGraph.&#39;.format(col))

                # first entry is easy 
                if self.is_empty():

                        # get loc_df, edge_df, t_df
                        if ftype == &#39;gtf&#39;:
                                self.create_dfs_gtf(fname)
                        elif ftype == &#39;db&#39;:
                                self.create_dfs_db(fname, annot, whitelist, &#39;hepg2_1&#39;)

                        # add column to each df to indicate where data came from
                        self.loc_df[col] = True
                        self.edge_df[col] = True
                        self.t_df[col] = True

                # adding a new dataset to the graph requires us to merge
                # SwanGraph objects
                else:
                        temp = SwanGraph()
                        if ftype == &#39;gtf&#39;:
                                temp.create_dfs_gtf(fname)
                        elif ftype == &#39;db&#39;:
                                temp.create_dfs_db(fname, annot, whitelist, &#39;hepg2_1&#39;)
                        self.merge_dfs(temp, col)

                # remove isms if we have access to that information
                if &#39;novelty&#39; in self.t_df.columns and not include_isms:
                        self.t_df = self.t_df.loc[self.t_df.novelty != &#39;ISM&#39;]

                # order node ids by genomic position, add node types,
                # and create graph
                self.update_ids()
                self.order_edge_df()
                self.order_transcripts()
                self.get_loc_types()
                self.create_graph_from_dfs()

                # update graph metadata
                self.datasets.append(col)

                # if we&#39;re also adding abundances
                if counts_file and count_cols:
                        self.add_abundance(counts_file, count_cols, col, tid_col)
 
        def add_abundance(self, counts_file, count_cols,
                                          dataset_name, tid_col=&#39;annot_transcript_id&#39;):
                &#34;&#34;&#34;
                Adds abundance information to an existing dataset in the SwanGraph.

                        Parameters:

                                counts_file (str): Path to tsv counts matrix
                                count_cols (str or list of str): Column names in counts_file to use
                                dataset_name (str): Name of SwanGraph dataset to associate abundance with
                                tid_col (str): Column name in counts_file containing transcript id
                                        Default=&#39;annot_transcript_id&#39;
                &#34;&#34;&#34;

                # if the dataset we&#39;re trying to add counts too doesn&#39;t exist
                if dataset_name not in self.datasets:
                        raise Exception(&#39;Trying to add expression data to a dataset &#39;
                                                        &#39;that is not in the graph. Add dataset to graph first.&#39;)

                # get counts from input abundance file 
                abundance_df = process_abundance_file(counts_file, count_cols, tid_col)
                abundance_df.rename({&#39;tpm&#39;: &#39;{}_tpm&#39;.format(dataset_name),
                                                         &#39;counts&#39;: &#39;{}_counts&#39;.format(dataset_name)},
                                                         axis=1, inplace=True)

                # merge on transcript id (tid) with t_df and make sure it&#39;s 
                # formatted correctly
                self.t_df.reset_index(drop=True, inplace=True)
                self.t_df = self.t_df.merge(abundance_df, on=&#39;tid&#39;, how=&#39;left&#39;)
                self.t_df.fillna(value=0, inplace=True)
                self.t_df = create_dupe_index(self.t_df, &#39;tid&#39;)
                self.t_df = set_dupe_index(self.t_df, &#39;tid&#39;)

                # finally update object&#39;s metadata
                self.counts.append(&#39;{}_counts&#39;.format(dataset_name))
                self.tpm.append(&#39;{}_tpm&#39;.format(dataset_name))

        # merge dfs from two SwanGraph objects
        def merge_dfs(self, b, b_col):

                # merge loc dfs
                # what locations correspond between the datasets?
                self.merge_loc_dfs(b, b_col)
                id_map = self.get_merged_id_map()

                self.loc_df.drop([&#39;vertex_id_a&#39;,&#39;vertex_id_b&#39;], axis=1, inplace=True)
                self.loc_df[&#39;vertex_id&#39;] = self.loc_df.index
                self.loc_df = create_dupe_index(self.loc_df, &#39;vertex_id&#39;)
                self.loc_df = set_dupe_index(self.loc_df, &#39;vertex_id&#39;)
                b.loc_df = create_dupe_index(b.loc_df, &#39;vertex_id&#39;)
                b.loc_df = set_dupe_index(b.loc_df, &#39;vertex_id&#39;)

                # update the ids in b to make edge_df, t_df merging easier
                b.update_ids(id_map=id_map)

                # merge edge_df and t_df
                self.merge_edge_dfs(b, b_col)
                self.merge_t_dfs(b, b_col)

        # merge t_dfs on tid, gid, gname, path
        def merge_t_dfs(self, b, b_col):

                # print note to user about merging with novelty
                existing_cols = self.t_df.columns
                add_cols = b.t_df.columns
                if &#39;novelty&#39; not in existing_cols and &#39;novelty&#39; in add_cols:
                        print(&#39;Novelty info not found for &#39;
                                  &#39;existing data. Transcripts &#39;
                                  &#39;without novelty information will be &#39;
                                  &#39;labelled &#34;Undefined&#34;.&#39;)
                elif &#39;novelty&#39; not in add_cols and &#39;novelty&#39; in existing_cols:
                        print(&#39;Novelty info not found for &#39;
                                 &#39;{} data. Transcripts &#39;
                                 &#39;without novelty information will be &#39;
                                 &#39;labelled &#34;Undefined&#34;.&#39;.format(b_col))

                # some df reformatting
                self.t_df.reset_index(drop=True, inplace=True)
                b.t_df.reset_index(drop=True, inplace=True)
                b.t_df[b_col] = True

                # convert paths to tuples so we can merge on them
                self.t_df.path = self.t_df.path.map(tuple)
                b.t_df.path = b.t_df.path.map(tuple)

                # merge on transcript information
                t_df = self.t_df.merge(b.t_df,
                           how=&#39;outer&#39;,
                           on=[&#39;tid&#39;, &#39;gid&#39;, &#39;gname&#39;, &#39;path&#39;],
                           suffixes=[&#39;_a&#39;, &#39;_b&#39;])

                # convert path back to list
                t_df.path = list(t_df.path)

                # assign False to entries that are not in the new dataset, 
                # and to new entries that were not in the prior datasets
                d_cols = self.datasets+[b_col]
                t_df[d_cols] = t_df[d_cols].fillna(value=False, axis=1)

                # deal with novelties
                t_df_cols = t_df.columns.tolist()
                if &#39;novelty&#39; in t_df_cols or &#39;novelty_a&#39; in t_df_cols:
                        t_df = self.merge_t_df_novelties(t_df)

                # set up index again
                t_df = create_dupe_index(t_df, &#39;tid&#39;)
                t_df = set_dupe_index(t_df, &#39;tid&#39;)

                self.t_df = t_df

        def merge_t_df_novelties(self, t_df):

                # merged dfs with and without novelty
                if &#39;novelty&#39; in t_df.columns.tolist():
                        t_df.fillna(value={&#39;novelty&#39;: &#39;Undefined&#39;},
                                inplace=True)

                # merged dfs where both have novelty types
                elif &#39;novelty_a&#39; in t_df.columns.tolist():

                        # if we already have any undefined entries, fill with nan
                        t_df.replace({&#39;novelty_a&#39;: {&#39;Undefined&#39;: np.nan},
                                                  &#39;novelty_b&#39;: {&#39;Undefined&#39;: np.nan}}, 
                                                  inplace=True)

                        # first take values that are only present in one dataset
                        t_df[&#39;novelty_a&#39;].fillna(t_df[&#39;novelty_b&#39;], inplace=True)
                        t_df[&#39;novelty_b&#39;].fillna(t_df[&#39;novelty_a&#39;], inplace=True)
                        a = t_df[[&#39;tid&#39;, &#39;novelty_a&#39;]].copy(deep=True)
                        a.rename({&#39;novelty_a&#39;: &#39;novelty&#39;}, axis=1, inplace=True)
                        a.reset_index(drop=True, inplace=True)
                        b = t_df[[&#39;tid&#39;, &#39;novelty_b&#39;]].copy(deep=True)
                        b.rename({&#39;novelty_b&#39;: &#39;novelty&#39;}, axis=1, inplace=True)
                        b.reset_index(drop=True, inplace=True)

                        # merge novelties on tid and novelty, then extract
                        # transcript ids that are duplicated, which represent
                        # those that have conflicting novelty assignments
                        nov = a.merge(b, on=[&#39;tid&#39;, &#39;novelty&#39;], how=&#39;outer&#39;)
                        amb_tids = nov[nov.tid.duplicated()].tid.tolist()

                        # label conflicting transcripts as Ambiguous
                        if amb_tids:
                                print(&#39;Novelty types between datasets conflict. Strongly &#39;
                                          &#39;consider using input from the same data source to &#39;
                                          &#39;reconcile these. Conflicting isoforms will be &#39;
                                          &#39;labelled &#34;Ambiguous&#34;.&#39;)
                                nov.set_index(&#39;tid&#39;, inplace=True)
                                nov.loc[amb_tids, &#39;novelty&#39;] = &#39;Ambiguous&#39;
                                nov.reset_index(inplace=True)
                                nov.drop_duplicates(inplace=True)

                        # finally, merge new novelty types into t_df
                        t_df.drop([&#39;novelty_a&#39;, &#39;novelty_b&#39;], axis=1, inplace=True)
                        t_df = t_df.merge(nov, on=&#39;tid&#39;)

                return t_df


        # merge edge_dfs on edge_id, v1, v2, strand, edge_type
        def merge_edge_dfs(self, b, b_col):

                # some df reformatting
                self.edge_df.reset_index(drop=True, inplace=True)
                b.edge_df.reset_index(drop=True, inplace=True)
                b.edge_df[b_col] = True

                # merge on edge info
                edge_df = self.edge_df.merge(b.edge_df,
                                  how=&#39;outer&#39;,
                                  on=[&#39;edge_id&#39;, &#39;v1&#39;, &#39;v2&#39;, &#39;edge_type&#39;, &#39;strand&#39;],
                                  suffixes=[&#39;_a&#39;, &#39;_b&#39;])

                # assign False to entries that are not in the new dataset, 
                # and to new entries that were not in the prior datasets
                d_cols = self.datasets+[b_col]
                edge_df[d_cols] = edge_df[d_cols].fillna(value=False, axis=1)

                # remake index
                edge_df = create_dupe_index(edge_df, &#39;edge_id&#39;)
                edge_df = set_dupe_index(edge_df, &#39;edge_id&#39;)
                
                self.edge_df = edge_df

        # merge loc_dfs on coord, chrom, strand
        def merge_loc_dfs(self, b, b_col):

                # some df reformatting
                node_types = [&#39;TSS&#39;, &#39;TES&#39;, &#39;internal&#39;]

                self.loc_df.drop(node_types, axis=1, inplace=True)
                self.loc_df.reset_index(drop=True, inplace=True)

                # b.loc_df.drop(node_types, axis=1, inplace=True)
                b.loc_df.reset_index(drop=True, inplace=True)
                b.loc_df[b_col] = True

                # merge on location info
                loc_df = self.loc_df.merge(b.loc_df,
                                 how=&#39;outer&#39;,
                                 on=[&#39;chrom&#39;, &#39;coord&#39;, &#39;strand&#39;],
                                 suffixes=[&#39;_a&#39;,&#39;_b&#39;])

                # assign False to entries that are not in the new dataset, 
                # and to new entries that were not in prior datasets
                d_cols = self.datasets+[b_col]
                loc_df[d_cols] = loc_df[d_cols].fillna(value=False, axis=1)

                self.loc_df = loc_df

        # returns a dictionary mapping vertex b: vertex a for each
        # vertex in dataset b
        def get_merged_id_map(self):

                id_map = list(zip(self.loc_df.vertex_id_b,
                                                  self.loc_df.vertex_id_a))
                id_map = [list(i) for i in id_map]

                # loop through id_map and assign new ids for 
                # those present in b but not a
                b_ind = int(self.loc_df.vertex_id_a.max() + 1)
                i = 0
                while i &lt; len(id_map):
                        if math.isnan(id_map[i][1]):
                                id_map[i][1] = b_ind
                                b_ind += 1
                        # set up entries where there isn&#39;t a b id (entries only found in a)
                        # to be removed
                        elif math.isnan(id_map[i][0]):
                                id_map[i] = []
                        i += 1

                # remove entries that are only in a but not in b
                # make sure everything is ints
                id_map = [i for i in id_map if len(i) == 2]
                id_map = dict([(int(a), int(b)) for a,b in id_map])

                return id_map

        ##########################################################################
        ############# Related to creating dfs from GTF or TALON DB ###############
        ##########################################################################

        # create loc_df (nodes), edge_df (edges), and t_df (transcripts) from gtf
        # adapted from Dana Wyman and TALON
        def create_dfs_gtf(self, gtf_file):

                # make sure file exists
                check_file_loc(gtf_file, &#39;GTF&#39;)

                # dictionaries to hold unique edges and transcripts
                transcripts = {}
                exons = {}

                with open(gtf_file) as gtf:
                        for line in gtf:

                                # ignore header lines
                                if line.startswith(&#39;#&#39;):
                                        continue

                                # split each entry
                                line = line.strip().split(&#39;\t&#39;)

                                # get some fields from gtf that we care about
                                chrom = line[0]
                                entry_type = line[2]
                                start = int(line[3])
                                stop = int(line[4])
                                strand = line[6]
                                fields = line[-1]

                                # transcript entry 
                                if entry_type == &#34;transcript&#34;:
                                        attributes = get_fields(fields)

                                        # check if this gtf has transcript novelty vals
                                        # for the first transcript entry
                                        if not transcripts:
                                                if &#39;talon_transcript&#39; in attributes:
                                                        from_talon = True
                                                else:
                                                        from_talon = False

                                        tid = attributes[&#39;transcript_id&#39;]
                                        gid = attributes[&#39;gene_id&#39;]
                                        gname = attributes[&#39;gene_name&#39;]

                                        # add transcript to dictionary 
                                        entry = {&#39;gid&#39;: gid,
                                                         &#39;gname&#39;: gname,
                                                         &#39;tid&#39;: tid,
                                                         &#39;strand&#39;: strand,
                                                         &#39;exons&#39;: []}

                                        # if we&#39;re using a talon gtf, add a novelty field
                                        if from_talon:
                                                novelty = get_transcript_novelties(attributes)
                                                entry[&#39;novelty&#39;] = novelty

                                        transcript = {tid: entry}
                                        transcripts.update(transcript)
                                        
                                # exon entry
                                elif entry_type == &#34;exon&#34;:
                                        attributes = get_fields(fields)
                                        start, stop = find_edge_start_stop(start, stop, strand)
                                        eid = &#39;{}_{}_{}_{}_exon&#39;.format(chrom, start, stop, strand)
                                        tid = attributes[&#39;transcript_id&#39;]       

                                        # add novel exon to dictionary 
                                        if eid not in exons:
                                                edge = {eid: {&#39;eid&#39;: eid,
                                                                          &#39;chrom&#39;: chrom,
                                                                          &#39;v1&#39;: start,
                                                                          &#39;v2&#39;: stop,
                                                                          &#39;strand&#39;: strand}}
                                                exons.update(edge)
                           
                                        # add this exon to the transcript&#39;s list of exons
                                        if tid in transcripts:
                                                transcripts[tid][&#39;exons&#39;].append(eid)

                # once we have all transcripts, make loc_df
                locs = {}
                vertex_id = 0
                for edge_id, edge in exons.items():
                        chrom = edge[&#39;chrom&#39;]
                        strand = edge[&#39;strand&#39;]

                        v1 = edge[&#39;v1&#39;]
                        v2 = edge[&#39;v2&#39;]

                        # exon start
                        key = (chrom, v1, strand)
                        if key not in locs:
                                locs[key] = vertex_id
                                vertex_id += 1
                        # exon end
                        key = (chrom, v2, strand)
                        if key not in locs:
                                locs[key] = vertex_id
                                vertex_id += 1

                # add locs-indexed path to transcripts, and populate edges
                edges = {}
                for _,t in transcripts.items():
                        t[&#39;path&#39;] = []
                        strand = t[&#39;strand&#39;]
                        t_exons = t[&#39;exons&#39;]

                        for i, exon_id in enumerate(t_exons):

                                # pull some information from exon dict
                                exon = exons[exon_id]
                                chrom = exon[&#39;chrom&#39;]
                                v1 = exon[&#39;v1&#39;]
                                v2 = exon[&#39;v2&#39;]
                                strand = exon[&#39;strand&#39;]

                                # add current exon and subsequent intron 
                                # (if not the last exon) for each exon to edges
                                key = (chrom, v1, v2, strand)
                                v1_key = (chrom, v1, strand)
                                v2_key = (chrom, v2, strand)
                                edge_id = (locs[v1_key], locs[v2_key])
                                if key not in edges:
                                        edges[key] = {&#39;edge_id&#39;: edge_id, &#39;edge_type&#39;: &#39;exon&#39;}

                                # add exon locs to path
                                t[&#39;path&#39;] += list(edge_id)

                                # if this isn&#39;t the last exon, we also needa add an intron
                                # this consists of v2 of the prev exon and v1 of the next exon
                                if i &lt; len(t_exons)-1:
                                        next_exon = exons[t_exons[i+1]]
                                        v1 = next_exon[&#39;v1&#39;]
                                        key = (chrom, v2, v1, strand)
                                        v1_key = (chrom, v1, strand)
                                        edge_id = (locs[v2_key], locs[v1_key])
                                        if key not in edges:
                                                edges[key] = {&#39;edge_id&#39;: edge_id, &#39;edge_type&#39;: &#39;intron&#39;}

                # turn transcripts, edges, and locs into dataframes
                locs = [{&#39;chrom&#39;: key[0],
                                 &#39;coord&#39;: key[1],
                                 &#39;strand&#39;: key[2],
                                 &#39;vertex_id&#39;: vertex_id} for key, vertex_id in locs.items()]
                loc_df = pd.DataFrame(locs)

                edges = [{&#39;v1&#39;: item[&#39;edge_id&#39;][0],
                                  &#39;v2&#39;: item[&#39;edge_id&#39;][1], 
                                  &#39;strand&#39;: key[3],
                                  &#39;edge_id&#39;: item[&#39;edge_id&#39;],
                                  &#39;edge_type&#39;: item[&#39;edge_type&#39;]} for key, item in edges.items()]
                edge_df = pd.DataFrame(edges)

                if from_talon:
                        transcripts = [{&#39;tid&#39;: key,
                                                &#39;gid&#39;: item[&#39;gid&#39;],
                                                &#39;gname&#39;: item[&#39;gname&#39;],
                                                &#39;path&#39;: item[&#39;path&#39;],
                                                &#39;novelty&#39;: item[&#39;novelty&#39;]} for key, item in transcripts.items()]
                else:
                        transcripts = [{&#39;tid&#39;: key,
                                                &#39;gid&#39;: item[&#39;gid&#39;],
                                                &#39;gname&#39;: item[&#39;gname&#39;],
                                                &#39;path&#39;: item[&#39;path&#39;]} for key, item in transcripts.items()]

                t_df = pd.DataFrame(transcripts)

                # final df formatting
                loc_df = create_dupe_index(loc_df, &#39;vertex_id&#39;)
                loc_df = set_dupe_index(loc_df, &#39;vertex_id&#39;)
                edge_df = create_dupe_index(edge_df, &#39;edge_id&#39;)
                edge_df = set_dupe_index(edge_df, &#39;edge_id&#39;)
                t_df = create_dupe_index(t_df, &#39;tid&#39;)
                t_df = set_dupe_index(t_df, &#39;tid&#39;)

                self.loc_df = loc_df
                self.edge_df = edge_df
                self.t_df = t_df

        # create SwanGraph dataframes from a TALON db. Code very ripped from 
        # TALON&#39;s create_GTF utility
        def create_dfs_db(self, database, annot, whitelist, dataset):

                # make sure file exists
                check_file_loc(database, &#39;TALON DB&#39;)

                annot = check_annot_validity(annot, database)

                whitelist = handle_filtering(database, 
                                                                                        annot, 
                                                                                        True, 
                                                                                        whitelist, 
                                                                                        dataset)
                # create separate gene and transcript whitelists
                gene_whitelist = []
                transcript_whitelist = []
                for key,group in itertools.groupby(whitelist,operator.itemgetter(0)):
                        gene_whitelist.append(key)
                        for id_tuple in list(group):
                                transcript_whitelist.append(id_tuple[1])

                # get gene, transcript, and exon annotations
                gene_annotations = get_annotations(database, &#34;gene&#34;, annot, 
                                                                                   whitelist = gene_whitelist)  
                transcript_annotations = get_annotations(database, &#34;transcript&#34;, annot,
                                                                                                 whitelist = transcript_whitelist) 
                exon_annotations = get_annotations(database, &#34;exon&#34;, annot)

                # get transcript data from the database
                gene_2_transcripts = get_gene_2_transcripts(database, 
                                                         transcript_whitelist)

                # get exon location info from database
                exon_ID_2_location = fetch_exon_locations(database)

                transcripts = {}
                exons = {}

                # loop through genes, transcripts, and exons
                for gene_ID, transcript_tuples in gene_2_transcripts.items():
                        curr_annot = gene_annotations[gene_ID]
                        gene_annotation_dict = {}
                        for annot in curr_annot:
                                attribute = annot[3]
                                value = annot[4]
                                gene_annotation_dict[attribute] = value
                
                        # get transcript entries
                        for transcript_entry in transcript_tuples:
                                transcript_ID = transcript_entry[&#34;transcript_ID&#34;]
                                curr_transcript_annot = transcript_annotations[transcript_ID]

                                transcript_annotation_dict = {}
                                for annot in curr_transcript_annot:
                                        attribute = annot[3]
                                        value = annot[4]
                                        transcript_annotation_dict[attribute] = value
                  
                                tid = transcript_annotation_dict[&#39;transcript_id&#39;]
                                gid = gene_annotation_dict[&#39;gene_id&#39;]  
                                gname = gene_annotation_dict[&#39;gene_name&#39;]
                                strand = transcript_entry[&#39;strand&#39;] 
                                novelty = get_transcript_novelties(transcript_annotation_dict)  

                                # add transcript to dictionary 
                                entry = {&#39;gid&#39;: gid,
                                                 &#39;gname&#39;: gname,
                                                 &#39;tid&#39;: tid,
                                                 &#39;strand&#39;: strand,
                                                 &#39;novelty&#39;: novelty,
                                                 &#39;exons&#39;: []}
                                transcript = {tid: entry}
                                transcripts.update(transcript)
                                                 
                                if transcript_entry[&#34;n_exons&#34;] != 1:
                                        transcript_edges = [str(transcript_entry[&#34;start_exon&#34;])] + \
                                                                           str(transcript_entry[&#34;jn_path&#34;]).split(&#34;,&#34;)+ \
                                                                           [str(transcript_entry[&#34;end_exon&#34;])]
                                else:
                                        transcript_edges = [transcript_entry[&#34;start_exon&#34;]]

                                # get exon entries
                                for exon_ID in transcript_edges[::2]:
                                        exon_ID = int(exon_ID)
                                        curr_exon_annot = exon_annotations[exon_ID]

                                        exon_annotation_dict = {}
                                        for annot in curr_exon_annot:
                                                attribute = annot[3]
                                                value = annot[4]
                                                exon_annotation_dict[attribute] = value

                                        e_tuple = exon_ID_2_location[exon_ID]
                                        chrom = e_tuple[0]
                                        start = e_tuple[1]
                                        stop = e_tuple[2]
                                        strand = e_tuple[3]
                                        start, stop = find_edge_start_stop(start, stop, strand)
                                        eid = &#39;{}_{}_{}_{}_exon&#39;.format(chrom, start, stop, strand)

                                        # add novel exon to dictionary 
                                        if eid not in exons:
                                                edge = {eid: {&#39;eid&#39;: eid,
                                                                          &#39;chrom&#39;: chrom,
                                                                          &#39;v1&#39;: start,
                                                                          &#39;v2&#39;: stop,
                                                                          &#39;strand&#39;: strand}}
                                                exons.update(edge) 

                                        # add this exon to the transcript&#39;s list of exons
                                        if tid in transcripts:
                                                transcripts[tid][&#39;exons&#39;].append(eid)

                # once we have all transcripts, make loc_df
                locs = {}
                vertex_id = 0
                for edge_id, edge in exons.items():
                        chrom = edge[&#39;chrom&#39;]
                        strand = edge[&#39;strand&#39;]

                        v1 = edge[&#39;v1&#39;]
                        v2 = edge[&#39;v2&#39;]

                        # exon start
                        key = (chrom, v1, strand)
                        if key not in locs:
                                locs[key] = vertex_id
                                vertex_id += 1
                        # exon end
                        key = (chrom, v2, strand)
                        if key not in locs:
                                locs[key] = vertex_id
                                vertex_id += 1

                # add locs-indexed path to transcripts, and populate edges
                edges = {}
                # print(dict(list(transcripts.items())[:3]))
                for _,t in transcripts.items():
                        t[&#39;path&#39;] = []
                        strand = t[&#39;strand&#39;]
                        t_exons = t[&#39;exons&#39;]

                        for i, exon_id in enumerate(t_exons):
                                # print(&#39;shouldnt u be in here&#39;)
                                # exit()

                                # pull some information from exon dict
                                exon = exons[exon_id]
                                chrom = exon[&#39;chrom&#39;]
                                v1 = exon[&#39;v1&#39;]
                                v2 = exon[&#39;v2&#39;]
                                strand = exon[&#39;strand&#39;]

                                # add current exon and subsequent intron 
                                # (if not the last exon) for each exon to edges
                                key = (chrom, v1, v2, strand)
                                v1_key = (chrom, v1, strand)
                                v2_key = (chrom, v2, strand)
                                edge_id = (locs[v1_key], locs[v2_key])
                                if key not in edges:
                                        edges[key] = {&#39;edge_id&#39;: edge_id, &#39;edge_type&#39;: &#39;exon&#39;}

                                # add exon locs to path
                                t[&#39;path&#39;] += list(edge_id)

                                # if this isn&#39;t the last exon, we also needa add an intron
                                # this consists of v2 of the prev exon and v1 of the next exon
                                if i &lt; len(t_exons)-1:
                                        next_exon = exons[t_exons[i+1]]
                                        v1 = next_exon[&#39;v1&#39;]
                                        key = (chrom, v2, v1, strand)
                                        v1_key = (chrom, v1, strand)
                                        edge_id = (locs[v2_key], locs[v1_key])
                                        if key not in edges:
                                                edges[key] = {&#39;edge_id&#39;: edge_id, &#39;edge_type&#39;: &#39;intron&#39;}

                # turn transcripts, edges, and locs into dataframes
                locs = [{&#39;chrom&#39;: key[0],
                                 &#39;coord&#39;: key[1],
                                 &#39;strand&#39;: key[2],
                                 &#39;vertex_id&#39;: vertex_id} for key, vertex_id in locs.items()]
                loc_df = pd.DataFrame(locs)

                edges = [{&#39;v1&#39;: item[&#39;edge_id&#39;][0],
                                  &#39;v2&#39;: item[&#39;edge_id&#39;][1], 
                                  &#39;strand&#39;: key[3],
                                  &#39;edge_id&#39;: item[&#39;edge_id&#39;],
                                  &#39;edge_type&#39;: item[&#39;edge_type&#39;]} for key, item in edges.items()]
                edge_df = pd.DataFrame(edges)

                transcripts = [{&#39;tid&#39;: key,
                                        &#39;gid&#39;: item[&#39;gid&#39;],
                                        &#39;gname&#39;: item[&#39;gname&#39;],
                                        &#39;path&#39;: item[&#39;path&#39;],
                                        &#39;novelty&#39;: item[&#39;novelty&#39;]} for key, item in transcripts.items()]

                t_df = pd.DataFrame(transcripts)        

                # final df formatting
                loc_df = create_dupe_index(loc_df, &#39;vertex_id&#39;)
                loc_df = set_dupe_index(loc_df, &#39;vertex_id&#39;)
                edge_df = create_dupe_index(edge_df, &#39;edge_id&#39;)
                edge_df = set_dupe_index(edge_df, &#39;edge_id&#39;)
                t_df = create_dupe_index(t_df, &#39;tid&#39;)
                t_df = set_dupe_index(t_df, &#39;tid&#39;)

                self.loc_df = loc_df
                self.edge_df = edge_df
                self.t_df = t_df

        # add node types (internal, TSS, TES) to loc_df
        def get_loc_types(self):

                self.loc_df[&#39;internal&#39;] = False
                self.loc_df[&#39;TSS&#39;] = False
                self.loc_df[&#39;TES&#39;] = False

                # get lists of locations that are used as TSS, TES
                paths = self.t_df.path.tolist()
                internal = list(set([n for path in paths for n in path[1:-1]]))
                tss = [path[0] for path in paths]
                tes = [path[-1] for path in paths]

                # set node types in t_df
                self.loc_df.loc[internal, &#39;internal&#39;] = True
                self.loc_df.loc[tss, &#39;TSS&#39;] = True
                self.loc_df.loc[tes, &#39;TES&#39;] = True

        ##########################################################################
        ######################## Other SwanGraph utilities #####################
        ##########################################################################

        # order the transcripts by expression of transcript, transcript id, 
        # or start/end nodes
        def order_transcripts(self, order=&#39;tid&#39;):

                # order by transcript id
                if order == &#39;tid&#39;:
                        ordered_tids = sorted(self.t_df.tid.tolist())
                        self.t_df = self.t_df.loc[ordered_tids]

                # order by expression
                elif order == &#39;expression&#39;:
                        tpm_cols = self.get_tpm_cols()

                        # make sure there are counts in the graph at all
                        if tpm_cols:
                                self.t_df[&#39;tpm_sum&#39;] = self.t_df[tpm_cols].sum(axis=1)
                                self.t_df.sort_values(by=&#39;tpm_sum&#39;, 
                                                                          ascending=False, 
                                                                          inplace=True)
                                self.t_df.drop(&#39;tpm_sum&#39;, axis=1, inplace=True)
                        else: 
                                raise Exception(&#39;Cannot order by expression because &#39;
                                                                &#39;there is no expression data.&#39;)

                # order by coordinate of tss in PlottedGraph
                elif order == &#39;tss&#39;:
                        self.t_df[&#39;start_coord&#39;] = self.t_df.apply(lambda x: 
                                self.loc_df.loc[x.path[0], &#39;coord&#39;], axis=1)

                        # watch out for strandedness
                        if self.loc_df.loc[self.loc_df.index[0], &#39;strand&#39;] == &#39;-&#39;:
                                ascending = False
                        else: 
                                ascending = True
                        self.t_df.sort_values(by=&#39;start_coord&#39;,
                                                                  ascending=ascending,
                                                                  inplace=True)
                        self.t_df.drop(&#39;start_coord&#39;, axis=1, inplace=True)
                        
                # order by coordinate of tes
                elif order == &#39;tes&#39;:
                        self.t_df[&#39;end_coord&#39;] = self.t_df.apply(lambda x: 
                                self.loc_df.loc[x.path[-1], &#39;coord&#39;], axis=1)

                        # watch out for strandedness
                        if self.loc_df.loc[self.loc_df.index[0], &#39;strand&#39;] == &#39;-&#39;:
                                ascending = False
                        else: 
                                ascending = True
                        self.t_df.sort_values(by=&#39;end_coord&#39;,
                                                                  ascending=ascending,
                                                                  inplace=True)
                        self.t_df.drop(&#39;end_coord&#39;, axis=1, inplace=True)

        ##########################################################################
        ######################## Finding &#34;interesting&#34; genes #####################
        ##########################################################################

        # returns a list of genes that are &#34;interesting&#34;
        def find_genes_with_novel_isoforms(self):

                # get all the datasets, make sure we&#39;re not counting transcripts 
                # that are only in the annotation
                if &#39;annotation&#39; not in self.datasets:
                        raise Exception(&#39;No annotation data in graph. Cannot &#39;,
                                &#39;determine isoform novelty.&#39;)
                datasets = self.get_dataset_cols(include_annotation=False)
                t_df = self.t_df.copy(deep=True)
                t_df = t_df.loc[t_df[datasets].any(axis=1)]

                # how many known and novel isoforms does each gene have
                t_df[&#39;known&#39;] = t_df.annotation
                t_df[&#39;novel&#39;] = [not i for i in t_df.annotation.tolist()]
                keep_cols = [&#39;annotation&#39;, &#39;known&#39;, &#39;novel&#39;, &#39;gid&#39;]
                g_df = t_df[keep_cols].groupby([&#39;gid&#39;]).sum()

                # create &#39;interestingness&#39; column ranking how many novel 
                # compared to known isoforms there are, also ranked by 
                # number of total isoforms
                g_df.known = g_df.known.astype(&#39;int32&#39;)
                g_df.novel = g_df.novel.astype(&#39;int32&#39;)
                g_df[&#39;interestingness&#39;] = ((g_df.novel+1)/(g_df.known+1))*(g_df.known+g_df.novel)
                g_df.sort_values(by=&#39;interestingness&#39;, ascending=False, inplace=True)

                # top 10 in case the user doesn&#39;t care about whole df
                genes = g_df.index.tolist()[:10]

                return genes, g_df

        # find genes with higher expression in novel than known isoforms
        def find_genes_with_high_novel_expression(self):
                
                # get all the datasets, make sure we&#39;re not counting transcripts 
                # that are only in the annotation
                if &#39;annotation&#39; not in self.datasets:
                        raise Exception(&#39;No annotation data in graph. Cannot &#39;,
                                &#39;determine isoform novelty.&#39;)
                datasets = self.get_dataset_cols(include_annotation=False)
                t_df = self.t_df.copy(deep=True)
                t_df = t_df.loc[t_df[datasets].any(axis=1)]

                # how much expression do known and novel isoforms have?
                t_df[&#39;known&#39;] = t_df.annotation
                tpm_cols = self.get_tpm_cols()
                keep_cols = tpm_cols+[&#39;known&#39;, &#39;gid&#39;]
                g_df = t_df[keep_cols].groupby([&#39;gid&#39;, &#39;known&#39;]).sum()
                g_df.reset_index(inplace=True)
                g_df[&#39;total_known_exp&#39;] = 0
                g_df[&#39;total_novel_exp&#39;] = 0
                g_df.loc[g_df.known == True, &#39;total_known_exp&#39;] = g_df.loc[g_df.known == True, tpm_cols].sum(axis=1) 
                g_df.loc[g_df.known == False, &#39;total_novel_exp&#39;] = g_df.loc[g_df.known == False, tpm_cols].sum(axis=1) 
                keep_cols = tpm_cols+[&#39;total_known_exp&#39;, &#39;total_novel_exp&#39;, &#39;gid&#39;]
                g_df = g_df[keep_cols].groupby(&#39;gid&#39;).sum()

                # create &#39;interestingness&#39; column ranking how much expression
                # of the gene is attributable to novel isoforms versus known isoforms
                g_df[&#39;interestingness&#39;] = ((g_df.total_novel_exp+1)/(g_df.total_known_exp+1))*np.log2(g_df.total_known_exp+1+g_df.total_novel_exp+1)
                g_df.sort_values(by=&#39;interestingness&#39;, ascending=False, inplace=True)

                # top 10 in case the user doesn&#39;t care about whole df
                genes = g_df.index.tolist()[:10]

                return genes, g_df

        def find_ir_genes(self):
                &#34;&#34;&#34;
                Finds all unique genes containing novel intron retention events. 
                Requires that an annotation has been added to the SwanGraph.

                        Returns:

                                ir_genes (list of str): A list of gene ids from the SwanGraph with 
                                        at least one novel intron retention event
                &#34;&#34;&#34;

                # get only novel edges
                if &#39;annotation&#39; not in self.edge_df.columns:
                        raise Exception(&#39;Cannot find novel IR events without &#39;
                                &#39;annotation in SwanGraph.&#39;)

                edge_ids = self.edge_df.loc[ \
                        (self.edge_df.annotation == False)&amp; \
                        (self.edge_df.edge_type == &#39;exon&#39;), &#39;edge_id&#39;]
                print(&#39;Analyzing {} exonic edges for IR&#39;.format(len(edge_ids)))

                # get subset of transcripts that are novel to look for ir edges in
                nt_df = self.t_df.loc[self.t_df.annotation == False]
                
                # for each edge, see if the subgraph between the edge vertices 
                # contains an exonic edge  
                ir_genes = []
                for i, eid in enumerate(edge_ids):
                        sub_nodes = [i for i in range(eid[0]+1,eid[1])]
                        sub_G = self.G.subgraph(sub_nodes)
                        sub_edges = list(sub_G.edges())
                        sub_edges = self.edge_df.loc[sub_edges]
                        sub_edges = sub_edges.loc[sub_edges.edge_type == &#39;intron&#39;]

                        if len(sub_edges.index) &gt; 0:

                                # transcripts that contain the exon-skipping edge
                                cand_t_df = nt_df[[eid in vertex_to_edge_path(x) \
                                        for x in nt_df.path.values.tolist()]]

                                # circumvent the ISM bug
                                if len(cand_t_df) == 0:
                                        continue

                                # does at least one of the retained introns belong
                                # to the same gene as the retaining edge?
                                else:
                                        # genes that contain the intron-retaining edge edge
                                        cand_genes = cand_t_df.gid.values.tolist()
                                        cand_g_df = self.t_df.loc[self.t_df.gid.isin(cand_genes)]

                                        # check if the retained edges are in one of the 
                                        # intron-retaining genes (wow this is confusing)
                                        for gid in cand_genes:
                                                if gid in ir_genes: continue
                                                for cand_eid in sub_edges.index:
                                                        temp_df = cand_g_df[[cand_eid in vertex_to_edge_path(x) \
                                                                        for x in cand_g_df.path.values.tolist()]]
                                                        if len(temp_df.index) &gt; 0:
                                                                ir_genes.append(gid)

                print(&#39;Found {} novel ir events from {} genes.&#39;.format(len(ir_genes), 
                        len(list(set(ir_genes)))))
                ir_genes = list(set(ir_genes))
                return ir_genes

        def find_es_genes(self):
                &#34;&#34;&#34;
                Finds all unique genes containing novel exon skipping events. 
                Requires that an annotation has been added to the SwanGraph.

                        Returns:

                                es_genes (list of str): A list of gene ids from the SwanGraph with 
                                        at least one novel exon skipping event
                &#34;&#34;&#34;

                # get only novel edges
                if &#39;annotation&#39; not in self.edge_df.columns:
                        raise Exception(&#39;Cannot find novel IR events without &#39;
                                &#39;annotation in SwanGraph.&#39;)

                edge_ids = self.edge_df.loc[ \
                        (self.edge_df.annotation == False)&amp; \
                        (self.edge_df.edge_type == &#39;intron&#39;), &#39;edge_id&#39;]
                print(&#39;Analyzing {} intronic edges for ES&#39;.format(len(edge_ids)))

                # get subset of transcripts that are novel to look for ir edges in
                nt_df = self.t_df.loc[self.t_df.annotation == False]

                # for each edge, see if the subgraph between the edge vertices 
                # contains an exonic edge
                es_genes = []
                for eid in edge_ids:
                        sub_nodes = [i for i in range(eid[0]+1,eid[1])]
                        sub_G = self.G.subgraph(sub_nodes)
                        sub_edges = list(sub_G.edges())
                        sub_edges = self.edge_df.loc[sub_edges]
                        sub_edges = sub_edges.loc[sub_edges.edge_type == &#39;exon&#39;]

                        if len(sub_edges.index) &gt; 0:

                                # transcripts that contain the exon-skipping edge
                                skip_t_df = nt_df[[eid in vertex_to_edge_path(x) \
                                        for x in nt_df.path.values.tolist()]]

                                # circumvent the ISM bug
                                if len(skip_t_df) == 0:
                                        continue

                                # does at least one of the skipped exons belong
                                # to the same gene as the skipping edge?
                                else:
                                        # genes that contain the exon-skipping edge
                                        skip_genes = skip_t_df.gid.values.tolist()
                                        skip_g_df = self.t_df.loc[self.t_df.gid.isin(skip_genes)]

                                        # check if the skipped edges are in one of the 
                                        # exon-skipping genes (wow this is confusing)
                                        for gid in skip_genes:
                                                if gid in es_genes: continue
                                                for skip_eid in sub_edges.index:
                                                        temp_df = skip_g_df[[skip_eid in vertex_to_edge_path(x) \
                                                                        for x in skip_g_df.path.values.tolist()]]
                                                        if len(temp_df.index) &gt; 0:
                                                                es_genes.append(gid)

                print(&#39;Found {} novel es events from {} genes.&#39;.format(len(es_genes),
                        len(list(set(es_genes)))))
                es_genes = list(set(es_genes))
                return es_genes

        def de_gene_test(self, dataset_groups):
                &#34;&#34;&#34; 
                Runs a differential expression test on the gene level.

                        Parameters:

                                dataset_groups (list of list of str, len 2): Grouping of datasets 
                                        from the SwanGraph to be used in the differential
                                        expression test
                                        Example: [[&#39;data1&#39;,&#39;data2&#39;],[&#39;data3&#39;,&#39;data4&#39;]]

                        Returns: 

                                test (pandas DataFrame): A summary table of the differential
                                        expression test, including p and q-values, as well 
                                        as log fold change.
                &#34;&#34;&#34;

                # format expression data to be used by diffxpy
                ann = self.create_gene_anndata(dataset_groups)

                # test
                test = de.test.wald(
                        data=ann,
                        formula_loc=&#34;~ 1 + condition&#34;,
                        factor_loc_totest=&#34;condition&#34;)
                test = test.summary()
                test.rename({&#39;gene&#39;: &#39;gid&#39;}, axis=1, inplace=True)


                # add gene name column
                gnames = self.t_df[[&#39;gid&#39;, &#39;gname&#39;]].copy(deep=True)
                gnames.reset_index(drop=True, inplace=True)
                test = test.merge(gnames, how=&#39;left&#39;, on=&#39;gid&#39;)
                test.drop_duplicates(inplace=True)

                # sort on log2fc
                test = test.reindex(test.log2fc.abs().sort_values(ascending=False).index)

                # assign the summary table to the parent object
                self.deg_test = test
                self.deg_test_groups = dataset_groups

                return test

        def get_de_genes(self, q=0.05, n_genes=None):
                &#34;&#34;&#34;
                Subsets the differential gene expression test summary table based
                on a q-value cutoff. Requires that de_gene_test has already been
                run.

                        Parameters:

                                q (float): q-value threshold to declare a gene as significant
                                        Default: 0.05
                                n_genes (int): Number of results to return. 
                                        Default: None (returns all found significant)

                        Returns:

                                genes (list of str): List of gene names that pass the 
                                        significance threshold
                                test (pandas DataFrame): Summary table of genes that pass the
                                        significance threshold
                &#34;&#34;&#34;

                # make sure we have the result of a deg test first!
                if self.deg_test.empty:
                        raise Exception(&#39;Cannot find DE genes without test results. &#39;
                                &#39;Run de_gene_test first.&#39;)

                # subset on q value 
                test = self.deg_test.loc[self.deg_test.qval &lt;= q].copy(deep=True)

                # list and the df of the top de genes according qval threshold
                if not n_genes:
                        genes = test.gname.tolist()
                else:
                        if n_genes &lt; len(test.index):
                                n_genes = len(test.index)
                                test = test.head(n_genes)
                                genes = test.gname.tolist()
                return genes, test

        def de_transcript_test(self, dataset_groups):
                &#34;&#34;&#34; 
                Runs a differential expression test on the transcript level.

                        Parameters:

                                dataset_groups (list of list of str, len 2): Grouping of datasets 
                                        from the SwanGraph to be used in the differential
                                        expression test
                                        Example: [[&#39;data1&#39;,&#39;data2&#39;],[&#39;data3&#39;,&#39;data4&#39;]]

                        Returns: 

                                test (pandas DataFrame): A summary table of the differential
                                        expression test, including p and q-values, as well 
                                        as log fold change.
                &#34;&#34;&#34;

                # format expression data to be used by diffxpy
                ann = self.create_transcript_anndata(dataset_groups)

                # test
                test = de.test.wald(
                        data=ann,
                        formula_loc=&#34;~ 1 + condition&#34;,
                        factor_loc_totest=&#34;condition&#34;)
                test = test.summary()
                test.rename({&#39;gene&#39;: &#39;tid&#39;}, axis=1, inplace=True)

                # add gene name column
                gnames = self.t_df[[&#39;tid&#39;, &#39;gid&#39;, &#39;gname&#39;]].copy(deep=True)
                gnames.reset_index(drop=True, inplace=True)
                test = test.merge(gnames, how=&#39;left&#39;, on=&#39;tid&#39;)

                # sort on log2fc
                test = test.reindex(test.log2fc.abs().sort_values(ascending=False).index)

                # assign the summary table to the parent object
                self.det_test = test
                self.det_test_groups = dataset_groups

                return test

        def get_de_transcripts(self, q=0.05, n_transcripts=None):
                &#34;&#34;&#34;
                Subsets the differential transcript expression test summary table based
                on a q-value cutoff. Requires that de_transcript_test has already been
                run.

                        Parameters:

                                q (float): q-value threshold to declare a transcript as significant
                                        Default: 0.05
                                n_transcripts (int): Number of results to return. 
                                        Default: None (returns all found significant)

                        Returns:

                                tids (list of str): List of transcript ids that pass the 
                                        significance threshold
                                test (pandas DataFrame): Summary table of transcripts that pass
                                        the significance threshold
                &#34;&#34;&#34;

                # make sure we have the result of a deg test first!
                if self.det_test.empty:
                        raise Exception(&#39;Cannot find DE transcripts without test results. &#39;
                                &#39;Run de_transcript_test first.&#39;)

                # subset on q value 
                test = self.det_test.loc[self.det_test.qval &lt;= q].copy(deep=True)

                # list and the df of the top de genes according qval threshold
                if not n_transcripts:
                        tids = test.tid.tolist()
                else:
                        if n_transcripts &lt; len(test.index):
                                n_transcripts = len(test.index)
                        n_transcripts = test.head(n_transcripts)
                        tids = test.transcript.tolist()
                return tids, test

        def find_isoform_switching_genes(self, q=0.05, n_genes=None):
                &#34;&#34;&#34; Finds isoform switching genes; genes that are not differentially
                        expressed but contain at least one transcript that is. Requires
                        that de_gene_test and de_transcript_test have been run.

                        Parameters:

                                q (float): q-value threshold to declare a gene/transcript 
                                        as significant
                                        Default: 0.05
                                n_genes (int): Number of results to return. 
                                        Default: None (returns all found significant)

                        Returns:

                                genes (list of str): List of gene names that were categorized
                                        as isoform switching
                                test (pandas DataFrame): Summary table of genes that were
                                        categorized as isoform switching
                &#34;&#34;&#34;

                # make sure both deg and det tests have been run
                if self.det_test.empty or self.deg_test.empty:
                        raise Exception(&#39;Cannot find isoform switches without test results. &#39;
                                &#39;Run de_gene_test and de_transcript_test first.&#39;)

                # subset for genes that aren&#39;t DE
                not_degs = self.deg_test.loc[self.deg_test.qval &gt; q]
                not_degs = not_degs.gid

                # subset for dets
                dets = self.det_test.loc[self.det_test.qval &lt;= q]

                # merge on gene id 
                switches = dets.merge(not_degs, how=&#39;inner&#39;, on=&#39;gid&#39;)

                # list and the df of the top de genes according qval threshold
                unique_genes = switches.gid.unique().tolist()
                if not n_genes:
                        genes = unique_genes
                else:
                        if n_genes &lt; len(unique_genes):
                                n_genes = len(unique_genes)
                        switches = switches.loc[switches.gid.isin(unique_genes[:n_genes])]
                        genes = unique_genes[:n_genes]
                return genes, switches

        def get_de_and_not_de_transcripts(self, dataset_groups):
                ann = self.create_transcript_anndata(dataset_groups)
                results = de.test.wald(data=ann,
                        formula_loc=&#34;~ 1 + condition&#34;,
                        factor_loc_totest=&#34;condition&#34;)
                test = results.summary()
                test.rename({&#39;gene&#39;: &#39;transcript&#39;}, axis=1, inplace=True)

                gnames = self.t_df[[&#39;tid&#39;, &#39;gname&#39;]].copy(deep=True)
                gnames.reset_index(drop=True, inplace=True)
                test = test.merge(gnames, how=&#39;left&#39;, left_on=&#39;transcript&#39;, right_on=&#39;tid&#39;)
                test = test.reindex(test.log2fc.abs().sort_values(ascending=False).index)

                det = test.loc[test.qval &lt; 0.05]
                not_det = test.loc[test.qval &gt;= 0.05]
                genes_w_det = det.gname.tolist()
                not_det = not_det.loc[not_det.gname.isin(genes_w_det)]
                df = pd.concat([det, not_det])
                df = df.loc[df.gname.duplicated(keep=False)]

                return df

        # return an anndata object that can be used to perform different 
        # differential gene expression tests using the diffxpy module
        def create_gene_anndata(self, dataset_groups):

                # group t_df into gene df and sum up abundances
                # both across genes and across datasets
                t_df = self.t_df.copy(deep=True)
                dataset_cols = []
                all_dataset_cols = []
                for group in dataset_groups:
                        tpm_cols = self.get_tpm_cols(group)
                        dataset_cols.append(tpm_cols)
                        all_dataset_cols.extend(tpm_cols)

                keep_cols = all_dataset_cols+[&#39;gid&#39;]
                g_df = t_df[keep_cols].groupby(&#39;gid&#39;).sum()

                # add pseudocounts for each gene
                g_df[all_dataset_cols] = g_df[all_dataset_cols] + 1

                # create obs, var, and x entries for the anndata object
                ann_x = g_df.to_numpy().T 
                ann_var = pd.DataFrame(index=g_df.index)
                ann_obs = pd.DataFrame(columns=[&#39;batch&#39;],
                                                           data=all_dataset_cols)
                ann_obs[&#39;condition&#39;] = np.nan
                for i, group in enumerate(dataset_cols):
                        ann_obs.loc[ann_obs.batch.isin(group),  &#39;condition&#39;] = i
                ann = anndata.AnnData(X=ann_x, var=ann_var, obs=ann_obs)

                return ann

        # returns an anndata object that can be used to perform different 
        # differential transcript expression tests using diffxpy
        def create_transcript_anndata(self, dataset_groups):

                # group t_df into gene df and sum up abundances
                # both across genes and across datasets
                t_df = self.t_df.copy(deep=True)
                dataset_cols = []
                all_dataset_cols = []
                for group in dataset_groups:
                        tpm_cols = self.get_tpm_cols(group)
                        dataset_cols.append(tpm_cols)
                        all_dataset_cols.extend(tpm_cols)

                # add pseudocounts for each transcript
                t_df[all_dataset_cols] = t_df[all_dataset_cols] + 1

                # create obs, var, and x entries for the anndata object
                ann_x = t_df[all_dataset_cols].to_numpy().T 
                ann_var = pd.DataFrame(index=t_df.index)
                ann_obs = pd.DataFrame(columns=[&#39;batch&#39;],
                                                           data=all_dataset_cols)
                ann_obs[&#39;condition&#39;] = np.nan
                for i, group in enumerate(dataset_cols):
                        ann_obs.loc[ann_obs.batch.isin(group),  &#39;condition&#39;] = i
                ann = anndata.AnnData(X=ann_x, var=ann_var, obs=ann_obs)

                return ann

        ##########################################################################
        ######################## Loading/saving SwanGraphs #####################
        ##########################################################################

        def save_graph(self, prefix):
                &#34;&#34;&#34;
                Saves the current SwanGraph in pickle format with the .p extension

                        Parameters: 

                                prefix (str): Path and filename prefix. Resulting file will 
                                        be saved as prefix.p
                &#34;&#34;&#34;
                print(&#39;Saving graph as &#39;+prefix+&#39;.p&#39;)
                picklefile = open(prefix+&#39;.p&#39;, &#39;wb&#39;)
                pickle.dump(self, picklefile)
                picklefile.close()

        # loads a splice graph object from pickle form
        def load_graph(self, fname):

                picklefile = open(fname, &#39;rb&#39;)
                graph = pickle.load(picklefile)

                # assign SwanGraph fields from file to self
                self.loc_df = graph.loc_df
                self.edge_df = graph.edge_df
                self.t_df = graph.t_df
                self.datasets = graph.datasets
                self.counts = graph.counts
                self.tpm = graph.tpm
                self.pg = graph.pg
                self.G = graph.G

                self.deg_test = graph.deg_test
                self.deg_test_groups = graph.deg_test_groups
                self.det_test = graph.det_test
                self.det_test_groups = graph.det_test_groups

                picklefile.close()

                print(&#39;Graph from {} loaded&#39;.format(fname))

        ##########################################################################
        ############################ Plotting utilities ##########################
        ##########################################################################

        def plot_graph(self, gid,
                                   indicate_dataset=False,
                                   indicate_novel=False,
                                   prefix=None):
                &#34;&#34;&#34;
                Plots a gene summary SwanGraph for an input gene.
                Does not automatically save the figure by default!

                        Parameters:

                                gid (str): Gene ID to plot for (can also be gene name but 
                                        we&#39;ve seen non-unique gene names so use at your own risk!)
                                indicate_dataset (str): Dataset name from SwanGraph to
                                        highlight with outlined nodes and dashed edges
                                        Incompatible with indicate_novel
                                        Default: False (no highlighting)
                                indicate_novel (bool): Highlight novel nodes and edges by 
                                        outlining them and dashing them respectively
                                        Incompatible with indicate_dataset
                                        Default: False
                                prefix (str): Path and file prefix to automatically save
                                        the plotted figure
                                        Default: None, won&#39;t automatically save 
                &#34;&#34;&#34;

                if gid not in self.t_df.gid.tolist():
                        gid = self.get_gid_from_gname(gid)

                self.check_plotting_args(indicate_dataset, indicate_novel)
                self.check_gene(gid)

                # reinit PlottedGraph object and plot
                self.pg.init_plot_settings(self, gid=gid,
                        indicate_dataset=indicate_dataset, 
                        indicate_novel=indicate_novel)
                self.pg.plot_graph()

                # if the user has provided a place to save
                if prefix:
                        browser = False # can&#39;t plot browser for entire gene
                        fname = create_fname(prefix,
                                                                indicate_dataset,
                                                                indicate_novel,
                                                                browser,
                                                                ftype=&#39;summary&#39;,
                                                                gid=gid)
                        self.pg.plot_graph()
                        print(&#39;Saving summary graph for {} as {}&#39;.format(gid, fname))
                        save_fig(fname)

        def plot_transcript_path(self, tid,
                                                         indicate_dataset=False,
                                                         indicate_novel=False,
                                                         browser=False,
                                                         prefix=None):
                &#34;&#34;&#34;
                Plots a path of a single transcript isoform through a gene summary 
                SwanGraph.

                        Parameters:

                                tid (str): Transcript id of transcript to plot
                                indicate_dataset (str): Dataset name from SwanGraph to
                                        highlight with outlined nodes and dashed edges
                                        Incompatible with indicate_novel
                                        Default: False (no highlighting)
                                indicate_novel (bool): Highlight novel nodes and edges by 
                                        outlining them and dashing them respectively
                                        Incompatible with indicate_dataset
                                        Default: False
                                browser (bool): Plot transcript models in genome browser-
                                        style format. Incompatible with indicate_dataset and
                                        indicate_novel
                                prefix (str): Path and file prefix to automatically save
                                        the plotted figure
                                        Default: None, won&#39;t automatically save
                &#34;&#34;&#34;

                self.check_plotting_args(indicate_dataset, indicate_novel, browser)
                self.check_transcript(tid)

                # reinit PlottedGraph object and plot
                self.pg.init_plot_settings(self, tid=tid, 
                        indicate_dataset=indicate_dataset,
                        indicate_novel=indicate_novel,
                        browser=browser)
                self.pg.plot_graph()

                # if the user has provided a place to save
                if prefix:
                        fname = create_fname(prefix,
                                                                indicate_dataset,
                                                                indicate_novel,
                                                                browser,
                                                                ftype=&#39;path&#39;,
                                                                tid=tid)
                        self.pg.plot_graph()
                        print(&#39;Saving transcript path graph for {} as {}&#39;.format(tid, fname))
                        save_fig(fname)

        def plot_each_transcript(self, tids, prefix,
                                                indicate_dataset=False,
                                                indicate_novel=False,
                                                browser=False):
                &#34;&#34;&#34;
                Plot each input transcript and automatically save figures

                        Parameters:

                                tids (list of str): List of transcript ids to plot
                                prefix (str): Path and file prefix to automatically save
                                        the plotted figures
                                indicate_dataset (str): Dataset name from SwanGraph to
                                        highlight with outlined nodes and dashed edges
                                        Incompatible with indicate_novel
                                        Default: False (no highlighting)
                                indicate_novel (bool): Highlight novel nodes and edges by 
                                        outlining them and dashing them respectively
                                        Incompatible with indicate_dataset
                                        Default: False
                                browser (bool): Plot transcript models in genome browser-
                                        style format. Incompatible with indicate_dataset and
                                        indicate_novel
                &#34;&#34;&#34;

                self.check_plotting_args(indicate_dataset, indicate_novel, browser)

                # loop through each transcript in the SwanGraph object
                for tid in tids:
                        self.check_transcript(tid)

                for tid in tids:
                        self.pg.init_plot_settings(self, tid=tid,
                                indicate_dataset=indicate_dataset,
                                indicate_novel=indicate_novel,
                                browser=browser)
                        fname = create_fname(prefix,
                                                                 indicate_dataset,
                                                                 indicate_novel,
                                                                 browser,
                                                                 ftype=&#39;path&#39;,
                                                                 tid=tid)
                        self.pg.plot_graph()
                        print(&#39;Saving transcript path graph for {} as {}&#39;.format(tid, fname))
                        save_fig(fname)

        def plot_each_transcript_in_gene(self, gid, prefix,
                                                         indicate_dataset=False,
                                                         indicate_novel=False,
                                                         browser=False):
                &#34;&#34;&#34;
                Plot each transcript in a given gene and automatically save figures

                        Parameters:

                                gid (str): Gene id or gene name to plot transcripts from
                                prefix (str): Path and file prefix to automatically save
                                        the plotted figures
                                indicate_dataset (str): Dataset name from SwanGraph to
                                        highlight with outlined nodes and dashed edges
                                        Incompatible with indicate_novel
                                        Default: False (no highlighting)
                                indicate_novel (bool): Highlight novel nodes and edges by 
                                        outlining them and dashing them respectively
                                        Incompatible with indicate_dataset
                                        Default: False
                                browser (bool): Plot transcript models in genome browser-
                                        style format. Incompatible with indicate_dataset and
                                        indicate_novel
                &#34;&#34;&#34;

                if gid not in self.t_df.gid.tolist():
                        gid = self.get_gid_from_gname(gid)
                self.check_gene(gid)

                self.check_plotting_args(indicate_dataset, indicate_novel, browser)

                # loop through each transcript in the SwanGraph object
                tids = self.t_df.loc[self.t_df.gid == gid, &#39;tid&#39;].tolist()
                print()
                print(&#39;Plotting {} transcripts for {}&#39;.format(len(tids), gid))
                for tid in tids:
                        self.pg.init_plot_settings(self, tid=tid,
                                indicate_dataset=indicate_dataset,
                                indicate_novel=indicate_novel,
                                browser=browser)
                        fname = create_fname(prefix,
                                                                 indicate_dataset,
                                                                 indicate_novel,
                                                                 browser,
                                                                 ftype=&#39;path&#39;,
                                                                 tid=tid)
                        self.pg.plot_graph()
                        print(&#39;Saving transcript path graph for {} as {}&#39;.format(tid, fname))
                        save_fig(fname)

        ##########################################################################
        ############################### Report stuff #############################
        ##########################################################################
        # creates a report for each transcript model for a gene according to user input
        def gen_report(self,
                                   gids,
                                   prefix,
                                   datasets=&#39;all&#39;,
                                   dataset_groups=False,
                                   dataset_group_names=False,
                                   novelty=False,
                                   heatmap=False,
                                   tpm=False,
                                   include_qvals=False,
                                   q=0.05,
                                   include_unexpressed=False,
                                   indicate_dataset=False, 
                                   indicate_novel=False,
                                   browser=False,
                                   order=&#39;expression&#39;):
                &#34;&#34;&#34;
                Generates a PDF report for a given gene or list of genes according
                to the user&#39;s input.

                        Parameters: 

                                gids (str or list of str): Gene ids or names to generate
                                        reports for
                                prefix (str): Path and/or filename prefix to save PDF and
                                        images used to generate the PDF

                                datasets (list of str): Datasets to include in the report
                                        Default: Include columns for all datasets
                                dataset_groups (list of list of str): Datasets to average
                                        together in the report and display as one column
                                        Example: [[&#39;group1_1&#39;,&#39;group1_2&#39;],[&#39;group2_1&#39;,&#39;group2_2&#39;]]
                                dataset_group_names (list of str): Names to give each group 
                                        given by dataset_groups. Must be the same length as 
                                        dataset_groups
                                        Example: [&#39;group1&#39;, &#39;group2&#39;]
                                        Default: Will assign numbers 1 through length(dataset_group)

                                novelty (bool): Include a column to dipslay novelty type of
                                        each transcript. Requires that a TALON GTF or DB has 
                                        been used to load data in
                                        Default: False

                                heatmap (bool): Display expression values in a heatmap
                                        format. Requires that abundance information has been 
                                        added to the SwanGraph
                                        Default: False
                                tpm (bool): Display TPM value of each transcript/dataset 
                                        combination, instead of presence/absence of each 
                                        transcript. Requires that abundance information has
                                        been added to the SwanGraph
                                        Default:False

                                include_qvals (bool): Display q-val of each transcript&#39;s 
                                        differential expression and bold entries found to be
                                        differentially expressed. Requires that de_transcript_test
                                        has been run, and that abundance information has been
                                        added to the SwanGraph
                                        Default: False
                                q (float): Q-value significance threshold to use when 
                                        bolding transcripts if include_qvals = True.
                                        Default: 0.05

                                include_unexpressed (bool): Add transcript entries to report
                                        that are not expressed in any input dataset.
                                        Default: False

                                indicate_dataset (str): Dataset name from SwanGraph to
                                        highlight with outlined nodes and dashed edges
                                        Incompatible with indicate_novel
                                        Default: False (no highlighting)
                                indicate_novel (bool): Highlight novel nodes and edges by 
                                        outlining them and dashing them respectively
                                        Incompatible with indicate_dataset
                                        Default: False
                                browser (bool): Plot transcript models in genome browser-
                                        style format. Incompatible with indicate_dataset and
                                        indicate_novel

                                order (str): Order to display transcripts in the report.
                                        Options are 
                                                &#39;tid&#39;: alphabetically by transcript ID
                                                &#39;expression&#39;: cumulative expression from high to low
                                                        Requires that abundance information has been 
                                                        added to the SwanGraph
                                                &#39;tss&#39;: genomic coordinate of transcription start site
                                                &#39;tes&#39;: genomic coordinate of transcription end site
                                        Default: &#39;expression&#39; if abundance information is present,
                                                         &#39;tid&#39; if not
                &#34;&#34;&#34;

                # check to see if input genes are in the graph
                if type(gids) != list:
                        gids = [gids]
                for i, gid in enumerate(gids):
                        if gid not in self.t_df.gid.tolist():
                                gid = self.get_gid_from_gname(gid)
                                gids[i] = gid
                        self.check_gene(gid)

                # check to see if these plotting settings will play together
                self.check_plotting_args(indicate_dataset,
                        indicate_novel, browser)

                # make sure all input datasets are present in graph
                if datasets == &#39;all&#39;:
                        datasets = self.get_dataset_cols(include_annotation=False)
                elif not datasets:
                        datasets = []
                else:
                        self.check_datasets(datasets)

                # if we have dataset groupings make sure that they are a subset
                # of the datasets already requested
                if dataset_groups:
                        if not datasets: 
                                raise Exception(&#39;Cannot group datasets as none were requested.&#39;)
                        else:
                                all_dgs = [j for i in dataset_groups for j in i]
                                self.check_datasets(all_dgs)

                                subsumed_datasets = [True if i in datasets else False for i in all_dgs]
                                if False in subsumed_datasets:
                                        bad_dataset = all_dgs[subsumed_datasets.index(False)]
                                        raise Exception(&#34;Grouping dataset {} not present in &#34; 
                                                &#34;datasets {}.&#34;.format(bad_dataset, datasets))

                # if we&#39;ve asked for novelty first check to make sure it&#39;s there
                if novelty:
                        if not self.has_novelty():
                                raise Exception(&#39;No novelty information present in the graph. &#39;
                                        &#39;Add it or do not use the &#34;novelty&#34; report option.&#39;)

                # check to make sure abundance data is there for the
                # query columns, if user is asking
                if tpm or heatmap:
                        self.check_abundances(datasets)

                # order transcripts by user&#39;s preferences 
                if order == &#39;expression&#39; and not self.get_count_cols():
                        order = &#39;tid&#39;
                self.order_transcripts(order)

                # subset t_df based on relevant tids and expression requirements
                t_df = self.t_df[self.t_df.gid.isin(gids)].copy(deep=True)

                # make sure de has been run if needed
                if include_qvals:
                        self.check_de(&#39;transcript&#39;)
                        de_df = self.det_test.copy(deep=True)
                        t_df = reset_dupe_index(t_df, &#39;tid&#39;)
                        t_df[&#39;significant&#39;] = False
                        t_df = t_df.merge(de_df[[&#39;tid&#39;, &#39;qval&#39;]], how=&#39;left&#39;, on=&#39;tid&#39;)
                        t_df[&#39;significant&#39;] = t_df.qval &lt;= q
                        t_df = set_dupe_index(t_df, &#39;tid&#39;)

                # if user doesn&#39;t care about datasets, just show all transcripts
                if not datasets:
                        include_unexpressed = True

                # user only wants transcript isoforms that appear in their data
                if not include_unexpressed:
                        counts_cols = self.get_count_cols(datasets)
                        t_df = t_df[t_df[counts_cols].sum(axis=1)&gt;0]

                # if we&#39;re grouping things switch up the datasets 
                # and how t_df is formatted
                if dataset_groups:

                        # no grouped dataset names were given - generate names
                        if not dataset_group_names:
                                print(&#39;No group names given. Will just use Group_#.&#39;)
                                dataset_group_names = [&#39;Group_{}&#39;.format(i) for i in range(len(dataset_groups))]

                        # check if we have the right number of group names
                        if len(dataset_groups) != len(dataset_group_names):
                                print(&#39;Not enough group names given. Will just use Group_#.&#39;)
                                dataset_group_names = [&#39;Group_{}&#39;.format(i) for i in range(len(dataset_groups))]

                        for i in range(len(dataset_groups)):
                                group = dataset_groups[i]
                                group_name = dataset_group_names[i]

                                # true or false
                                if not heatmap and not tpm:
                                        t_df[group_name] = t_df[group].any(axis=1)
                                # tpm values
                                else:
                                        group_name += &#39;_counts&#39;
                                        count_group_cols = self.get_count_cols(group)
                                        t_df[group_name] = t_df[count_group_cols].mean(axis=1)
                        datasets = dataset_group_names
                        # report_cols = dataset_group_names

                # determine report type
                if heatmap:
                        data_type = &#39;heatmap&#39;
                elif tpm:
                        data_type = &#39;tpm&#39;
                else:
                        data_type = None

                # determine report type
                if not browser:
                        report_type = &#39;swan&#39;
                else:
                        report_type = &#39;browser&#39;

                # parallel
                # launch report jobs on different threads
                with Pool() as pool:
                        pool.starmap(_create_gene_report, zip(gids, repeat(self), repeat(t_df),
                                repeat(datasets), repeat(data_type), repeat(prefix), repeat(indicate_dataset),
                                repeat(indicate_novel), repeat(browser), repeat(report_type),
                                repeat(novelty), repeat(heatmap), repeat(include_qvals)))

                # # not parallel
                # # loop through each gid and create the report
                # for gid in gids:

                #       report_tids = t_df.loc[t_df.gid == gid, &#39;tid&#39;].tolist()

                #       # plot each transcript with these settings
                #       print(&#39;Plotting transcripts for {}&#39;.format(gid))
                #       self.plot_each_transcript(report_tids, prefix,
                #                                                         indicate_dataset,
                #                                                         indicate_novel,
                #                                                         browser=browser)

                #       # if we&#39;re plotting tracks, we need a scale as well
                #       if not browser:
                #               report_type = &#39;swan&#39;
                #       else:
                #               self.pg.plot_browser_scale()
                #               self.save_fig(prefix+&#39;_browser_scale.png&#39;)
                #               report_type = &#39;browser&#39;

                #       # subset on gene
                #       gid_t_df = t_df.loc[t_df.gid == gid].copy(deep=True)

                #       if heatmap:
                #               # take log2(tpm) and gene-normalize 
                #               count_cols = [&#39;{}_counts&#39;.format(d) for d in datasets]
                #               log_cols = [&#39;{}_log_tpm&#39;.format(d) for d in datasets]
                #               norm_log_cols = [&#39;{}_norm_log_tpm&#39;.format(d) for d in datasets]
                #               gid_t_df[log_cols] = np.log2(gid_t_df[count_cols]+1)
                #               max_val = max(gid_t_df[log_cols].max().tolist())
                #               min_val = min(gid_t_df[log_cols].min().tolist())
                #               gid_t_df[norm_log_cols] = (gid_t_df[log_cols]-min_val)/(max_val-min_val)

                #               # create a colorbar 
                #               plt.rcParams.update({&#39;font.size&#39;: 20})
                #               fig, ax = plt.subplots(figsize=(14, 1.5))
                #               fig.subplots_adjust(bottom=0.5)
                #               fig.patch.set_visible(False)
                #               ax.patch.set_visible(False)

                #               cmap = plt.get_cmap(&#39;Spectral_r&#39;)
                #               norm = mpl.colors.Normalize(vmin=min_val, vmax=max_val)

                #               cb = mpl.colorbar.ColorbarBase(ax,
                #                                                                               cmap=cmap,
                #                                                                               norm=norm,
                #                                                                               orientation=&#39;horizontal&#39;)
                #               cb.set_label(&#39;log2(TPM)&#39;)
                #               plt.savefig(prefix+&#39;_colorbar_scale.png&#39;, format=&#39;png&#39;, dpi=200)
                #               plt.clf()
                #               plt.close()

                #       # create report
                #       print(&#39;Generating report for {}&#39;.format(gid))
                #       pdf_name = create_fname(prefix, 
                #                                indicate_dataset,
                #                                indicate_novel,
                #                                browser,
                #                                ftype=&#39;report&#39;,
                #                                gid=gid)
                #       report = Report(prefix,
                #                                       report_type,
                #                                       datasets,
                #                                       data_type,
                #                                       novelty=novelty,
                #                                       heatmap=heatmap)
                #       report.add_page()

                #       # loop through each transcript and add it to the report
                #       for tid in report_tids:
                #               entry = gid_t_df.loc[tid]
                #               ## TODO would be faster if I didn&#39;t have to compute these names twice....
                #               ## ie once in plot_each_transcript and once here
                #               fname = create_fname(prefix,
                #                                                        indicate_dataset,
                #                                                        indicate_novel, 
                #                                                        browser,
                #                                                        tid=entry.tid)
                #               report.add_transcript(entry, fname)
                #       report.write_pdf(pdf_name)

        ##########################################################################
        ############################# Error handling #############################
        ##########################################################################

        # make sure that the set of arguments work with each other 
        # before we start plotting
        def check_plotting_args(self,
                                                        indicate_dataset,
                                                        indicate_novel,
                                                        browser=False):

                # can only do one or another
                if indicate_dataset and indicate_novel:
                        raise Exception(&#39;Please choose either indicate_dataset &#39;
                                                        &#39;or indicate_novel, not both.&#39;)

                # if indicate_dataset or indicate_novel are chosen, make sure
                # the dataset or annotation data exists in the SwanGraph
                if indicate_novel and &#39;annotation&#39; not in self.get_dataset_cols():
                        raise Exception(&#39;Annotation data not present in graph. Use &#39;
                                                        &#39;add_annotation before using indicate_novel&#39;)
                if indicate_dataset and indicate_dataset not in self.get_dataset_cols():
                        raise Exception(&#39;Dataset {} not present in the graph. &#39;
                                                        &#39;&#39;.format(indicate_dataset))

                # if browser, can&#39;t do indicate_novel, or indicate_dataset
                if browser:
                        if indicate_novel or indicate_dataset:
                                raise Exception(&#39;Cannot indicate_novel or indicate_dataset &#39;
                                                                &#39;with browser option.&#39;)

##########################################################################
################################## Extras ################################
##########################################################################

# generate a report for one gene; used for parallelization
def _create_gene_report(gid, sg, t_df, 
        datasets, data_type,
        prefix,
        indicate_dataset, indicate_novel,
        browser, 
        report_type, novelty, heatmap, 
        include_qvals):

        report_tids = t_df.loc[t_df.gid == gid, &#39;tid&#39;].tolist()

        # plot each transcript with these settings
        print()
        print(&#39;Plotting transcripts for {}&#39;.format(gid))
        sg.plot_each_transcript(report_tids, prefix,
                                                          indicate_dataset,
                                                          indicate_novel,
                                                          browser=browser)

        # get a different prefix for saving colorbars and scales
        gid_prefix = prefix+&#39;_{}&#39;.format(gid)

        # if we&#39;re plotting tracks, we need a scale as well
        if browser:
                sg.pg.plot_browser_scale()
                save_fig(gid_prefix+&#39;_browser_scale.png&#39;)

        # subset on gene
        gid_t_df = t_df.loc[t_df.gid == gid].copy(deep=True)

        if heatmap:
                # take log2(tpm) and gene-normalize 
                count_cols = [&#39;{}_counts&#39;.format(d) for d in datasets]
                log_cols = [&#39;{}_log_tpm&#39;.format(d) for d in datasets]
                norm_log_cols = [&#39;{}_norm_log_tpm&#39;.format(d) for d in datasets]
                gid_t_df[log_cols] = np.log2(gid_t_df[count_cols]+1)
                max_val = max(gid_t_df[log_cols].max().tolist())
                min_val = min(gid_t_df[log_cols].min().tolist())
                gid_t_df[norm_log_cols] = (gid_t_df[log_cols]-min_val)/(max_val-min_val)

                # create a colorbar 
                plt.rcParams.update({&#39;font.size&#39;: 20})
                fig, ax = plt.subplots(figsize=(14, 1.5))
                fig.subplots_adjust(bottom=0.5)
                fig.patch.set_visible(False)
                ax.patch.set_visible(False)

                cmap = plt.get_cmap(&#39;Spectral_r&#39;)
                norm = mpl.colors.Normalize(vmin=min_val, vmax=max_val)

                cb = mpl.colorbar.ColorbarBase(ax,
                                                                                cmap=cmap,
                                                                                norm=norm,
                                                                                orientation=&#39;horizontal&#39;)
                cb.set_label(&#39;log2(TPM)&#39;)
                plt.savefig(gid_prefix+&#39;_colorbar_scale.png&#39;, format=&#39;png&#39;, dpi=200)
                plt.clf()
                plt.close()

        # create report
        print(&#39;Generating report for {}&#39;.format(gid))
        pdf_name = create_fname(prefix, 
                                 indicate_dataset,
                                 indicate_novel,
                                 browser,
                                 ftype=&#39;report&#39;,
                                 gid=gid)
        report = Report(gid_prefix,
                                        report_type,
                                        datasets,
                                        data_type,
                                        novelty=novelty,
                                        heatmap=heatmap,
                                        include_qvals=include_qvals)
        report.add_page()

        # loop through each transcript and add it to the report
        for tid in report_tids:
                entry = gid_t_df.loc[tid]
                ## TODO would be faster if I didn&#39;t have to compute these names twice....
                ## ie once in plot_each_transcript and once here
                fname = create_fname(prefix,
                                                         indicate_dataset,
                                                         indicate_novel, 
                                                         browser,
                                                         ftype=&#39;path&#39;,
                                                         tid=entry.tid)
                report.add_transcript(entry, fname)
        report.write_pdf(pdf_name)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="swan_vis.swangraph.SwanGraph"><code class="flex name class">
<span>class <span class="ident">SwanGraph</span></span>
<span>(</span><span>file=None)</span>
</code></dt>
<dd>
<div class="desc"><p>A graph class to represent a transcriptome and perform
plotting and analysis from it</p>
<pre><code>    Attributes:
            datasets (list of str):
                    Names of datasets in the Graph
            counts (list of str):
                    Names of columns holding counts in the Graph
            tpm (list of str):
                    Names of columns holding tpm values in the Graph
            loc_df (pandas DataFrame): 
                    DataFrame of all unique observed genomic 
                    coordinates in the transcriptome
            edge_df (pandas DataFrame):
                    DataFrame of all unique observed exonic or intronic
                    combinations of splice sites in the transcriptome
            t_df (pandas DataFrame): 
                    DataFrame of all unique transcripts found 
                    in the transcriptome
            pg (swan PlottedGraph):
                    The PlottedGraph holds the information from the most 
                    recently made plot
            deg_test (pandas DataFrame): 
                    A summary table of the results of a differential gene
                    expression test
            deg_test_groups (list of str, len 2):
                    The configuration of groupings used to run the differential
                    gene expression test
                    det_test (pandas DataFrame): 
                    A summary table of the results of a differential transcript
                    expression test
            det_test_groups (list of str, len 2):
                    The configuration of groupings used to run the differential
                    transcript expression test
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class SwanGraph(Graph):
        &#34;&#34;&#34; 
        A graph class to represent a transcriptome and perform
        plotting and analysis from it

                Attributes:
                        datasets (list of str):
                                Names of datasets in the Graph
                        counts (list of str):
                                Names of columns holding counts in the Graph
                        tpm (list of str):
                                Names of columns holding tpm values in the Graph
                        loc_df (pandas DataFrame): 
                                DataFrame of all unique observed genomic 
                                coordinates in the transcriptome
                        edge_df (pandas DataFrame):
                                DataFrame of all unique observed exonic or intronic
                                combinations of splice sites in the transcriptome
                        t_df (pandas DataFrame): 
                                DataFrame of all unique transcripts found 
                                in the transcriptome
                        pg (swan PlottedGraph):
                                The PlottedGraph holds the information from the most 
                                recently made plot
                        deg_test (pandas DataFrame): 
                                A summary table of the results of a differential gene
                                expression test
                        deg_test_groups (list of str, len 2):
                                The configuration of groupings used to run the differential
                                gene expression test
                                det_test (pandas DataFrame): 
                                A summary table of the results of a differential transcript
                                expression test
                        det_test_groups (list of str, len 2):
                                The configuration of groupings used to run the differential
                                transcript expression test
        &#34;&#34;&#34;

        def __init__(self, file=None):

                if not file:
                        super().__init__()

                        # only a SwanGraph should have a plotted graph
                        self.pg = PlottedGraph()

                        # only a SwanGraph should have DEG and DET data
                        self.deg_test = pd.DataFrame()
                        self.deg_test_groups = &#39;&#39;
                        self.det_test = pd.DataFrame()
                        self.det_test_groups = &#39;&#39;

                else:
                        check_file_loc(file, &#39;SwanGraph&#39;)
                        self.load_graph(file)

        ###########################################################################
        ############## Related to adding datasets and merging #####################
        ###########################################################################

        def add_annotation(self, fname):
                &#34;&#34;&#34;
                Adds an annotation from input fname to the SwanGraph.

                        Parameters:

                                fname (str): Path to annotation GTF
                &#34;&#34;&#34;

                # column name for annotation 
                col = &#39;annotation&#39;

                # use the add_dataset function to add stuff to graph
                self.add_dataset(col, fname, include_isms=True)

                # call all transcripts from the annotation &#34;Known&#34;
                self.t_df.loc[self.t_df.annotation == True, &#39;novelty&#39;] = &#39;Known&#39;
                self.t_df.novelty.fillna(&#39;Undefined&#39;, inplace=True)

        def add_dataset(self, col, fname,
                                        dataset_name=None,
                                        whitelist=None,
                                        annot=None,
                                        counts_file=None, count_cols=None, 
                                        tid_col=&#39;annot_transcript_id&#39;,
                                        include_isms=False):
                &#34;&#34;&#34;
                Add transcripts from a dataset from either a GTF or a TALON database.

                        Parameters:

                                col (str): Name of column to add data to in the SwanGraph
                                fname (str): Path to GTF or TALON db

                                Only for loading from TALON
                                dataset_name (str): Dataset name in TALON db to add transcripts from
                                        Default=None
                                whitelist (str): TALON whitelist of transcripts to add.
                                        Default: None
                                annot (str): TALON annotation name in database to 
                                        add transcripts from
                                        Default: None

                                Only if also adding abundance:
                                counts_file (str): Path to tsv counts matrix
                                        Default=None
                                count_cols (str or list of str): Column names in counts_file to use
                                        Default=None
                                tid_col (str): Column name in counts_file containing transcript id
                                        Default=&#39;annot_transcript_id&#39;

                                include_isms (bool): Include ISMs from input dataset
                                        Default=False
                &#34;&#34;&#34;

                # make sure that input dataset name is not
                # already in any of the df col spaces
                if col in self.datasets:
                        raise Exception(&#39;Dataset {} is already in the graph. &#39;
                                &#39;Provide a different name.&#39;.format(col))
                if col in self.loc_df.columns:
                        raise Exception(&#39;Dataset name {} conflicts with preexisting &#39;
                                &#39;column in loc_df. Choose a different name.&#39;.format(col))
                if col in self.edge_df.columns:
                        raise Exception(&#39;Dataset name {} conflicts with preexisting &#39;
                                &#39;column in edge_df. Choose a different name.&#39;.format(col))
                if col in self.t_df.columns:
                        raise Exception(&#39;Dataset name {} conflicts with preexisting &#39;
                                &#39;column in t_df. Choose a different name.&#39;.format(col))

                # are we dealing with a gtf or a db?
                ftype = gtf_or_db(fname)

                print(&#39;Adding dataset {} to the SwanGraph.&#39;.format(col))

                # first entry is easy 
                if self.is_empty():

                        # get loc_df, edge_df, t_df
                        if ftype == &#39;gtf&#39;:
                                self.create_dfs_gtf(fname)
                        elif ftype == &#39;db&#39;:
                                self.create_dfs_db(fname, annot, whitelist, &#39;hepg2_1&#39;)

                        # add column to each df to indicate where data came from
                        self.loc_df[col] = True
                        self.edge_df[col] = True
                        self.t_df[col] = True

                # adding a new dataset to the graph requires us to merge
                # SwanGraph objects
                else:
                        temp = SwanGraph()
                        if ftype == &#39;gtf&#39;:
                                temp.create_dfs_gtf(fname)
                        elif ftype == &#39;db&#39;:
                                temp.create_dfs_db(fname, annot, whitelist, &#39;hepg2_1&#39;)
                        self.merge_dfs(temp, col)

                # remove isms if we have access to that information
                if &#39;novelty&#39; in self.t_df.columns and not include_isms:
                        self.t_df = self.t_df.loc[self.t_df.novelty != &#39;ISM&#39;]

                # order node ids by genomic position, add node types,
                # and create graph
                self.update_ids()
                self.order_edge_df()
                self.order_transcripts()
                self.get_loc_types()
                self.create_graph_from_dfs()

                # update graph metadata
                self.datasets.append(col)

                # if we&#39;re also adding abundances
                if counts_file and count_cols:
                        self.add_abundance(counts_file, count_cols, col, tid_col)
 
        def add_abundance(self, counts_file, count_cols,
                                          dataset_name, tid_col=&#39;annot_transcript_id&#39;):
                &#34;&#34;&#34;
                Adds abundance information to an existing dataset in the SwanGraph.

                        Parameters:

                                counts_file (str): Path to tsv counts matrix
                                count_cols (str or list of str): Column names in counts_file to use
                                dataset_name (str): Name of SwanGraph dataset to associate abundance with
                                tid_col (str): Column name in counts_file containing transcript id
                                        Default=&#39;annot_transcript_id&#39;
                &#34;&#34;&#34;

                # if the dataset we&#39;re trying to add counts too doesn&#39;t exist
                if dataset_name not in self.datasets:
                        raise Exception(&#39;Trying to add expression data to a dataset &#39;
                                                        &#39;that is not in the graph. Add dataset to graph first.&#39;)

                # get counts from input abundance file 
                abundance_df = process_abundance_file(counts_file, count_cols, tid_col)
                abundance_df.rename({&#39;tpm&#39;: &#39;{}_tpm&#39;.format(dataset_name),
                                                         &#39;counts&#39;: &#39;{}_counts&#39;.format(dataset_name)},
                                                         axis=1, inplace=True)

                # merge on transcript id (tid) with t_df and make sure it&#39;s 
                # formatted correctly
                self.t_df.reset_index(drop=True, inplace=True)
                self.t_df = self.t_df.merge(abundance_df, on=&#39;tid&#39;, how=&#39;left&#39;)
                self.t_df.fillna(value=0, inplace=True)
                self.t_df = create_dupe_index(self.t_df, &#39;tid&#39;)
                self.t_df = set_dupe_index(self.t_df, &#39;tid&#39;)

                # finally update object&#39;s metadata
                self.counts.append(&#39;{}_counts&#39;.format(dataset_name))
                self.tpm.append(&#39;{}_tpm&#39;.format(dataset_name))

        # merge dfs from two SwanGraph objects
        def merge_dfs(self, b, b_col):

                # merge loc dfs
                # what locations correspond between the datasets?
                self.merge_loc_dfs(b, b_col)
                id_map = self.get_merged_id_map()

                self.loc_df.drop([&#39;vertex_id_a&#39;,&#39;vertex_id_b&#39;], axis=1, inplace=True)
                self.loc_df[&#39;vertex_id&#39;] = self.loc_df.index
                self.loc_df = create_dupe_index(self.loc_df, &#39;vertex_id&#39;)
                self.loc_df = set_dupe_index(self.loc_df, &#39;vertex_id&#39;)
                b.loc_df = create_dupe_index(b.loc_df, &#39;vertex_id&#39;)
                b.loc_df = set_dupe_index(b.loc_df, &#39;vertex_id&#39;)

                # update the ids in b to make edge_df, t_df merging easier
                b.update_ids(id_map=id_map)

                # merge edge_df and t_df
                self.merge_edge_dfs(b, b_col)
                self.merge_t_dfs(b, b_col)

        # merge t_dfs on tid, gid, gname, path
        def merge_t_dfs(self, b, b_col):

                # print note to user about merging with novelty
                existing_cols = self.t_df.columns
                add_cols = b.t_df.columns
                if &#39;novelty&#39; not in existing_cols and &#39;novelty&#39; in add_cols:
                        print(&#39;Novelty info not found for &#39;
                                  &#39;existing data. Transcripts &#39;
                                  &#39;without novelty information will be &#39;
                                  &#39;labelled &#34;Undefined&#34;.&#39;)
                elif &#39;novelty&#39; not in add_cols and &#39;novelty&#39; in existing_cols:
                        print(&#39;Novelty info not found for &#39;
                                 &#39;{} data. Transcripts &#39;
                                 &#39;without novelty information will be &#39;
                                 &#39;labelled &#34;Undefined&#34;.&#39;.format(b_col))

                # some df reformatting
                self.t_df.reset_index(drop=True, inplace=True)
                b.t_df.reset_index(drop=True, inplace=True)
                b.t_df[b_col] = True

                # convert paths to tuples so we can merge on them
                self.t_df.path = self.t_df.path.map(tuple)
                b.t_df.path = b.t_df.path.map(tuple)

                # merge on transcript information
                t_df = self.t_df.merge(b.t_df,
                           how=&#39;outer&#39;,
                           on=[&#39;tid&#39;, &#39;gid&#39;, &#39;gname&#39;, &#39;path&#39;],
                           suffixes=[&#39;_a&#39;, &#39;_b&#39;])

                # convert path back to list
                t_df.path = list(t_df.path)

                # assign False to entries that are not in the new dataset, 
                # and to new entries that were not in the prior datasets
                d_cols = self.datasets+[b_col]
                t_df[d_cols] = t_df[d_cols].fillna(value=False, axis=1)

                # deal with novelties
                t_df_cols = t_df.columns.tolist()
                if &#39;novelty&#39; in t_df_cols or &#39;novelty_a&#39; in t_df_cols:
                        t_df = self.merge_t_df_novelties(t_df)

                # set up index again
                t_df = create_dupe_index(t_df, &#39;tid&#39;)
                t_df = set_dupe_index(t_df, &#39;tid&#39;)

                self.t_df = t_df

        def merge_t_df_novelties(self, t_df):

                # merged dfs with and without novelty
                if &#39;novelty&#39; in t_df.columns.tolist():
                        t_df.fillna(value={&#39;novelty&#39;: &#39;Undefined&#39;},
                                inplace=True)

                # merged dfs where both have novelty types
                elif &#39;novelty_a&#39; in t_df.columns.tolist():

                        # if we already have any undefined entries, fill with nan
                        t_df.replace({&#39;novelty_a&#39;: {&#39;Undefined&#39;: np.nan},
                                                  &#39;novelty_b&#39;: {&#39;Undefined&#39;: np.nan}}, 
                                                  inplace=True)

                        # first take values that are only present in one dataset
                        t_df[&#39;novelty_a&#39;].fillna(t_df[&#39;novelty_b&#39;], inplace=True)
                        t_df[&#39;novelty_b&#39;].fillna(t_df[&#39;novelty_a&#39;], inplace=True)
                        a = t_df[[&#39;tid&#39;, &#39;novelty_a&#39;]].copy(deep=True)
                        a.rename({&#39;novelty_a&#39;: &#39;novelty&#39;}, axis=1, inplace=True)
                        a.reset_index(drop=True, inplace=True)
                        b = t_df[[&#39;tid&#39;, &#39;novelty_b&#39;]].copy(deep=True)
                        b.rename({&#39;novelty_b&#39;: &#39;novelty&#39;}, axis=1, inplace=True)
                        b.reset_index(drop=True, inplace=True)

                        # merge novelties on tid and novelty, then extract
                        # transcript ids that are duplicated, which represent
                        # those that have conflicting novelty assignments
                        nov = a.merge(b, on=[&#39;tid&#39;, &#39;novelty&#39;], how=&#39;outer&#39;)
                        amb_tids = nov[nov.tid.duplicated()].tid.tolist()

                        # label conflicting transcripts as Ambiguous
                        if amb_tids:
                                print(&#39;Novelty types between datasets conflict. Strongly &#39;
                                          &#39;consider using input from the same data source to &#39;
                                          &#39;reconcile these. Conflicting isoforms will be &#39;
                                          &#39;labelled &#34;Ambiguous&#34;.&#39;)
                                nov.set_index(&#39;tid&#39;, inplace=True)
                                nov.loc[amb_tids, &#39;novelty&#39;] = &#39;Ambiguous&#39;
                                nov.reset_index(inplace=True)
                                nov.drop_duplicates(inplace=True)

                        # finally, merge new novelty types into t_df
                        t_df.drop([&#39;novelty_a&#39;, &#39;novelty_b&#39;], axis=1, inplace=True)
                        t_df = t_df.merge(nov, on=&#39;tid&#39;)

                return t_df


        # merge edge_dfs on edge_id, v1, v2, strand, edge_type
        def merge_edge_dfs(self, b, b_col):

                # some df reformatting
                self.edge_df.reset_index(drop=True, inplace=True)
                b.edge_df.reset_index(drop=True, inplace=True)
                b.edge_df[b_col] = True

                # merge on edge info
                edge_df = self.edge_df.merge(b.edge_df,
                                  how=&#39;outer&#39;,
                                  on=[&#39;edge_id&#39;, &#39;v1&#39;, &#39;v2&#39;, &#39;edge_type&#39;, &#39;strand&#39;],
                                  suffixes=[&#39;_a&#39;, &#39;_b&#39;])

                # assign False to entries that are not in the new dataset, 
                # and to new entries that were not in the prior datasets
                d_cols = self.datasets+[b_col]
                edge_df[d_cols] = edge_df[d_cols].fillna(value=False, axis=1)

                # remake index
                edge_df = create_dupe_index(edge_df, &#39;edge_id&#39;)
                edge_df = set_dupe_index(edge_df, &#39;edge_id&#39;)
                
                self.edge_df = edge_df

        # merge loc_dfs on coord, chrom, strand
        def merge_loc_dfs(self, b, b_col):

                # some df reformatting
                node_types = [&#39;TSS&#39;, &#39;TES&#39;, &#39;internal&#39;]

                self.loc_df.drop(node_types, axis=1, inplace=True)
                self.loc_df.reset_index(drop=True, inplace=True)

                # b.loc_df.drop(node_types, axis=1, inplace=True)
                b.loc_df.reset_index(drop=True, inplace=True)
                b.loc_df[b_col] = True

                # merge on location info
                loc_df = self.loc_df.merge(b.loc_df,
                                 how=&#39;outer&#39;,
                                 on=[&#39;chrom&#39;, &#39;coord&#39;, &#39;strand&#39;],
                                 suffixes=[&#39;_a&#39;,&#39;_b&#39;])

                # assign False to entries that are not in the new dataset, 
                # and to new entries that were not in prior datasets
                d_cols = self.datasets+[b_col]
                loc_df[d_cols] = loc_df[d_cols].fillna(value=False, axis=1)

                self.loc_df = loc_df

        # returns a dictionary mapping vertex b: vertex a for each
        # vertex in dataset b
        def get_merged_id_map(self):

                id_map = list(zip(self.loc_df.vertex_id_b,
                                                  self.loc_df.vertex_id_a))
                id_map = [list(i) for i in id_map]

                # loop through id_map and assign new ids for 
                # those present in b but not a
                b_ind = int(self.loc_df.vertex_id_a.max() + 1)
                i = 0
                while i &lt; len(id_map):
                        if math.isnan(id_map[i][1]):
                                id_map[i][1] = b_ind
                                b_ind += 1
                        # set up entries where there isn&#39;t a b id (entries only found in a)
                        # to be removed
                        elif math.isnan(id_map[i][0]):
                                id_map[i] = []
                        i += 1

                # remove entries that are only in a but not in b
                # make sure everything is ints
                id_map = [i for i in id_map if len(i) == 2]
                id_map = dict([(int(a), int(b)) for a,b in id_map])

                return id_map

        ##########################################################################
        ############# Related to creating dfs from GTF or TALON DB ###############
        ##########################################################################

        # create loc_df (nodes), edge_df (edges), and t_df (transcripts) from gtf
        # adapted from Dana Wyman and TALON
        def create_dfs_gtf(self, gtf_file):

                # make sure file exists
                check_file_loc(gtf_file, &#39;GTF&#39;)

                # dictionaries to hold unique edges and transcripts
                transcripts = {}
                exons = {}

                with open(gtf_file) as gtf:
                        for line in gtf:

                                # ignore header lines
                                if line.startswith(&#39;#&#39;):
                                        continue

                                # split each entry
                                line = line.strip().split(&#39;\t&#39;)

                                # get some fields from gtf that we care about
                                chrom = line[0]
                                entry_type = line[2]
                                start = int(line[3])
                                stop = int(line[4])
                                strand = line[6]
                                fields = line[-1]

                                # transcript entry 
                                if entry_type == &#34;transcript&#34;:
                                        attributes = get_fields(fields)

                                        # check if this gtf has transcript novelty vals
                                        # for the first transcript entry
                                        if not transcripts:
                                                if &#39;talon_transcript&#39; in attributes:
                                                        from_talon = True
                                                else:
                                                        from_talon = False

                                        tid = attributes[&#39;transcript_id&#39;]
                                        gid = attributes[&#39;gene_id&#39;]
                                        gname = attributes[&#39;gene_name&#39;]

                                        # add transcript to dictionary 
                                        entry = {&#39;gid&#39;: gid,
                                                         &#39;gname&#39;: gname,
                                                         &#39;tid&#39;: tid,
                                                         &#39;strand&#39;: strand,
                                                         &#39;exons&#39;: []}

                                        # if we&#39;re using a talon gtf, add a novelty field
                                        if from_talon:
                                                novelty = get_transcript_novelties(attributes)
                                                entry[&#39;novelty&#39;] = novelty

                                        transcript = {tid: entry}
                                        transcripts.update(transcript)
                                        
                                # exon entry
                                elif entry_type == &#34;exon&#34;:
                                        attributes = get_fields(fields)
                                        start, stop = find_edge_start_stop(start, stop, strand)
                                        eid = &#39;{}_{}_{}_{}_exon&#39;.format(chrom, start, stop, strand)
                                        tid = attributes[&#39;transcript_id&#39;]       

                                        # add novel exon to dictionary 
                                        if eid not in exons:
                                                edge = {eid: {&#39;eid&#39;: eid,
                                                                          &#39;chrom&#39;: chrom,
                                                                          &#39;v1&#39;: start,
                                                                          &#39;v2&#39;: stop,
                                                                          &#39;strand&#39;: strand}}
                                                exons.update(edge)
                           
                                        # add this exon to the transcript&#39;s list of exons
                                        if tid in transcripts:
                                                transcripts[tid][&#39;exons&#39;].append(eid)

                # once we have all transcripts, make loc_df
                locs = {}
                vertex_id = 0
                for edge_id, edge in exons.items():
                        chrom = edge[&#39;chrom&#39;]
                        strand = edge[&#39;strand&#39;]

                        v1 = edge[&#39;v1&#39;]
                        v2 = edge[&#39;v2&#39;]

                        # exon start
                        key = (chrom, v1, strand)
                        if key not in locs:
                                locs[key] = vertex_id
                                vertex_id += 1
                        # exon end
                        key = (chrom, v2, strand)
                        if key not in locs:
                                locs[key] = vertex_id
                                vertex_id += 1

                # add locs-indexed path to transcripts, and populate edges
                edges = {}
                for _,t in transcripts.items():
                        t[&#39;path&#39;] = []
                        strand = t[&#39;strand&#39;]
                        t_exons = t[&#39;exons&#39;]

                        for i, exon_id in enumerate(t_exons):

                                # pull some information from exon dict
                                exon = exons[exon_id]
                                chrom = exon[&#39;chrom&#39;]
                                v1 = exon[&#39;v1&#39;]
                                v2 = exon[&#39;v2&#39;]
                                strand = exon[&#39;strand&#39;]

                                # add current exon and subsequent intron 
                                # (if not the last exon) for each exon to edges
                                key = (chrom, v1, v2, strand)
                                v1_key = (chrom, v1, strand)
                                v2_key = (chrom, v2, strand)
                                edge_id = (locs[v1_key], locs[v2_key])
                                if key not in edges:
                                        edges[key] = {&#39;edge_id&#39;: edge_id, &#39;edge_type&#39;: &#39;exon&#39;}

                                # add exon locs to path
                                t[&#39;path&#39;] += list(edge_id)

                                # if this isn&#39;t the last exon, we also needa add an intron
                                # this consists of v2 of the prev exon and v1 of the next exon
                                if i &lt; len(t_exons)-1:
                                        next_exon = exons[t_exons[i+1]]
                                        v1 = next_exon[&#39;v1&#39;]
                                        key = (chrom, v2, v1, strand)
                                        v1_key = (chrom, v1, strand)
                                        edge_id = (locs[v2_key], locs[v1_key])
                                        if key not in edges:
                                                edges[key] = {&#39;edge_id&#39;: edge_id, &#39;edge_type&#39;: &#39;intron&#39;}

                # turn transcripts, edges, and locs into dataframes
                locs = [{&#39;chrom&#39;: key[0],
                                 &#39;coord&#39;: key[1],
                                 &#39;strand&#39;: key[2],
                                 &#39;vertex_id&#39;: vertex_id} for key, vertex_id in locs.items()]
                loc_df = pd.DataFrame(locs)

                edges = [{&#39;v1&#39;: item[&#39;edge_id&#39;][0],
                                  &#39;v2&#39;: item[&#39;edge_id&#39;][1], 
                                  &#39;strand&#39;: key[3],
                                  &#39;edge_id&#39;: item[&#39;edge_id&#39;],
                                  &#39;edge_type&#39;: item[&#39;edge_type&#39;]} for key, item in edges.items()]
                edge_df = pd.DataFrame(edges)

                if from_talon:
                        transcripts = [{&#39;tid&#39;: key,
                                                &#39;gid&#39;: item[&#39;gid&#39;],
                                                &#39;gname&#39;: item[&#39;gname&#39;],
                                                &#39;path&#39;: item[&#39;path&#39;],
                                                &#39;novelty&#39;: item[&#39;novelty&#39;]} for key, item in transcripts.items()]
                else:
                        transcripts = [{&#39;tid&#39;: key,
                                                &#39;gid&#39;: item[&#39;gid&#39;],
                                                &#39;gname&#39;: item[&#39;gname&#39;],
                                                &#39;path&#39;: item[&#39;path&#39;]} for key, item in transcripts.items()]

                t_df = pd.DataFrame(transcripts)

                # final df formatting
                loc_df = create_dupe_index(loc_df, &#39;vertex_id&#39;)
                loc_df = set_dupe_index(loc_df, &#39;vertex_id&#39;)
                edge_df = create_dupe_index(edge_df, &#39;edge_id&#39;)
                edge_df = set_dupe_index(edge_df, &#39;edge_id&#39;)
                t_df = create_dupe_index(t_df, &#39;tid&#39;)
                t_df = set_dupe_index(t_df, &#39;tid&#39;)

                self.loc_df = loc_df
                self.edge_df = edge_df
                self.t_df = t_df

        # create SwanGraph dataframes from a TALON db. Code very ripped from 
        # TALON&#39;s create_GTF utility
        def create_dfs_db(self, database, annot, whitelist, dataset):

                # make sure file exists
                check_file_loc(database, &#39;TALON DB&#39;)

                annot = check_annot_validity(annot, database)

                whitelist = handle_filtering(database, 
                                                                                        annot, 
                                                                                        True, 
                                                                                        whitelist, 
                                                                                        dataset)
                # create separate gene and transcript whitelists
                gene_whitelist = []
                transcript_whitelist = []
                for key,group in itertools.groupby(whitelist,operator.itemgetter(0)):
                        gene_whitelist.append(key)
                        for id_tuple in list(group):
                                transcript_whitelist.append(id_tuple[1])

                # get gene, transcript, and exon annotations
                gene_annotations = get_annotations(database, &#34;gene&#34;, annot, 
                                                                                   whitelist = gene_whitelist)  
                transcript_annotations = get_annotations(database, &#34;transcript&#34;, annot,
                                                                                                 whitelist = transcript_whitelist) 
                exon_annotations = get_annotations(database, &#34;exon&#34;, annot)

                # get transcript data from the database
                gene_2_transcripts = get_gene_2_transcripts(database, 
                                                         transcript_whitelist)

                # get exon location info from database
                exon_ID_2_location = fetch_exon_locations(database)

                transcripts = {}
                exons = {}

                # loop through genes, transcripts, and exons
                for gene_ID, transcript_tuples in gene_2_transcripts.items():
                        curr_annot = gene_annotations[gene_ID]
                        gene_annotation_dict = {}
                        for annot in curr_annot:
                                attribute = annot[3]
                                value = annot[4]
                                gene_annotation_dict[attribute] = value
                
                        # get transcript entries
                        for transcript_entry in transcript_tuples:
                                transcript_ID = transcript_entry[&#34;transcript_ID&#34;]
                                curr_transcript_annot = transcript_annotations[transcript_ID]

                                transcript_annotation_dict = {}
                                for annot in curr_transcript_annot:
                                        attribute = annot[3]
                                        value = annot[4]
                                        transcript_annotation_dict[attribute] = value
                  
                                tid = transcript_annotation_dict[&#39;transcript_id&#39;]
                                gid = gene_annotation_dict[&#39;gene_id&#39;]  
                                gname = gene_annotation_dict[&#39;gene_name&#39;]
                                strand = transcript_entry[&#39;strand&#39;] 
                                novelty = get_transcript_novelties(transcript_annotation_dict)  

                                # add transcript to dictionary 
                                entry = {&#39;gid&#39;: gid,
                                                 &#39;gname&#39;: gname,
                                                 &#39;tid&#39;: tid,
                                                 &#39;strand&#39;: strand,
                                                 &#39;novelty&#39;: novelty,
                                                 &#39;exons&#39;: []}
                                transcript = {tid: entry}
                                transcripts.update(transcript)
                                                 
                                if transcript_entry[&#34;n_exons&#34;] != 1:
                                        transcript_edges = [str(transcript_entry[&#34;start_exon&#34;])] + \
                                                                           str(transcript_entry[&#34;jn_path&#34;]).split(&#34;,&#34;)+ \
                                                                           [str(transcript_entry[&#34;end_exon&#34;])]
                                else:
                                        transcript_edges = [transcript_entry[&#34;start_exon&#34;]]

                                # get exon entries
                                for exon_ID in transcript_edges[::2]:
                                        exon_ID = int(exon_ID)
                                        curr_exon_annot = exon_annotations[exon_ID]

                                        exon_annotation_dict = {}
                                        for annot in curr_exon_annot:
                                                attribute = annot[3]
                                                value = annot[4]
                                                exon_annotation_dict[attribute] = value

                                        e_tuple = exon_ID_2_location[exon_ID]
                                        chrom = e_tuple[0]
                                        start = e_tuple[1]
                                        stop = e_tuple[2]
                                        strand = e_tuple[3]
                                        start, stop = find_edge_start_stop(start, stop, strand)
                                        eid = &#39;{}_{}_{}_{}_exon&#39;.format(chrom, start, stop, strand)

                                        # add novel exon to dictionary 
                                        if eid not in exons:
                                                edge = {eid: {&#39;eid&#39;: eid,
                                                                          &#39;chrom&#39;: chrom,
                                                                          &#39;v1&#39;: start,
                                                                          &#39;v2&#39;: stop,
                                                                          &#39;strand&#39;: strand}}
                                                exons.update(edge) 

                                        # add this exon to the transcript&#39;s list of exons
                                        if tid in transcripts:
                                                transcripts[tid][&#39;exons&#39;].append(eid)

                # once we have all transcripts, make loc_df
                locs = {}
                vertex_id = 0
                for edge_id, edge in exons.items():
                        chrom = edge[&#39;chrom&#39;]
                        strand = edge[&#39;strand&#39;]

                        v1 = edge[&#39;v1&#39;]
                        v2 = edge[&#39;v2&#39;]

                        # exon start
                        key = (chrom, v1, strand)
                        if key not in locs:
                                locs[key] = vertex_id
                                vertex_id += 1
                        # exon end
                        key = (chrom, v2, strand)
                        if key not in locs:
                                locs[key] = vertex_id
                                vertex_id += 1

                # add locs-indexed path to transcripts, and populate edges
                edges = {}
                # print(dict(list(transcripts.items())[:3]))
                for _,t in transcripts.items():
                        t[&#39;path&#39;] = []
                        strand = t[&#39;strand&#39;]
                        t_exons = t[&#39;exons&#39;]

                        for i, exon_id in enumerate(t_exons):
                                # print(&#39;shouldnt u be in here&#39;)
                                # exit()

                                # pull some information from exon dict
                                exon = exons[exon_id]
                                chrom = exon[&#39;chrom&#39;]
                                v1 = exon[&#39;v1&#39;]
                                v2 = exon[&#39;v2&#39;]
                                strand = exon[&#39;strand&#39;]

                                # add current exon and subsequent intron 
                                # (if not the last exon) for each exon to edges
                                key = (chrom, v1, v2, strand)
                                v1_key = (chrom, v1, strand)
                                v2_key = (chrom, v2, strand)
                                edge_id = (locs[v1_key], locs[v2_key])
                                if key not in edges:
                                        edges[key] = {&#39;edge_id&#39;: edge_id, &#39;edge_type&#39;: &#39;exon&#39;}

                                # add exon locs to path
                                t[&#39;path&#39;] += list(edge_id)

                                # if this isn&#39;t the last exon, we also needa add an intron
                                # this consists of v2 of the prev exon and v1 of the next exon
                                if i &lt; len(t_exons)-1:
                                        next_exon = exons[t_exons[i+1]]
                                        v1 = next_exon[&#39;v1&#39;]
                                        key = (chrom, v2, v1, strand)
                                        v1_key = (chrom, v1, strand)
                                        edge_id = (locs[v2_key], locs[v1_key])
                                        if key not in edges:
                                                edges[key] = {&#39;edge_id&#39;: edge_id, &#39;edge_type&#39;: &#39;intron&#39;}

                # turn transcripts, edges, and locs into dataframes
                locs = [{&#39;chrom&#39;: key[0],
                                 &#39;coord&#39;: key[1],
                                 &#39;strand&#39;: key[2],
                                 &#39;vertex_id&#39;: vertex_id} for key, vertex_id in locs.items()]
                loc_df = pd.DataFrame(locs)

                edges = [{&#39;v1&#39;: item[&#39;edge_id&#39;][0],
                                  &#39;v2&#39;: item[&#39;edge_id&#39;][1], 
                                  &#39;strand&#39;: key[3],
                                  &#39;edge_id&#39;: item[&#39;edge_id&#39;],
                                  &#39;edge_type&#39;: item[&#39;edge_type&#39;]} for key, item in edges.items()]
                edge_df = pd.DataFrame(edges)

                transcripts = [{&#39;tid&#39;: key,
                                        &#39;gid&#39;: item[&#39;gid&#39;],
                                        &#39;gname&#39;: item[&#39;gname&#39;],
                                        &#39;path&#39;: item[&#39;path&#39;],
                                        &#39;novelty&#39;: item[&#39;novelty&#39;]} for key, item in transcripts.items()]

                t_df = pd.DataFrame(transcripts)        

                # final df formatting
                loc_df = create_dupe_index(loc_df, &#39;vertex_id&#39;)
                loc_df = set_dupe_index(loc_df, &#39;vertex_id&#39;)
                edge_df = create_dupe_index(edge_df, &#39;edge_id&#39;)
                edge_df = set_dupe_index(edge_df, &#39;edge_id&#39;)
                t_df = create_dupe_index(t_df, &#39;tid&#39;)
                t_df = set_dupe_index(t_df, &#39;tid&#39;)

                self.loc_df = loc_df
                self.edge_df = edge_df
                self.t_df = t_df

        # add node types (internal, TSS, TES) to loc_df
        def get_loc_types(self):

                self.loc_df[&#39;internal&#39;] = False
                self.loc_df[&#39;TSS&#39;] = False
                self.loc_df[&#39;TES&#39;] = False

                # get lists of locations that are used as TSS, TES
                paths = self.t_df.path.tolist()
                internal = list(set([n for path in paths for n in path[1:-1]]))
                tss = [path[0] for path in paths]
                tes = [path[-1] for path in paths]

                # set node types in t_df
                self.loc_df.loc[internal, &#39;internal&#39;] = True
                self.loc_df.loc[tss, &#39;TSS&#39;] = True
                self.loc_df.loc[tes, &#39;TES&#39;] = True

        ##########################################################################
        ######################## Other SwanGraph utilities #####################
        ##########################################################################

        # order the transcripts by expression of transcript, transcript id, 
        # or start/end nodes
        def order_transcripts(self, order=&#39;tid&#39;):

                # order by transcript id
                if order == &#39;tid&#39;:
                        ordered_tids = sorted(self.t_df.tid.tolist())
                        self.t_df = self.t_df.loc[ordered_tids]

                # order by expression
                elif order == &#39;expression&#39;:
                        tpm_cols = self.get_tpm_cols()

                        # make sure there are counts in the graph at all
                        if tpm_cols:
                                self.t_df[&#39;tpm_sum&#39;] = self.t_df[tpm_cols].sum(axis=1)
                                self.t_df.sort_values(by=&#39;tpm_sum&#39;, 
                                                                          ascending=False, 
                                                                          inplace=True)
                                self.t_df.drop(&#39;tpm_sum&#39;, axis=1, inplace=True)
                        else: 
                                raise Exception(&#39;Cannot order by expression because &#39;
                                                                &#39;there is no expression data.&#39;)

                # order by coordinate of tss in PlottedGraph
                elif order == &#39;tss&#39;:
                        self.t_df[&#39;start_coord&#39;] = self.t_df.apply(lambda x: 
                                self.loc_df.loc[x.path[0], &#39;coord&#39;], axis=1)

                        # watch out for strandedness
                        if self.loc_df.loc[self.loc_df.index[0], &#39;strand&#39;] == &#39;-&#39;:
                                ascending = False
                        else: 
                                ascending = True
                        self.t_df.sort_values(by=&#39;start_coord&#39;,
                                                                  ascending=ascending,
                                                                  inplace=True)
                        self.t_df.drop(&#39;start_coord&#39;, axis=1, inplace=True)
                        
                # order by coordinate of tes
                elif order == &#39;tes&#39;:
                        self.t_df[&#39;end_coord&#39;] = self.t_df.apply(lambda x: 
                                self.loc_df.loc[x.path[-1], &#39;coord&#39;], axis=1)

                        # watch out for strandedness
                        if self.loc_df.loc[self.loc_df.index[0], &#39;strand&#39;] == &#39;-&#39;:
                                ascending = False
                        else: 
                                ascending = True
                        self.t_df.sort_values(by=&#39;end_coord&#39;,
                                                                  ascending=ascending,
                                                                  inplace=True)
                        self.t_df.drop(&#39;end_coord&#39;, axis=1, inplace=True)

        ##########################################################################
        ######################## Finding &#34;interesting&#34; genes #####################
        ##########################################################################

        # returns a list of genes that are &#34;interesting&#34;
        def find_genes_with_novel_isoforms(self):

                # get all the datasets, make sure we&#39;re not counting transcripts 
                # that are only in the annotation
                if &#39;annotation&#39; not in self.datasets:
                        raise Exception(&#39;No annotation data in graph. Cannot &#39;,
                                &#39;determine isoform novelty.&#39;)
                datasets = self.get_dataset_cols(include_annotation=False)
                t_df = self.t_df.copy(deep=True)
                t_df = t_df.loc[t_df[datasets].any(axis=1)]

                # how many known and novel isoforms does each gene have
                t_df[&#39;known&#39;] = t_df.annotation
                t_df[&#39;novel&#39;] = [not i for i in t_df.annotation.tolist()]
                keep_cols = [&#39;annotation&#39;, &#39;known&#39;, &#39;novel&#39;, &#39;gid&#39;]
                g_df = t_df[keep_cols].groupby([&#39;gid&#39;]).sum()

                # create &#39;interestingness&#39; column ranking how many novel 
                # compared to known isoforms there are, also ranked by 
                # number of total isoforms
                g_df.known = g_df.known.astype(&#39;int32&#39;)
                g_df.novel = g_df.novel.astype(&#39;int32&#39;)
                g_df[&#39;interestingness&#39;] = ((g_df.novel+1)/(g_df.known+1))*(g_df.known+g_df.novel)
                g_df.sort_values(by=&#39;interestingness&#39;, ascending=False, inplace=True)

                # top 10 in case the user doesn&#39;t care about whole df
                genes = g_df.index.tolist()[:10]

                return genes, g_df

        # find genes with higher expression in novel than known isoforms
        def find_genes_with_high_novel_expression(self):
                
                # get all the datasets, make sure we&#39;re not counting transcripts 
                # that are only in the annotation
                if &#39;annotation&#39; not in self.datasets:
                        raise Exception(&#39;No annotation data in graph. Cannot &#39;,
                                &#39;determine isoform novelty.&#39;)
                datasets = self.get_dataset_cols(include_annotation=False)
                t_df = self.t_df.copy(deep=True)
                t_df = t_df.loc[t_df[datasets].any(axis=1)]

                # how much expression do known and novel isoforms have?
                t_df[&#39;known&#39;] = t_df.annotation
                tpm_cols = self.get_tpm_cols()
                keep_cols = tpm_cols+[&#39;known&#39;, &#39;gid&#39;]
                g_df = t_df[keep_cols].groupby([&#39;gid&#39;, &#39;known&#39;]).sum()
                g_df.reset_index(inplace=True)
                g_df[&#39;total_known_exp&#39;] = 0
                g_df[&#39;total_novel_exp&#39;] = 0
                g_df.loc[g_df.known == True, &#39;total_known_exp&#39;] = g_df.loc[g_df.known == True, tpm_cols].sum(axis=1) 
                g_df.loc[g_df.known == False, &#39;total_novel_exp&#39;] = g_df.loc[g_df.known == False, tpm_cols].sum(axis=1) 
                keep_cols = tpm_cols+[&#39;total_known_exp&#39;, &#39;total_novel_exp&#39;, &#39;gid&#39;]
                g_df = g_df[keep_cols].groupby(&#39;gid&#39;).sum()

                # create &#39;interestingness&#39; column ranking how much expression
                # of the gene is attributable to novel isoforms versus known isoforms
                g_df[&#39;interestingness&#39;] = ((g_df.total_novel_exp+1)/(g_df.total_known_exp+1))*np.log2(g_df.total_known_exp+1+g_df.total_novel_exp+1)
                g_df.sort_values(by=&#39;interestingness&#39;, ascending=False, inplace=True)

                # top 10 in case the user doesn&#39;t care about whole df
                genes = g_df.index.tolist()[:10]

                return genes, g_df

        def find_ir_genes(self):
                &#34;&#34;&#34;
                Finds all unique genes containing novel intron retention events. 
                Requires that an annotation has been added to the SwanGraph.

                        Returns:

                                ir_genes (list of str): A list of gene ids from the SwanGraph with 
                                        at least one novel intron retention event
                &#34;&#34;&#34;

                # get only novel edges
                if &#39;annotation&#39; not in self.edge_df.columns:
                        raise Exception(&#39;Cannot find novel IR events without &#39;
                                &#39;annotation in SwanGraph.&#39;)

                edge_ids = self.edge_df.loc[ \
                        (self.edge_df.annotation == False)&amp; \
                        (self.edge_df.edge_type == &#39;exon&#39;), &#39;edge_id&#39;]
                print(&#39;Analyzing {} exonic edges for IR&#39;.format(len(edge_ids)))

                # get subset of transcripts that are novel to look for ir edges in
                nt_df = self.t_df.loc[self.t_df.annotation == False]
                
                # for each edge, see if the subgraph between the edge vertices 
                # contains an exonic edge  
                ir_genes = []
                for i, eid in enumerate(edge_ids):
                        sub_nodes = [i for i in range(eid[0]+1,eid[1])]
                        sub_G = self.G.subgraph(sub_nodes)
                        sub_edges = list(sub_G.edges())
                        sub_edges = self.edge_df.loc[sub_edges]
                        sub_edges = sub_edges.loc[sub_edges.edge_type == &#39;intron&#39;]

                        if len(sub_edges.index) &gt; 0:

                                # transcripts that contain the exon-skipping edge
                                cand_t_df = nt_df[[eid in vertex_to_edge_path(x) \
                                        for x in nt_df.path.values.tolist()]]

                                # circumvent the ISM bug
                                if len(cand_t_df) == 0:
                                        continue

                                # does at least one of the retained introns belong
                                # to the same gene as the retaining edge?
                                else:
                                        # genes that contain the intron-retaining edge edge
                                        cand_genes = cand_t_df.gid.values.tolist()
                                        cand_g_df = self.t_df.loc[self.t_df.gid.isin(cand_genes)]

                                        # check if the retained edges are in one of the 
                                        # intron-retaining genes (wow this is confusing)
                                        for gid in cand_genes:
                                                if gid in ir_genes: continue
                                                for cand_eid in sub_edges.index:
                                                        temp_df = cand_g_df[[cand_eid in vertex_to_edge_path(x) \
                                                                        for x in cand_g_df.path.values.tolist()]]
                                                        if len(temp_df.index) &gt; 0:
                                                                ir_genes.append(gid)

                print(&#39;Found {} novel ir events from {} genes.&#39;.format(len(ir_genes), 
                        len(list(set(ir_genes)))))
                ir_genes = list(set(ir_genes))
                return ir_genes

        def find_es_genes(self):
                &#34;&#34;&#34;
                Finds all unique genes containing novel exon skipping events. 
                Requires that an annotation has been added to the SwanGraph.

                        Returns:

                                es_genes (list of str): A list of gene ids from the SwanGraph with 
                                        at least one novel exon skipping event
                &#34;&#34;&#34;

                # get only novel edges
                if &#39;annotation&#39; not in self.edge_df.columns:
                        raise Exception(&#39;Cannot find novel IR events without &#39;
                                &#39;annotation in SwanGraph.&#39;)

                edge_ids = self.edge_df.loc[ \
                        (self.edge_df.annotation == False)&amp; \
                        (self.edge_df.edge_type == &#39;intron&#39;), &#39;edge_id&#39;]
                print(&#39;Analyzing {} intronic edges for ES&#39;.format(len(edge_ids)))

                # get subset of transcripts that are novel to look for ir edges in
                nt_df = self.t_df.loc[self.t_df.annotation == False]

                # for each edge, see if the subgraph between the edge vertices 
                # contains an exonic edge
                es_genes = []
                for eid in edge_ids:
                        sub_nodes = [i for i in range(eid[0]+1,eid[1])]
                        sub_G = self.G.subgraph(sub_nodes)
                        sub_edges = list(sub_G.edges())
                        sub_edges = self.edge_df.loc[sub_edges]
                        sub_edges = sub_edges.loc[sub_edges.edge_type == &#39;exon&#39;]

                        if len(sub_edges.index) &gt; 0:

                                # transcripts that contain the exon-skipping edge
                                skip_t_df = nt_df[[eid in vertex_to_edge_path(x) \
                                        for x in nt_df.path.values.tolist()]]

                                # circumvent the ISM bug
                                if len(skip_t_df) == 0:
                                        continue

                                # does at least one of the skipped exons belong
                                # to the same gene as the skipping edge?
                                else:
                                        # genes that contain the exon-skipping edge
                                        skip_genes = skip_t_df.gid.values.tolist()
                                        skip_g_df = self.t_df.loc[self.t_df.gid.isin(skip_genes)]

                                        # check if the skipped edges are in one of the 
                                        # exon-skipping genes (wow this is confusing)
                                        for gid in skip_genes:
                                                if gid in es_genes: continue
                                                for skip_eid in sub_edges.index:
                                                        temp_df = skip_g_df[[skip_eid in vertex_to_edge_path(x) \
                                                                        for x in skip_g_df.path.values.tolist()]]
                                                        if len(temp_df.index) &gt; 0:
                                                                es_genes.append(gid)

                print(&#39;Found {} novel es events from {} genes.&#39;.format(len(es_genes),
                        len(list(set(es_genes)))))
                es_genes = list(set(es_genes))
                return es_genes

        def de_gene_test(self, dataset_groups):
                &#34;&#34;&#34; 
                Runs a differential expression test on the gene level.

                        Parameters:

                                dataset_groups (list of list of str, len 2): Grouping of datasets 
                                        from the SwanGraph to be used in the differential
                                        expression test
                                        Example: [[&#39;data1&#39;,&#39;data2&#39;],[&#39;data3&#39;,&#39;data4&#39;]]

                        Returns: 

                                test (pandas DataFrame): A summary table of the differential
                                        expression test, including p and q-values, as well 
                                        as log fold change.
                &#34;&#34;&#34;

                # format expression data to be used by diffxpy
                ann = self.create_gene_anndata(dataset_groups)

                # test
                test = de.test.wald(
                        data=ann,
                        formula_loc=&#34;~ 1 + condition&#34;,
                        factor_loc_totest=&#34;condition&#34;)
                test = test.summary()
                test.rename({&#39;gene&#39;: &#39;gid&#39;}, axis=1, inplace=True)


                # add gene name column
                gnames = self.t_df[[&#39;gid&#39;, &#39;gname&#39;]].copy(deep=True)
                gnames.reset_index(drop=True, inplace=True)
                test = test.merge(gnames, how=&#39;left&#39;, on=&#39;gid&#39;)
                test.drop_duplicates(inplace=True)

                # sort on log2fc
                test = test.reindex(test.log2fc.abs().sort_values(ascending=False).index)

                # assign the summary table to the parent object
                self.deg_test = test
                self.deg_test_groups = dataset_groups

                return test

        def get_de_genes(self, q=0.05, n_genes=None):
                &#34;&#34;&#34;
                Subsets the differential gene expression test summary table based
                on a q-value cutoff. Requires that de_gene_test has already been
                run.

                        Parameters:

                                q (float): q-value threshold to declare a gene as significant
                                        Default: 0.05
                                n_genes (int): Number of results to return. 
                                        Default: None (returns all found significant)

                        Returns:

                                genes (list of str): List of gene names that pass the 
                                        significance threshold
                                test (pandas DataFrame): Summary table of genes that pass the
                                        significance threshold
                &#34;&#34;&#34;

                # make sure we have the result of a deg test first!
                if self.deg_test.empty:
                        raise Exception(&#39;Cannot find DE genes without test results. &#39;
                                &#39;Run de_gene_test first.&#39;)

                # subset on q value 
                test = self.deg_test.loc[self.deg_test.qval &lt;= q].copy(deep=True)

                # list and the df of the top de genes according qval threshold
                if not n_genes:
                        genes = test.gname.tolist()
                else:
                        if n_genes &lt; len(test.index):
                                n_genes = len(test.index)
                                test = test.head(n_genes)
                                genes = test.gname.tolist()
                return genes, test

        def de_transcript_test(self, dataset_groups):
                &#34;&#34;&#34; 
                Runs a differential expression test on the transcript level.

                        Parameters:

                                dataset_groups (list of list of str, len 2): Grouping of datasets 
                                        from the SwanGraph to be used in the differential
                                        expression test
                                        Example: [[&#39;data1&#39;,&#39;data2&#39;],[&#39;data3&#39;,&#39;data4&#39;]]

                        Returns: 

                                test (pandas DataFrame): A summary table of the differential
                                        expression test, including p and q-values, as well 
                                        as log fold change.
                &#34;&#34;&#34;

                # format expression data to be used by diffxpy
                ann = self.create_transcript_anndata(dataset_groups)

                # test
                test = de.test.wald(
                        data=ann,
                        formula_loc=&#34;~ 1 + condition&#34;,
                        factor_loc_totest=&#34;condition&#34;)
                test = test.summary()
                test.rename({&#39;gene&#39;: &#39;tid&#39;}, axis=1, inplace=True)

                # add gene name column
                gnames = self.t_df[[&#39;tid&#39;, &#39;gid&#39;, &#39;gname&#39;]].copy(deep=True)
                gnames.reset_index(drop=True, inplace=True)
                test = test.merge(gnames, how=&#39;left&#39;, on=&#39;tid&#39;)

                # sort on log2fc
                test = test.reindex(test.log2fc.abs().sort_values(ascending=False).index)

                # assign the summary table to the parent object
                self.det_test = test
                self.det_test_groups = dataset_groups

                return test

        def get_de_transcripts(self, q=0.05, n_transcripts=None):
                &#34;&#34;&#34;
                Subsets the differential transcript expression test summary table based
                on a q-value cutoff. Requires that de_transcript_test has already been
                run.

                        Parameters:

                                q (float): q-value threshold to declare a transcript as significant
                                        Default: 0.05
                                n_transcripts (int): Number of results to return. 
                                        Default: None (returns all found significant)

                        Returns:

                                tids (list of str): List of transcript ids that pass the 
                                        significance threshold
                                test (pandas DataFrame): Summary table of transcripts that pass
                                        the significance threshold
                &#34;&#34;&#34;

                # make sure we have the result of a deg test first!
                if self.det_test.empty:
                        raise Exception(&#39;Cannot find DE transcripts without test results. &#39;
                                &#39;Run de_transcript_test first.&#39;)

                # subset on q value 
                test = self.det_test.loc[self.det_test.qval &lt;= q].copy(deep=True)

                # list and the df of the top de genes according qval threshold
                if not n_transcripts:
                        tids = test.tid.tolist()
                else:
                        if n_transcripts &lt; len(test.index):
                                n_transcripts = len(test.index)
                        n_transcripts = test.head(n_transcripts)
                        tids = test.transcript.tolist()
                return tids, test

        def find_isoform_switching_genes(self, q=0.05, n_genes=None):
                &#34;&#34;&#34; Finds isoform switching genes; genes that are not differentially
                        expressed but contain at least one transcript that is. Requires
                        that de_gene_test and de_transcript_test have been run.

                        Parameters:

                                q (float): q-value threshold to declare a gene/transcript 
                                        as significant
                                        Default: 0.05
                                n_genes (int): Number of results to return. 
                                        Default: None (returns all found significant)

                        Returns:

                                genes (list of str): List of gene names that were categorized
                                        as isoform switching
                                test (pandas DataFrame): Summary table of genes that were
                                        categorized as isoform switching
                &#34;&#34;&#34;

                # make sure both deg and det tests have been run
                if self.det_test.empty or self.deg_test.empty:
                        raise Exception(&#39;Cannot find isoform switches without test results. &#39;
                                &#39;Run de_gene_test and de_transcript_test first.&#39;)

                # subset for genes that aren&#39;t DE
                not_degs = self.deg_test.loc[self.deg_test.qval &gt; q]
                not_degs = not_degs.gid

                # subset for dets
                dets = self.det_test.loc[self.det_test.qval &lt;= q]

                # merge on gene id 
                switches = dets.merge(not_degs, how=&#39;inner&#39;, on=&#39;gid&#39;)

                # list and the df of the top de genes according qval threshold
                unique_genes = switches.gid.unique().tolist()
                if not n_genes:
                        genes = unique_genes
                else:
                        if n_genes &lt; len(unique_genes):
                                n_genes = len(unique_genes)
                        switches = switches.loc[switches.gid.isin(unique_genes[:n_genes])]
                        genes = unique_genes[:n_genes]
                return genes, switches

        def get_de_and_not_de_transcripts(self, dataset_groups):
                ann = self.create_transcript_anndata(dataset_groups)
                results = de.test.wald(data=ann,
                        formula_loc=&#34;~ 1 + condition&#34;,
                        factor_loc_totest=&#34;condition&#34;)
                test = results.summary()
                test.rename({&#39;gene&#39;: &#39;transcript&#39;}, axis=1, inplace=True)

                gnames = self.t_df[[&#39;tid&#39;, &#39;gname&#39;]].copy(deep=True)
                gnames.reset_index(drop=True, inplace=True)
                test = test.merge(gnames, how=&#39;left&#39;, left_on=&#39;transcript&#39;, right_on=&#39;tid&#39;)
                test = test.reindex(test.log2fc.abs().sort_values(ascending=False).index)

                det = test.loc[test.qval &lt; 0.05]
                not_det = test.loc[test.qval &gt;= 0.05]
                genes_w_det = det.gname.tolist()
                not_det = not_det.loc[not_det.gname.isin(genes_w_det)]
                df = pd.concat([det, not_det])
                df = df.loc[df.gname.duplicated(keep=False)]

                return df

        # return an anndata object that can be used to perform different 
        # differential gene expression tests using the diffxpy module
        def create_gene_anndata(self, dataset_groups):

                # group t_df into gene df and sum up abundances
                # both across genes and across datasets
                t_df = self.t_df.copy(deep=True)
                dataset_cols = []
                all_dataset_cols = []
                for group in dataset_groups:
                        tpm_cols = self.get_tpm_cols(group)
                        dataset_cols.append(tpm_cols)
                        all_dataset_cols.extend(tpm_cols)

                keep_cols = all_dataset_cols+[&#39;gid&#39;]
                g_df = t_df[keep_cols].groupby(&#39;gid&#39;).sum()

                # add pseudocounts for each gene
                g_df[all_dataset_cols] = g_df[all_dataset_cols] + 1

                # create obs, var, and x entries for the anndata object
                ann_x = g_df.to_numpy().T 
                ann_var = pd.DataFrame(index=g_df.index)
                ann_obs = pd.DataFrame(columns=[&#39;batch&#39;],
                                                           data=all_dataset_cols)
                ann_obs[&#39;condition&#39;] = np.nan
                for i, group in enumerate(dataset_cols):
                        ann_obs.loc[ann_obs.batch.isin(group),  &#39;condition&#39;] = i
                ann = anndata.AnnData(X=ann_x, var=ann_var, obs=ann_obs)

                return ann

        # returns an anndata object that can be used to perform different 
        # differential transcript expression tests using diffxpy
        def create_transcript_anndata(self, dataset_groups):

                # group t_df into gene df and sum up abundances
                # both across genes and across datasets
                t_df = self.t_df.copy(deep=True)
                dataset_cols = []
                all_dataset_cols = []
                for group in dataset_groups:
                        tpm_cols = self.get_tpm_cols(group)
                        dataset_cols.append(tpm_cols)
                        all_dataset_cols.extend(tpm_cols)

                # add pseudocounts for each transcript
                t_df[all_dataset_cols] = t_df[all_dataset_cols] + 1

                # create obs, var, and x entries for the anndata object
                ann_x = t_df[all_dataset_cols].to_numpy().T 
                ann_var = pd.DataFrame(index=t_df.index)
                ann_obs = pd.DataFrame(columns=[&#39;batch&#39;],
                                                           data=all_dataset_cols)
                ann_obs[&#39;condition&#39;] = np.nan
                for i, group in enumerate(dataset_cols):
                        ann_obs.loc[ann_obs.batch.isin(group),  &#39;condition&#39;] = i
                ann = anndata.AnnData(X=ann_x, var=ann_var, obs=ann_obs)

                return ann

        ##########################################################################
        ######################## Loading/saving SwanGraphs #####################
        ##########################################################################

        def save_graph(self, prefix):
                &#34;&#34;&#34;
                Saves the current SwanGraph in pickle format with the .p extension

                        Parameters: 

                                prefix (str): Path and filename prefix. Resulting file will 
                                        be saved as prefix.p
                &#34;&#34;&#34;
                print(&#39;Saving graph as &#39;+prefix+&#39;.p&#39;)
                picklefile = open(prefix+&#39;.p&#39;, &#39;wb&#39;)
                pickle.dump(self, picklefile)
                picklefile.close()

        # loads a splice graph object from pickle form
        def load_graph(self, fname):

                picklefile = open(fname, &#39;rb&#39;)
                graph = pickle.load(picklefile)

                # assign SwanGraph fields from file to self
                self.loc_df = graph.loc_df
                self.edge_df = graph.edge_df
                self.t_df = graph.t_df
                self.datasets = graph.datasets
                self.counts = graph.counts
                self.tpm = graph.tpm
                self.pg = graph.pg
                self.G = graph.G

                self.deg_test = graph.deg_test
                self.deg_test_groups = graph.deg_test_groups
                self.det_test = graph.det_test
                self.det_test_groups = graph.det_test_groups

                picklefile.close()

                print(&#39;Graph from {} loaded&#39;.format(fname))

        ##########################################################################
        ############################ Plotting utilities ##########################
        ##########################################################################

        def plot_graph(self, gid,
                                   indicate_dataset=False,
                                   indicate_novel=False,
                                   prefix=None):
                &#34;&#34;&#34;
                Plots a gene summary SwanGraph for an input gene.
                Does not automatically save the figure by default!

                        Parameters:

                                gid (str): Gene ID to plot for (can also be gene name but 
                                        we&#39;ve seen non-unique gene names so use at your own risk!)
                                indicate_dataset (str): Dataset name from SwanGraph to
                                        highlight with outlined nodes and dashed edges
                                        Incompatible with indicate_novel
                                        Default: False (no highlighting)
                                indicate_novel (bool): Highlight novel nodes and edges by 
                                        outlining them and dashing them respectively
                                        Incompatible with indicate_dataset
                                        Default: False
                                prefix (str): Path and file prefix to automatically save
                                        the plotted figure
                                        Default: None, won&#39;t automatically save 
                &#34;&#34;&#34;

                if gid not in self.t_df.gid.tolist():
                        gid = self.get_gid_from_gname(gid)

                self.check_plotting_args(indicate_dataset, indicate_novel)
                self.check_gene(gid)

                # reinit PlottedGraph object and plot
                self.pg.init_plot_settings(self, gid=gid,
                        indicate_dataset=indicate_dataset, 
                        indicate_novel=indicate_novel)
                self.pg.plot_graph()

                # if the user has provided a place to save
                if prefix:
                        browser = False # can&#39;t plot browser for entire gene
                        fname = create_fname(prefix,
                                                                indicate_dataset,
                                                                indicate_novel,
                                                                browser,
                                                                ftype=&#39;summary&#39;,
                                                                gid=gid)
                        self.pg.plot_graph()
                        print(&#39;Saving summary graph for {} as {}&#39;.format(gid, fname))
                        save_fig(fname)

        def plot_transcript_path(self, tid,
                                                         indicate_dataset=False,
                                                         indicate_novel=False,
                                                         browser=False,
                                                         prefix=None):
                &#34;&#34;&#34;
                Plots a path of a single transcript isoform through a gene summary 
                SwanGraph.

                        Parameters:

                                tid (str): Transcript id of transcript to plot
                                indicate_dataset (str): Dataset name from SwanGraph to
                                        highlight with outlined nodes and dashed edges
                                        Incompatible with indicate_novel
                                        Default: False (no highlighting)
                                indicate_novel (bool): Highlight novel nodes and edges by 
                                        outlining them and dashing them respectively
                                        Incompatible with indicate_dataset
                                        Default: False
                                browser (bool): Plot transcript models in genome browser-
                                        style format. Incompatible with indicate_dataset and
                                        indicate_novel
                                prefix (str): Path and file prefix to automatically save
                                        the plotted figure
                                        Default: None, won&#39;t automatically save
                &#34;&#34;&#34;

                self.check_plotting_args(indicate_dataset, indicate_novel, browser)
                self.check_transcript(tid)

                # reinit PlottedGraph object and plot
                self.pg.init_plot_settings(self, tid=tid, 
                        indicate_dataset=indicate_dataset,
                        indicate_novel=indicate_novel,
                        browser=browser)
                self.pg.plot_graph()

                # if the user has provided a place to save
                if prefix:
                        fname = create_fname(prefix,
                                                                indicate_dataset,
                                                                indicate_novel,
                                                                browser,
                                                                ftype=&#39;path&#39;,
                                                                tid=tid)
                        self.pg.plot_graph()
                        print(&#39;Saving transcript path graph for {} as {}&#39;.format(tid, fname))
                        save_fig(fname)

        def plot_each_transcript(self, tids, prefix,
                                                indicate_dataset=False,
                                                indicate_novel=False,
                                                browser=False):
                &#34;&#34;&#34;
                Plot each input transcript and automatically save figures

                        Parameters:

                                tids (list of str): List of transcript ids to plot
                                prefix (str): Path and file prefix to automatically save
                                        the plotted figures
                                indicate_dataset (str): Dataset name from SwanGraph to
                                        highlight with outlined nodes and dashed edges
                                        Incompatible with indicate_novel
                                        Default: False (no highlighting)
                                indicate_novel (bool): Highlight novel nodes and edges by 
                                        outlining them and dashing them respectively
                                        Incompatible with indicate_dataset
                                        Default: False
                                browser (bool): Plot transcript models in genome browser-
                                        style format. Incompatible with indicate_dataset and
                                        indicate_novel
                &#34;&#34;&#34;

                self.check_plotting_args(indicate_dataset, indicate_novel, browser)

                # loop through each transcript in the SwanGraph object
                for tid in tids:
                        self.check_transcript(tid)

                for tid in tids:
                        self.pg.init_plot_settings(self, tid=tid,
                                indicate_dataset=indicate_dataset,
                                indicate_novel=indicate_novel,
                                browser=browser)
                        fname = create_fname(prefix,
                                                                 indicate_dataset,
                                                                 indicate_novel,
                                                                 browser,
                                                                 ftype=&#39;path&#39;,
                                                                 tid=tid)
                        self.pg.plot_graph()
                        print(&#39;Saving transcript path graph for {} as {}&#39;.format(tid, fname))
                        save_fig(fname)

        def plot_each_transcript_in_gene(self, gid, prefix,
                                                         indicate_dataset=False,
                                                         indicate_novel=False,
                                                         browser=False):
                &#34;&#34;&#34;
                Plot each transcript in a given gene and automatically save figures

                        Parameters:

                                gid (str): Gene id or gene name to plot transcripts from
                                prefix (str): Path and file prefix to automatically save
                                        the plotted figures
                                indicate_dataset (str): Dataset name from SwanGraph to
                                        highlight with outlined nodes and dashed edges
                                        Incompatible with indicate_novel
                                        Default: False (no highlighting)
                                indicate_novel (bool): Highlight novel nodes and edges by 
                                        outlining them and dashing them respectively
                                        Incompatible with indicate_dataset
                                        Default: False
                                browser (bool): Plot transcript models in genome browser-
                                        style format. Incompatible with indicate_dataset and
                                        indicate_novel
                &#34;&#34;&#34;

                if gid not in self.t_df.gid.tolist():
                        gid = self.get_gid_from_gname(gid)
                self.check_gene(gid)

                self.check_plotting_args(indicate_dataset, indicate_novel, browser)

                # loop through each transcript in the SwanGraph object
                tids = self.t_df.loc[self.t_df.gid == gid, &#39;tid&#39;].tolist()
                print()
                print(&#39;Plotting {} transcripts for {}&#39;.format(len(tids), gid))
                for tid in tids:
                        self.pg.init_plot_settings(self, tid=tid,
                                indicate_dataset=indicate_dataset,
                                indicate_novel=indicate_novel,
                                browser=browser)
                        fname = create_fname(prefix,
                                                                 indicate_dataset,
                                                                 indicate_novel,
                                                                 browser,
                                                                 ftype=&#39;path&#39;,
                                                                 tid=tid)
                        self.pg.plot_graph()
                        print(&#39;Saving transcript path graph for {} as {}&#39;.format(tid, fname))
                        save_fig(fname)

        ##########################################################################
        ############################### Report stuff #############################
        ##########################################################################
        # creates a report for each transcript model for a gene according to user input
        def gen_report(self,
                                   gids,
                                   prefix,
                                   datasets=&#39;all&#39;,
                                   dataset_groups=False,
                                   dataset_group_names=False,
                                   novelty=False,
                                   heatmap=False,
                                   tpm=False,
                                   include_qvals=False,
                                   q=0.05,
                                   include_unexpressed=False,
                                   indicate_dataset=False, 
                                   indicate_novel=False,
                                   browser=False,
                                   order=&#39;expression&#39;):
                &#34;&#34;&#34;
                Generates a PDF report for a given gene or list of genes according
                to the user&#39;s input.

                        Parameters: 

                                gids (str or list of str): Gene ids or names to generate
                                        reports for
                                prefix (str): Path and/or filename prefix to save PDF and
                                        images used to generate the PDF

                                datasets (list of str): Datasets to include in the report
                                        Default: Include columns for all datasets
                                dataset_groups (list of list of str): Datasets to average
                                        together in the report and display as one column
                                        Example: [[&#39;group1_1&#39;,&#39;group1_2&#39;],[&#39;group2_1&#39;,&#39;group2_2&#39;]]
                                dataset_group_names (list of str): Names to give each group 
                                        given by dataset_groups. Must be the same length as 
                                        dataset_groups
                                        Example: [&#39;group1&#39;, &#39;group2&#39;]
                                        Default: Will assign numbers 1 through length(dataset_group)

                                novelty (bool): Include a column to dipslay novelty type of
                                        each transcript. Requires that a TALON GTF or DB has 
                                        been used to load data in
                                        Default: False

                                heatmap (bool): Display expression values in a heatmap
                                        format. Requires that abundance information has been 
                                        added to the SwanGraph
                                        Default: False
                                tpm (bool): Display TPM value of each transcript/dataset 
                                        combination, instead of presence/absence of each 
                                        transcript. Requires that abundance information has
                                        been added to the SwanGraph
                                        Default:False

                                include_qvals (bool): Display q-val of each transcript&#39;s 
                                        differential expression and bold entries found to be
                                        differentially expressed. Requires that de_transcript_test
                                        has been run, and that abundance information has been
                                        added to the SwanGraph
                                        Default: False
                                q (float): Q-value significance threshold to use when 
                                        bolding transcripts if include_qvals = True.
                                        Default: 0.05

                                include_unexpressed (bool): Add transcript entries to report
                                        that are not expressed in any input dataset.
                                        Default: False

                                indicate_dataset (str): Dataset name from SwanGraph to
                                        highlight with outlined nodes and dashed edges
                                        Incompatible with indicate_novel
                                        Default: False (no highlighting)
                                indicate_novel (bool): Highlight novel nodes and edges by 
                                        outlining them and dashing them respectively
                                        Incompatible with indicate_dataset
                                        Default: False
                                browser (bool): Plot transcript models in genome browser-
                                        style format. Incompatible with indicate_dataset and
                                        indicate_novel

                                order (str): Order to display transcripts in the report.
                                        Options are 
                                                &#39;tid&#39;: alphabetically by transcript ID
                                                &#39;expression&#39;: cumulative expression from high to low
                                                        Requires that abundance information has been 
                                                        added to the SwanGraph
                                                &#39;tss&#39;: genomic coordinate of transcription start site
                                                &#39;tes&#39;: genomic coordinate of transcription end site
                                        Default: &#39;expression&#39; if abundance information is present,
                                                         &#39;tid&#39; if not
                &#34;&#34;&#34;

                # check to see if input genes are in the graph
                if type(gids) != list:
                        gids = [gids]
                for i, gid in enumerate(gids):
                        if gid not in self.t_df.gid.tolist():
                                gid = self.get_gid_from_gname(gid)
                                gids[i] = gid
                        self.check_gene(gid)

                # check to see if these plotting settings will play together
                self.check_plotting_args(indicate_dataset,
                        indicate_novel, browser)

                # make sure all input datasets are present in graph
                if datasets == &#39;all&#39;:
                        datasets = self.get_dataset_cols(include_annotation=False)
                elif not datasets:
                        datasets = []
                else:
                        self.check_datasets(datasets)

                # if we have dataset groupings make sure that they are a subset
                # of the datasets already requested
                if dataset_groups:
                        if not datasets: 
                                raise Exception(&#39;Cannot group datasets as none were requested.&#39;)
                        else:
                                all_dgs = [j for i in dataset_groups for j in i]
                                self.check_datasets(all_dgs)

                                subsumed_datasets = [True if i in datasets else False for i in all_dgs]
                                if False in subsumed_datasets:
                                        bad_dataset = all_dgs[subsumed_datasets.index(False)]
                                        raise Exception(&#34;Grouping dataset {} not present in &#34; 
                                                &#34;datasets {}.&#34;.format(bad_dataset, datasets))

                # if we&#39;ve asked for novelty first check to make sure it&#39;s there
                if novelty:
                        if not self.has_novelty():
                                raise Exception(&#39;No novelty information present in the graph. &#39;
                                        &#39;Add it or do not use the &#34;novelty&#34; report option.&#39;)

                # check to make sure abundance data is there for the
                # query columns, if user is asking
                if tpm or heatmap:
                        self.check_abundances(datasets)

                # order transcripts by user&#39;s preferences 
                if order == &#39;expression&#39; and not self.get_count_cols():
                        order = &#39;tid&#39;
                self.order_transcripts(order)

                # subset t_df based on relevant tids and expression requirements
                t_df = self.t_df[self.t_df.gid.isin(gids)].copy(deep=True)

                # make sure de has been run if needed
                if include_qvals:
                        self.check_de(&#39;transcript&#39;)
                        de_df = self.det_test.copy(deep=True)
                        t_df = reset_dupe_index(t_df, &#39;tid&#39;)
                        t_df[&#39;significant&#39;] = False
                        t_df = t_df.merge(de_df[[&#39;tid&#39;, &#39;qval&#39;]], how=&#39;left&#39;, on=&#39;tid&#39;)
                        t_df[&#39;significant&#39;] = t_df.qval &lt;= q
                        t_df = set_dupe_index(t_df, &#39;tid&#39;)

                # if user doesn&#39;t care about datasets, just show all transcripts
                if not datasets:
                        include_unexpressed = True

                # user only wants transcript isoforms that appear in their data
                if not include_unexpressed:
                        counts_cols = self.get_count_cols(datasets)
                        t_df = t_df[t_df[counts_cols].sum(axis=1)&gt;0]

                # if we&#39;re grouping things switch up the datasets 
                # and how t_df is formatted
                if dataset_groups:

                        # no grouped dataset names were given - generate names
                        if not dataset_group_names:
                                print(&#39;No group names given. Will just use Group_#.&#39;)
                                dataset_group_names = [&#39;Group_{}&#39;.format(i) for i in range(len(dataset_groups))]

                        # check if we have the right number of group names
                        if len(dataset_groups) != len(dataset_group_names):
                                print(&#39;Not enough group names given. Will just use Group_#.&#39;)
                                dataset_group_names = [&#39;Group_{}&#39;.format(i) for i in range(len(dataset_groups))]

                        for i in range(len(dataset_groups)):
                                group = dataset_groups[i]
                                group_name = dataset_group_names[i]

                                # true or false
                                if not heatmap and not tpm:
                                        t_df[group_name] = t_df[group].any(axis=1)
                                # tpm values
                                else:
                                        group_name += &#39;_counts&#39;
                                        count_group_cols = self.get_count_cols(group)
                                        t_df[group_name] = t_df[count_group_cols].mean(axis=1)
                        datasets = dataset_group_names
                        # report_cols = dataset_group_names

                # determine report type
                if heatmap:
                        data_type = &#39;heatmap&#39;
                elif tpm:
                        data_type = &#39;tpm&#39;
                else:
                        data_type = None

                # determine report type
                if not browser:
                        report_type = &#39;swan&#39;
                else:
                        report_type = &#39;browser&#39;

                # parallel
                # launch report jobs on different threads
                with Pool() as pool:
                        pool.starmap(_create_gene_report, zip(gids, repeat(self), repeat(t_df),
                                repeat(datasets), repeat(data_type), repeat(prefix), repeat(indicate_dataset),
                                repeat(indicate_novel), repeat(browser), repeat(report_type),
                                repeat(novelty), repeat(heatmap), repeat(include_qvals)))

                # # not parallel
                # # loop through each gid and create the report
                # for gid in gids:

                #       report_tids = t_df.loc[t_df.gid == gid, &#39;tid&#39;].tolist()

                #       # plot each transcript with these settings
                #       print(&#39;Plotting transcripts for {}&#39;.format(gid))
                #       self.plot_each_transcript(report_tids, prefix,
                #                                                         indicate_dataset,
                #                                                         indicate_novel,
                #                                                         browser=browser)

                #       # if we&#39;re plotting tracks, we need a scale as well
                #       if not browser:
                #               report_type = &#39;swan&#39;
                #       else:
                #               self.pg.plot_browser_scale()
                #               self.save_fig(prefix+&#39;_browser_scale.png&#39;)
                #               report_type = &#39;browser&#39;

                #       # subset on gene
                #       gid_t_df = t_df.loc[t_df.gid == gid].copy(deep=True)

                #       if heatmap:
                #               # take log2(tpm) and gene-normalize 
                #               count_cols = [&#39;{}_counts&#39;.format(d) for d in datasets]
                #               log_cols = [&#39;{}_log_tpm&#39;.format(d) for d in datasets]
                #               norm_log_cols = [&#39;{}_norm_log_tpm&#39;.format(d) for d in datasets]
                #               gid_t_df[log_cols] = np.log2(gid_t_df[count_cols]+1)
                #               max_val = max(gid_t_df[log_cols].max().tolist())
                #               min_val = min(gid_t_df[log_cols].min().tolist())
                #               gid_t_df[norm_log_cols] = (gid_t_df[log_cols]-min_val)/(max_val-min_val)

                #               # create a colorbar 
                #               plt.rcParams.update({&#39;font.size&#39;: 20})
                #               fig, ax = plt.subplots(figsize=(14, 1.5))
                #               fig.subplots_adjust(bottom=0.5)
                #               fig.patch.set_visible(False)
                #               ax.patch.set_visible(False)

                #               cmap = plt.get_cmap(&#39;Spectral_r&#39;)
                #               norm = mpl.colors.Normalize(vmin=min_val, vmax=max_val)

                #               cb = mpl.colorbar.ColorbarBase(ax,
                #                                                                               cmap=cmap,
                #                                                                               norm=norm,
                #                                                                               orientation=&#39;horizontal&#39;)
                #               cb.set_label(&#39;log2(TPM)&#39;)
                #               plt.savefig(prefix+&#39;_colorbar_scale.png&#39;, format=&#39;png&#39;, dpi=200)
                #               plt.clf()
                #               plt.close()

                #       # create report
                #       print(&#39;Generating report for {}&#39;.format(gid))
                #       pdf_name = create_fname(prefix, 
                #                                indicate_dataset,
                #                                indicate_novel,
                #                                browser,
                #                                ftype=&#39;report&#39;,
                #                                gid=gid)
                #       report = Report(prefix,
                #                                       report_type,
                #                                       datasets,
                #                                       data_type,
                #                                       novelty=novelty,
                #                                       heatmap=heatmap)
                #       report.add_page()

                #       # loop through each transcript and add it to the report
                #       for tid in report_tids:
                #               entry = gid_t_df.loc[tid]
                #               ## TODO would be faster if I didn&#39;t have to compute these names twice....
                #               ## ie once in plot_each_transcript and once here
                #               fname = create_fname(prefix,
                #                                                        indicate_dataset,
                #                                                        indicate_novel, 
                #                                                        browser,
                #                                                        tid=entry.tid)
                #               report.add_transcript(entry, fname)
                #       report.write_pdf(pdf_name)

        ##########################################################################
        ############################# Error handling #############################
        ##########################################################################

        # make sure that the set of arguments work with each other 
        # before we start plotting
        def check_plotting_args(self,
                                                        indicate_dataset,
                                                        indicate_novel,
                                                        browser=False):

                # can only do one or another
                if indicate_dataset and indicate_novel:
                        raise Exception(&#39;Please choose either indicate_dataset &#39;
                                                        &#39;or indicate_novel, not both.&#39;)

                # if indicate_dataset or indicate_novel are chosen, make sure
                # the dataset or annotation data exists in the SwanGraph
                if indicate_novel and &#39;annotation&#39; not in self.get_dataset_cols():
                        raise Exception(&#39;Annotation data not present in graph. Use &#39;
                                                        &#39;add_annotation before using indicate_novel&#39;)
                if indicate_dataset and indicate_dataset not in self.get_dataset_cols():
                        raise Exception(&#39;Dataset {} not present in the graph. &#39;
                                                        &#39;&#39;.format(indicate_dataset))

                # if browser, can&#39;t do indicate_novel, or indicate_dataset
                if browser:
                        if indicate_novel or indicate_dataset:
                                raise Exception(&#39;Cannot indicate_novel or indicate_dataset &#39;
                                                                &#39;with browser option.&#39;)</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="swan_vis.swangraph.SwanGraph.add_abundance"><code class="name flex">
<span>def <span class="ident">add_abundance</span></span>(<span>self, counts_file, count_cols, dataset_name, tid_col='annot_transcript_id')</span>
</code></dt>
<dd>
<div class="desc"><p>Adds abundance information to an existing dataset in the SwanGraph.</p>
<pre><code>    Parameters:

            counts_file (str): Path to tsv counts matrix
            count_cols (str or list of str): Column names in counts_file to use
            dataset_name (str): Name of SwanGraph dataset to associate abundance with
            tid_col (str): Column name in counts_file containing transcript id
                    Default='annot_transcript_id'
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_abundance(self, counts_file, count_cols,
                                  dataset_name, tid_col=&#39;annot_transcript_id&#39;):
        &#34;&#34;&#34;
        Adds abundance information to an existing dataset in the SwanGraph.

                Parameters:

                        counts_file (str): Path to tsv counts matrix
                        count_cols (str or list of str): Column names in counts_file to use
                        dataset_name (str): Name of SwanGraph dataset to associate abundance with
                        tid_col (str): Column name in counts_file containing transcript id
                                Default=&#39;annot_transcript_id&#39;
        &#34;&#34;&#34;

        # if the dataset we&#39;re trying to add counts too doesn&#39;t exist
        if dataset_name not in self.datasets:
                raise Exception(&#39;Trying to add expression data to a dataset &#39;
                                                &#39;that is not in the graph. Add dataset to graph first.&#39;)

        # get counts from input abundance file 
        abundance_df = process_abundance_file(counts_file, count_cols, tid_col)
        abundance_df.rename({&#39;tpm&#39;: &#39;{}_tpm&#39;.format(dataset_name),
                                                 &#39;counts&#39;: &#39;{}_counts&#39;.format(dataset_name)},
                                                 axis=1, inplace=True)

        # merge on transcript id (tid) with t_df and make sure it&#39;s 
        # formatted correctly
        self.t_df.reset_index(drop=True, inplace=True)
        self.t_df = self.t_df.merge(abundance_df, on=&#39;tid&#39;, how=&#39;left&#39;)
        self.t_df.fillna(value=0, inplace=True)
        self.t_df = create_dupe_index(self.t_df, &#39;tid&#39;)
        self.t_df = set_dupe_index(self.t_df, &#39;tid&#39;)

        # finally update object&#39;s metadata
        self.counts.append(&#39;{}_counts&#39;.format(dataset_name))
        self.tpm.append(&#39;{}_tpm&#39;.format(dataset_name))</code></pre>
</details>
</dd>
<dt id="swan_vis.swangraph.SwanGraph.add_annotation"><code class="name flex">
<span>def <span class="ident">add_annotation</span></span>(<span>self, fname)</span>
</code></dt>
<dd>
<div class="desc"><p>Adds an annotation from input fname to the SwanGraph.</p>
<pre><code>    Parameters:

            fname (str): Path to annotation GTF
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_annotation(self, fname):
        &#34;&#34;&#34;
        Adds an annotation from input fname to the SwanGraph.

                Parameters:

                        fname (str): Path to annotation GTF
        &#34;&#34;&#34;

        # column name for annotation 
        col = &#39;annotation&#39;

        # use the add_dataset function to add stuff to graph
        self.add_dataset(col, fname, include_isms=True)

        # call all transcripts from the annotation &#34;Known&#34;
        self.t_df.loc[self.t_df.annotation == True, &#39;novelty&#39;] = &#39;Known&#39;
        self.t_df.novelty.fillna(&#39;Undefined&#39;, inplace=True)</code></pre>
</details>
</dd>
<dt id="swan_vis.swangraph.SwanGraph.add_dataset"><code class="name flex">
<span>def <span class="ident">add_dataset</span></span>(<span>self, col, fname, dataset_name=None, whitelist=None, annot=None, counts_file=None, count_cols=None, tid_col='annot_transcript_id', include_isms=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Add transcripts from a dataset from either a GTF or a TALON database.</p>
<pre><code>    Parameters:

            col (str): Name of column to add data to in the SwanGraph
            fname (str): Path to GTF or TALON db

            Only for loading from TALON
            dataset_name (str): Dataset name in TALON db to add transcripts from
                    Default=None
            whitelist (str): TALON whitelist of transcripts to add.
                    Default: None
            annot (str): TALON annotation name in database to 
                    add transcripts from
                    Default: None

            Only if also adding abundance:
            counts_file (str): Path to tsv counts matrix
                    Default=None
            count_cols (str or list of str): Column names in counts_file to use
                    Default=None
            tid_col (str): Column name in counts_file containing transcript id
                    Default='annot_transcript_id'

            include_isms (bool): Include ISMs from input dataset
                    Default=False
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_dataset(self, col, fname,
                                dataset_name=None,
                                whitelist=None,
                                annot=None,
                                counts_file=None, count_cols=None, 
                                tid_col=&#39;annot_transcript_id&#39;,
                                include_isms=False):
        &#34;&#34;&#34;
        Add transcripts from a dataset from either a GTF or a TALON database.

                Parameters:

                        col (str): Name of column to add data to in the SwanGraph
                        fname (str): Path to GTF or TALON db

                        Only for loading from TALON
                        dataset_name (str): Dataset name in TALON db to add transcripts from
                                Default=None
                        whitelist (str): TALON whitelist of transcripts to add.
                                Default: None
                        annot (str): TALON annotation name in database to 
                                add transcripts from
                                Default: None

                        Only if also adding abundance:
                        counts_file (str): Path to tsv counts matrix
                                Default=None
                        count_cols (str or list of str): Column names in counts_file to use
                                Default=None
                        tid_col (str): Column name in counts_file containing transcript id
                                Default=&#39;annot_transcript_id&#39;

                        include_isms (bool): Include ISMs from input dataset
                                Default=False
        &#34;&#34;&#34;

        # make sure that input dataset name is not
        # already in any of the df col spaces
        if col in self.datasets:
                raise Exception(&#39;Dataset {} is already in the graph. &#39;
                        &#39;Provide a different name.&#39;.format(col))
        if col in self.loc_df.columns:
                raise Exception(&#39;Dataset name {} conflicts with preexisting &#39;
                        &#39;column in loc_df. Choose a different name.&#39;.format(col))
        if col in self.edge_df.columns:
                raise Exception(&#39;Dataset name {} conflicts with preexisting &#39;
                        &#39;column in edge_df. Choose a different name.&#39;.format(col))
        if col in self.t_df.columns:
                raise Exception(&#39;Dataset name {} conflicts with preexisting &#39;
                        &#39;column in t_df. Choose a different name.&#39;.format(col))

        # are we dealing with a gtf or a db?
        ftype = gtf_or_db(fname)

        print(&#39;Adding dataset {} to the SwanGraph.&#39;.format(col))

        # first entry is easy 
        if self.is_empty():

                # get loc_df, edge_df, t_df
                if ftype == &#39;gtf&#39;:
                        self.create_dfs_gtf(fname)
                elif ftype == &#39;db&#39;:
                        self.create_dfs_db(fname, annot, whitelist, &#39;hepg2_1&#39;)

                # add column to each df to indicate where data came from
                self.loc_df[col] = True
                self.edge_df[col] = True
                self.t_df[col] = True

        # adding a new dataset to the graph requires us to merge
        # SwanGraph objects
        else:
                temp = SwanGraph()
                if ftype == &#39;gtf&#39;:
                        temp.create_dfs_gtf(fname)
                elif ftype == &#39;db&#39;:
                        temp.create_dfs_db(fname, annot, whitelist, &#39;hepg2_1&#39;)
                self.merge_dfs(temp, col)

        # remove isms if we have access to that information
        if &#39;novelty&#39; in self.t_df.columns and not include_isms:
                self.t_df = self.t_df.loc[self.t_df.novelty != &#39;ISM&#39;]

        # order node ids by genomic position, add node types,
        # and create graph
        self.update_ids()
        self.order_edge_df()
        self.order_transcripts()
        self.get_loc_types()
        self.create_graph_from_dfs()

        # update graph metadata
        self.datasets.append(col)

        # if we&#39;re also adding abundances
        if counts_file and count_cols:
                self.add_abundance(counts_file, count_cols, col, tid_col)</code></pre>
</details>
</dd>
<dt id="swan_vis.swangraph.SwanGraph.de_gene_test"><code class="name flex">
<span>def <span class="ident">de_gene_test</span></span>(<span>self, dataset_groups)</span>
</code></dt>
<dd>
<div class="desc"><p>Runs a differential expression test on the gene level.</p>
<pre><code>    Parameters:

            dataset_groups (list of list of str, len 2): Grouping of datasets 
                    from the SwanGraph to be used in the differential
                    expression test
                    Example: [['data1','data2'],['data3','data4']]

    Returns:

            test (pandas DataFrame): A summary table of the differential
                    expression test, including p and q-values, as well 
                    as log fold change.
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def de_gene_test(self, dataset_groups):
        &#34;&#34;&#34; 
        Runs a differential expression test on the gene level.

                Parameters:

                        dataset_groups (list of list of str, len 2): Grouping of datasets 
                                from the SwanGraph to be used in the differential
                                expression test
                                Example: [[&#39;data1&#39;,&#39;data2&#39;],[&#39;data3&#39;,&#39;data4&#39;]]

                Returns: 

                        test (pandas DataFrame): A summary table of the differential
                                expression test, including p and q-values, as well 
                                as log fold change.
        &#34;&#34;&#34;

        # format expression data to be used by diffxpy
        ann = self.create_gene_anndata(dataset_groups)

        # test
        test = de.test.wald(
                data=ann,
                formula_loc=&#34;~ 1 + condition&#34;,
                factor_loc_totest=&#34;condition&#34;)
        test = test.summary()
        test.rename({&#39;gene&#39;: &#39;gid&#39;}, axis=1, inplace=True)


        # add gene name column
        gnames = self.t_df[[&#39;gid&#39;, &#39;gname&#39;]].copy(deep=True)
        gnames.reset_index(drop=True, inplace=True)
        test = test.merge(gnames, how=&#39;left&#39;, on=&#39;gid&#39;)
        test.drop_duplicates(inplace=True)

        # sort on log2fc
        test = test.reindex(test.log2fc.abs().sort_values(ascending=False).index)

        # assign the summary table to the parent object
        self.deg_test = test
        self.deg_test_groups = dataset_groups

        return test</code></pre>
</details>
</dd>
<dt id="swan_vis.swangraph.SwanGraph.de_transcript_test"><code class="name flex">
<span>def <span class="ident">de_transcript_test</span></span>(<span>self, dataset_groups)</span>
</code></dt>
<dd>
<div class="desc"><p>Runs a differential expression test on the transcript level.</p>
<pre><code>    Parameters:

            dataset_groups (list of list of str, len 2): Grouping of datasets 
                    from the SwanGraph to be used in the differential
                    expression test
                    Example: [['data1','data2'],['data3','data4']]

    Returns:

            test (pandas DataFrame): A summary table of the differential
                    expression test, including p and q-values, as well 
                    as log fold change.
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def de_transcript_test(self, dataset_groups):
        &#34;&#34;&#34; 
        Runs a differential expression test on the transcript level.

                Parameters:

                        dataset_groups (list of list of str, len 2): Grouping of datasets 
                                from the SwanGraph to be used in the differential
                                expression test
                                Example: [[&#39;data1&#39;,&#39;data2&#39;],[&#39;data3&#39;,&#39;data4&#39;]]

                Returns: 

                        test (pandas DataFrame): A summary table of the differential
                                expression test, including p and q-values, as well 
                                as log fold change.
        &#34;&#34;&#34;

        # format expression data to be used by diffxpy
        ann = self.create_transcript_anndata(dataset_groups)

        # test
        test = de.test.wald(
                data=ann,
                formula_loc=&#34;~ 1 + condition&#34;,
                factor_loc_totest=&#34;condition&#34;)
        test = test.summary()
        test.rename({&#39;gene&#39;: &#39;tid&#39;}, axis=1, inplace=True)

        # add gene name column
        gnames = self.t_df[[&#39;tid&#39;, &#39;gid&#39;, &#39;gname&#39;]].copy(deep=True)
        gnames.reset_index(drop=True, inplace=True)
        test = test.merge(gnames, how=&#39;left&#39;, on=&#39;tid&#39;)

        # sort on log2fc
        test = test.reindex(test.log2fc.abs().sort_values(ascending=False).index)

        # assign the summary table to the parent object
        self.det_test = test
        self.det_test_groups = dataset_groups

        return test</code></pre>
</details>
</dd>
<dt id="swan_vis.swangraph.SwanGraph.find_es_genes"><code class="name flex">
<span>def <span class="ident">find_es_genes</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Finds all unique genes containing novel exon skipping events.
Requires that an annotation has been added to the SwanGraph.</p>
<pre><code>    Returns:

            es_genes (list of str): A list of gene ids from the SwanGraph with 
                    at least one novel exon skipping event
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def find_es_genes(self):
        &#34;&#34;&#34;
        Finds all unique genes containing novel exon skipping events. 
        Requires that an annotation has been added to the SwanGraph.

                Returns:

                        es_genes (list of str): A list of gene ids from the SwanGraph with 
                                at least one novel exon skipping event
        &#34;&#34;&#34;

        # get only novel edges
        if &#39;annotation&#39; not in self.edge_df.columns:
                raise Exception(&#39;Cannot find novel IR events without &#39;
                        &#39;annotation in SwanGraph.&#39;)

        edge_ids = self.edge_df.loc[ \
                (self.edge_df.annotation == False)&amp; \
                (self.edge_df.edge_type == &#39;intron&#39;), &#39;edge_id&#39;]
        print(&#39;Analyzing {} intronic edges for ES&#39;.format(len(edge_ids)))

        # get subset of transcripts that are novel to look for ir edges in
        nt_df = self.t_df.loc[self.t_df.annotation == False]

        # for each edge, see if the subgraph between the edge vertices 
        # contains an exonic edge
        es_genes = []
        for eid in edge_ids:
                sub_nodes = [i for i in range(eid[0]+1,eid[1])]
                sub_G = self.G.subgraph(sub_nodes)
                sub_edges = list(sub_G.edges())
                sub_edges = self.edge_df.loc[sub_edges]
                sub_edges = sub_edges.loc[sub_edges.edge_type == &#39;exon&#39;]

                if len(sub_edges.index) &gt; 0:

                        # transcripts that contain the exon-skipping edge
                        skip_t_df = nt_df[[eid in vertex_to_edge_path(x) \
                                for x in nt_df.path.values.tolist()]]

                        # circumvent the ISM bug
                        if len(skip_t_df) == 0:
                                continue

                        # does at least one of the skipped exons belong
                        # to the same gene as the skipping edge?
                        else:
                                # genes that contain the exon-skipping edge
                                skip_genes = skip_t_df.gid.values.tolist()
                                skip_g_df = self.t_df.loc[self.t_df.gid.isin(skip_genes)]

                                # check if the skipped edges are in one of the 
                                # exon-skipping genes (wow this is confusing)
                                for gid in skip_genes:
                                        if gid in es_genes: continue
                                        for skip_eid in sub_edges.index:
                                                temp_df = skip_g_df[[skip_eid in vertex_to_edge_path(x) \
                                                                for x in skip_g_df.path.values.tolist()]]
                                                if len(temp_df.index) &gt; 0:
                                                        es_genes.append(gid)

        print(&#39;Found {} novel es events from {} genes.&#39;.format(len(es_genes),
                len(list(set(es_genes)))))
        es_genes = list(set(es_genes))
        return es_genes</code></pre>
</details>
</dd>
<dt id="swan_vis.swangraph.SwanGraph.find_ir_genes"><code class="name flex">
<span>def <span class="ident">find_ir_genes</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Finds all unique genes containing novel intron retention events.
Requires that an annotation has been added to the SwanGraph.</p>
<pre><code>    Returns:

            ir_genes (list of str): A list of gene ids from the SwanGraph with 
                    at least one novel intron retention event
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def find_ir_genes(self):
        &#34;&#34;&#34;
        Finds all unique genes containing novel intron retention events. 
        Requires that an annotation has been added to the SwanGraph.

                Returns:

                        ir_genes (list of str): A list of gene ids from the SwanGraph with 
                                at least one novel intron retention event
        &#34;&#34;&#34;

        # get only novel edges
        if &#39;annotation&#39; not in self.edge_df.columns:
                raise Exception(&#39;Cannot find novel IR events without &#39;
                        &#39;annotation in SwanGraph.&#39;)

        edge_ids = self.edge_df.loc[ \
                (self.edge_df.annotation == False)&amp; \
                (self.edge_df.edge_type == &#39;exon&#39;), &#39;edge_id&#39;]
        print(&#39;Analyzing {} exonic edges for IR&#39;.format(len(edge_ids)))

        # get subset of transcripts that are novel to look for ir edges in
        nt_df = self.t_df.loc[self.t_df.annotation == False]
        
        # for each edge, see if the subgraph between the edge vertices 
        # contains an exonic edge  
        ir_genes = []
        for i, eid in enumerate(edge_ids):
                sub_nodes = [i for i in range(eid[0]+1,eid[1])]
                sub_G = self.G.subgraph(sub_nodes)
                sub_edges = list(sub_G.edges())
                sub_edges = self.edge_df.loc[sub_edges]
                sub_edges = sub_edges.loc[sub_edges.edge_type == &#39;intron&#39;]

                if len(sub_edges.index) &gt; 0:

                        # transcripts that contain the exon-skipping edge
                        cand_t_df = nt_df[[eid in vertex_to_edge_path(x) \
                                for x in nt_df.path.values.tolist()]]

                        # circumvent the ISM bug
                        if len(cand_t_df) == 0:
                                continue

                        # does at least one of the retained introns belong
                        # to the same gene as the retaining edge?
                        else:
                                # genes that contain the intron-retaining edge edge
                                cand_genes = cand_t_df.gid.values.tolist()
                                cand_g_df = self.t_df.loc[self.t_df.gid.isin(cand_genes)]

                                # check if the retained edges are in one of the 
                                # intron-retaining genes (wow this is confusing)
                                for gid in cand_genes:
                                        if gid in ir_genes: continue
                                        for cand_eid in sub_edges.index:
                                                temp_df = cand_g_df[[cand_eid in vertex_to_edge_path(x) \
                                                                for x in cand_g_df.path.values.tolist()]]
                                                if len(temp_df.index) &gt; 0:
                                                        ir_genes.append(gid)

        print(&#39;Found {} novel ir events from {} genes.&#39;.format(len(ir_genes), 
                len(list(set(ir_genes)))))
        ir_genes = list(set(ir_genes))
        return ir_genes</code></pre>
</details>
</dd>
<dt id="swan_vis.swangraph.SwanGraph.find_isoform_switching_genes"><code class="name flex">
<span>def <span class="ident">find_isoform_switching_genes</span></span>(<span>self, q=0.05, n_genes=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Finds isoform switching genes; genes that are not differentially
expressed but contain at least one transcript that is. Requires
that de_gene_test and de_transcript_test have been run.</p>
<h2 id="parameters">Parameters</h2>
<p>q (float): q-value threshold to declare a gene/transcript
as significant
Default: 0.05
n_genes (int): Number of results to return.
Default: None (returns all found significant)</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>genes (list</code> of <code>str): List</code> of <code>gene names that were categorized</code></dt>
<dd>as isoform switching</dd>
<dt><code>test (pandas DataFrame): Summary table</code> of <code>genes that were</code></dt>
<dd>categorized as isoform switching</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def find_isoform_switching_genes(self, q=0.05, n_genes=None):
        &#34;&#34;&#34; Finds isoform switching genes; genes that are not differentially
                expressed but contain at least one transcript that is. Requires
                that de_gene_test and de_transcript_test have been run.

                Parameters:

                        q (float): q-value threshold to declare a gene/transcript 
                                as significant
                                Default: 0.05
                        n_genes (int): Number of results to return. 
                                Default: None (returns all found significant)

                Returns:

                        genes (list of str): List of gene names that were categorized
                                as isoform switching
                        test (pandas DataFrame): Summary table of genes that were
                                categorized as isoform switching
        &#34;&#34;&#34;

        # make sure both deg and det tests have been run
        if self.det_test.empty or self.deg_test.empty:
                raise Exception(&#39;Cannot find isoform switches without test results. &#39;
                        &#39;Run de_gene_test and de_transcript_test first.&#39;)

        # subset for genes that aren&#39;t DE
        not_degs = self.deg_test.loc[self.deg_test.qval &gt; q]
        not_degs = not_degs.gid

        # subset for dets
        dets = self.det_test.loc[self.det_test.qval &lt;= q]

        # merge on gene id 
        switches = dets.merge(not_degs, how=&#39;inner&#39;, on=&#39;gid&#39;)

        # list and the df of the top de genes according qval threshold
        unique_genes = switches.gid.unique().tolist()
        if not n_genes:
                genes = unique_genes
        else:
                if n_genes &lt; len(unique_genes):
                        n_genes = len(unique_genes)
                switches = switches.loc[switches.gid.isin(unique_genes[:n_genes])]
                genes = unique_genes[:n_genes]
        return genes, switches</code></pre>
</details>
</dd>
<dt id="swan_vis.swangraph.SwanGraph.gen_report"><code class="name flex">
<span>def <span class="ident">gen_report</span></span>(<span>self, gids, prefix, datasets='all', dataset_groups=False, dataset_group_names=False, novelty=False, heatmap=False, tpm=False, include_qvals=False, q=0.05, include_unexpressed=False, indicate_dataset=False, indicate_novel=False, browser=False, order='expression')</span>
</code></dt>
<dd>
<div class="desc"><p>Generates a PDF report for a given gene or list of genes according
to the user's input.</p>
<pre><code>    Parameters:

            gids (str or list of str): Gene ids or names to generate
                    reports for
            prefix (str): Path and/or filename prefix to save PDF and
                    images used to generate the PDF

            datasets (list of str): Datasets to include in the report
                    Default: Include columns for all datasets
            dataset_groups (list of list of str): Datasets to average
                    together in the report and display as one column
                    Example: [['group1_1','group1_2'],['group2_1','group2_2']]
            dataset_group_names (list of str): Names to give each group 
                    given by dataset_groups. Must be the same length as 
                    dataset_groups
                    Example: ['group1', 'group2']
                    Default: Will assign numbers 1 through length(dataset_group)

            novelty (bool): Include a column to dipslay novelty type of
                    each transcript. Requires that a TALON GTF or DB has 
                    been used to load data in
                    Default: False

            heatmap (bool): Display expression values in a heatmap
                    format. Requires that abundance information has been 
                    added to the SwanGraph
                    Default: False
            tpm (bool): Display TPM value of each transcript/dataset 
                    combination, instead of presence/absence of each 
                    transcript. Requires that abundance information has
                    been added to the SwanGraph
                    Default:False

            include_qvals (bool): Display q-val of each transcript's 
                    differential expression and bold entries found to be
                    differentially expressed. Requires that de_transcript_test
                    has been run, and that abundance information has been
                    added to the SwanGraph
                    Default: False
            q (float): Q-value significance threshold to use when 
                    bolding transcripts if include_qvals = True.
                    Default: 0.05

            include_unexpressed (bool): Add transcript entries to report
                    that are not expressed in any input dataset.
                    Default: False

            indicate_dataset (str): Dataset name from SwanGraph to
                    highlight with outlined nodes and dashed edges
                    Incompatible with indicate_novel
                    Default: False (no highlighting)
            indicate_novel (bool): Highlight novel nodes and edges by 
                    outlining them and dashing them respectively
                    Incompatible with indicate_dataset
                    Default: False
            browser (bool): Plot transcript models in genome browser-
                    style format. Incompatible with indicate_dataset and
                    indicate_novel

            order (str): Order to display transcripts in the report.
                    Options are 
                            'tid': alphabetically by transcript ID
                            'expression': cumulative expression from high to low
                                    Requires that abundance information has been 
                                    added to the SwanGraph
                            'tss': genomic coordinate of transcription start site
                            'tes': genomic coordinate of transcription end site
                    Default: 'expression' if abundance information is present,
                                     'tid' if not
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def gen_report(self,
                           gids,
                           prefix,
                           datasets=&#39;all&#39;,
                           dataset_groups=False,
                           dataset_group_names=False,
                           novelty=False,
                           heatmap=False,
                           tpm=False,
                           include_qvals=False,
                           q=0.05,
                           include_unexpressed=False,
                           indicate_dataset=False, 
                           indicate_novel=False,
                           browser=False,
                           order=&#39;expression&#39;):
        &#34;&#34;&#34;
        Generates a PDF report for a given gene or list of genes according
        to the user&#39;s input.

                Parameters: 

                        gids (str or list of str): Gene ids or names to generate
                                reports for
                        prefix (str): Path and/or filename prefix to save PDF and
                                images used to generate the PDF

                        datasets (list of str): Datasets to include in the report
                                Default: Include columns for all datasets
                        dataset_groups (list of list of str): Datasets to average
                                together in the report and display as one column
                                Example: [[&#39;group1_1&#39;,&#39;group1_2&#39;],[&#39;group2_1&#39;,&#39;group2_2&#39;]]
                        dataset_group_names (list of str): Names to give each group 
                                given by dataset_groups. Must be the same length as 
                                dataset_groups
                                Example: [&#39;group1&#39;, &#39;group2&#39;]
                                Default: Will assign numbers 1 through length(dataset_group)

                        novelty (bool): Include a column to dipslay novelty type of
                                each transcript. Requires that a TALON GTF or DB has 
                                been used to load data in
                                Default: False

                        heatmap (bool): Display expression values in a heatmap
                                format. Requires that abundance information has been 
                                added to the SwanGraph
                                Default: False
                        tpm (bool): Display TPM value of each transcript/dataset 
                                combination, instead of presence/absence of each 
                                transcript. Requires that abundance information has
                                been added to the SwanGraph
                                Default:False

                        include_qvals (bool): Display q-val of each transcript&#39;s 
                                differential expression and bold entries found to be
                                differentially expressed. Requires that de_transcript_test
                                has been run, and that abundance information has been
                                added to the SwanGraph
                                Default: False
                        q (float): Q-value significance threshold to use when 
                                bolding transcripts if include_qvals = True.
                                Default: 0.05

                        include_unexpressed (bool): Add transcript entries to report
                                that are not expressed in any input dataset.
                                Default: False

                        indicate_dataset (str): Dataset name from SwanGraph to
                                highlight with outlined nodes and dashed edges
                                Incompatible with indicate_novel
                                Default: False (no highlighting)
                        indicate_novel (bool): Highlight novel nodes and edges by 
                                outlining them and dashing them respectively
                                Incompatible with indicate_dataset
                                Default: False
                        browser (bool): Plot transcript models in genome browser-
                                style format. Incompatible with indicate_dataset and
                                indicate_novel

                        order (str): Order to display transcripts in the report.
                                Options are 
                                        &#39;tid&#39;: alphabetically by transcript ID
                                        &#39;expression&#39;: cumulative expression from high to low
                                                Requires that abundance information has been 
                                                added to the SwanGraph
                                        &#39;tss&#39;: genomic coordinate of transcription start site
                                        &#39;tes&#39;: genomic coordinate of transcription end site
                                Default: &#39;expression&#39; if abundance information is present,
                                                 &#39;tid&#39; if not
        &#34;&#34;&#34;

        # check to see if input genes are in the graph
        if type(gids) != list:
                gids = [gids]
        for i, gid in enumerate(gids):
                if gid not in self.t_df.gid.tolist():
                        gid = self.get_gid_from_gname(gid)
                        gids[i] = gid
                self.check_gene(gid)

        # check to see if these plotting settings will play together
        self.check_plotting_args(indicate_dataset,
                indicate_novel, browser)

        # make sure all input datasets are present in graph
        if datasets == &#39;all&#39;:
                datasets = self.get_dataset_cols(include_annotation=False)
        elif not datasets:
                datasets = []
        else:
                self.check_datasets(datasets)

        # if we have dataset groupings make sure that they are a subset
        # of the datasets already requested
        if dataset_groups:
                if not datasets: 
                        raise Exception(&#39;Cannot group datasets as none were requested.&#39;)
                else:
                        all_dgs = [j for i in dataset_groups for j in i]
                        self.check_datasets(all_dgs)

                        subsumed_datasets = [True if i in datasets else False for i in all_dgs]
                        if False in subsumed_datasets:
                                bad_dataset = all_dgs[subsumed_datasets.index(False)]
                                raise Exception(&#34;Grouping dataset {} not present in &#34; 
                                        &#34;datasets {}.&#34;.format(bad_dataset, datasets))

        # if we&#39;ve asked for novelty first check to make sure it&#39;s there
        if novelty:
                if not self.has_novelty():
                        raise Exception(&#39;No novelty information present in the graph. &#39;
                                &#39;Add it or do not use the &#34;novelty&#34; report option.&#39;)

        # check to make sure abundance data is there for the
        # query columns, if user is asking
        if tpm or heatmap:
                self.check_abundances(datasets)

        # order transcripts by user&#39;s preferences 
        if order == &#39;expression&#39; and not self.get_count_cols():
                order = &#39;tid&#39;
        self.order_transcripts(order)

        # subset t_df based on relevant tids and expression requirements
        t_df = self.t_df[self.t_df.gid.isin(gids)].copy(deep=True)

        # make sure de has been run if needed
        if include_qvals:
                self.check_de(&#39;transcript&#39;)
                de_df = self.det_test.copy(deep=True)
                t_df = reset_dupe_index(t_df, &#39;tid&#39;)
                t_df[&#39;significant&#39;] = False
                t_df = t_df.merge(de_df[[&#39;tid&#39;, &#39;qval&#39;]], how=&#39;left&#39;, on=&#39;tid&#39;)
                t_df[&#39;significant&#39;] = t_df.qval &lt;= q
                t_df = set_dupe_index(t_df, &#39;tid&#39;)

        # if user doesn&#39;t care about datasets, just show all transcripts
        if not datasets:
                include_unexpressed = True

        # user only wants transcript isoforms that appear in their data
        if not include_unexpressed:
                counts_cols = self.get_count_cols(datasets)
                t_df = t_df[t_df[counts_cols].sum(axis=1)&gt;0]

        # if we&#39;re grouping things switch up the datasets 
        # and how t_df is formatted
        if dataset_groups:

                # no grouped dataset names were given - generate names
                if not dataset_group_names:
                        print(&#39;No group names given. Will just use Group_#.&#39;)
                        dataset_group_names = [&#39;Group_{}&#39;.format(i) for i in range(len(dataset_groups))]

                # check if we have the right number of group names
                if len(dataset_groups) != len(dataset_group_names):
                        print(&#39;Not enough group names given. Will just use Group_#.&#39;)
                        dataset_group_names = [&#39;Group_{}&#39;.format(i) for i in range(len(dataset_groups))]

                for i in range(len(dataset_groups)):
                        group = dataset_groups[i]
                        group_name = dataset_group_names[i]

                        # true or false
                        if not heatmap and not tpm:
                                t_df[group_name] = t_df[group].any(axis=1)
                        # tpm values
                        else:
                                group_name += &#39;_counts&#39;
                                count_group_cols = self.get_count_cols(group)
                                t_df[group_name] = t_df[count_group_cols].mean(axis=1)
                datasets = dataset_group_names
                # report_cols = dataset_group_names

        # determine report type
        if heatmap:
                data_type = &#39;heatmap&#39;
        elif tpm:
                data_type = &#39;tpm&#39;
        else:
                data_type = None

        # determine report type
        if not browser:
                report_type = &#39;swan&#39;
        else:
                report_type = &#39;browser&#39;

        # parallel
        # launch report jobs on different threads
        with Pool() as pool:
                pool.starmap(_create_gene_report, zip(gids, repeat(self), repeat(t_df),
                        repeat(datasets), repeat(data_type), repeat(prefix), repeat(indicate_dataset),
                        repeat(indicate_novel), repeat(browser), repeat(report_type),
                        repeat(novelty), repeat(heatmap), repeat(include_qvals)))</code></pre>
</details>
</dd>
<dt id="swan_vis.swangraph.SwanGraph.get_de_and_not_de_transcripts"><code class="name flex">
<span>def <span class="ident">get_de_and_not_de_transcripts</span></span>(<span>self, dataset_groups)</span>
</code></dt>
<dt id="swan_vis.swangraph.SwanGraph.get_de_genes"><code class="name flex">
<span>def <span class="ident">get_de_genes</span></span>(<span>self, q=0.05, n_genes=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Subsets the differential gene expression test summary table based
on a q-value cutoff. Requires that de_gene_test has already been
run.</p>
<pre><code>    Parameters:

            q (float): q-value threshold to declare a gene as significant
                    Default: 0.05
            n_genes (int): Number of results to return. 
                    Default: None (returns all found significant)

    Returns:

            genes (list of str): List of gene names that pass the 
                    significance threshold
            test (pandas DataFrame): Summary table of genes that pass the
                    significance threshold
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_de_genes(self, q=0.05, n_genes=None):
        &#34;&#34;&#34;
        Subsets the differential gene expression test summary table based
        on a q-value cutoff. Requires that de_gene_test has already been
        run.

                Parameters:

                        q (float): q-value threshold to declare a gene as significant
                                Default: 0.05
                        n_genes (int): Number of results to return. 
                                Default: None (returns all found significant)

                Returns:

                        genes (list of str): List of gene names that pass the 
                                significance threshold
                        test (pandas DataFrame): Summary table of genes that pass the
                                significance threshold
        &#34;&#34;&#34;

        # make sure we have the result of a deg test first!
        if self.deg_test.empty:
                raise Exception(&#39;Cannot find DE genes without test results. &#39;
                        &#39;Run de_gene_test first.&#39;)

        # subset on q value 
        test = self.deg_test.loc[self.deg_test.qval &lt;= q].copy(deep=True)

        # list and the df of the top de genes according qval threshold
        if not n_genes:
                genes = test.gname.tolist()
        else:
                if n_genes &lt; len(test.index):
                        n_genes = len(test.index)
                        test = test.head(n_genes)
                        genes = test.gname.tolist()
        return genes, test</code></pre>
</details>
</dd>
<dt id="swan_vis.swangraph.SwanGraph.get_de_transcripts"><code class="name flex">
<span>def <span class="ident">get_de_transcripts</span></span>(<span>self, q=0.05, n_transcripts=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Subsets the differential transcript expression test summary table based
on a q-value cutoff. Requires that de_transcript_test has already been
run.</p>
<pre><code>    Parameters:

            q (float): q-value threshold to declare a transcript as significant
                    Default: 0.05
            n_transcripts (int): Number of results to return. 
                    Default: None (returns all found significant)

    Returns:

            tids (list of str): List of transcript ids that pass the 
                    significance threshold
            test (pandas DataFrame): Summary table of transcripts that pass
                    the significance threshold
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_de_transcripts(self, q=0.05, n_transcripts=None):
        &#34;&#34;&#34;
        Subsets the differential transcript expression test summary table based
        on a q-value cutoff. Requires that de_transcript_test has already been
        run.

                Parameters:

                        q (float): q-value threshold to declare a transcript as significant
                                Default: 0.05
                        n_transcripts (int): Number of results to return. 
                                Default: None (returns all found significant)

                Returns:

                        tids (list of str): List of transcript ids that pass the 
                                significance threshold
                        test (pandas DataFrame): Summary table of transcripts that pass
                                the significance threshold
        &#34;&#34;&#34;

        # make sure we have the result of a deg test first!
        if self.det_test.empty:
                raise Exception(&#39;Cannot find DE transcripts without test results. &#39;
                        &#39;Run de_transcript_test first.&#39;)

        # subset on q value 
        test = self.det_test.loc[self.det_test.qval &lt;= q].copy(deep=True)

        # list and the df of the top de genes according qval threshold
        if not n_transcripts:
                tids = test.tid.tolist()
        else:
                if n_transcripts &lt; len(test.index):
                        n_transcripts = len(test.index)
                n_transcripts = test.head(n_transcripts)
                tids = test.transcript.tolist()
        return tids, test</code></pre>
</details>
</dd>
<dt id="swan_vis.swangraph.SwanGraph.plot_each_transcript"><code class="name flex">
<span>def <span class="ident">plot_each_transcript</span></span>(<span>self, tids, prefix, indicate_dataset=False, indicate_novel=False, browser=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Plot each input transcript and automatically save figures</p>
<pre><code>    Parameters:

            tids (list of str): List of transcript ids to plot
            prefix (str): Path and file prefix to automatically save
                    the plotted figures
            indicate_dataset (str): Dataset name from SwanGraph to
                    highlight with outlined nodes and dashed edges
                    Incompatible with indicate_novel
                    Default: False (no highlighting)
            indicate_novel (bool): Highlight novel nodes and edges by 
                    outlining them and dashing them respectively
                    Incompatible with indicate_dataset
                    Default: False
            browser (bool): Plot transcript models in genome browser-
                    style format. Incompatible with indicate_dataset and
                    indicate_novel
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_each_transcript(self, tids, prefix,
                                        indicate_dataset=False,
                                        indicate_novel=False,
                                        browser=False):
        &#34;&#34;&#34;
        Plot each input transcript and automatically save figures

                Parameters:

                        tids (list of str): List of transcript ids to plot
                        prefix (str): Path and file prefix to automatically save
                                the plotted figures
                        indicate_dataset (str): Dataset name from SwanGraph to
                                highlight with outlined nodes and dashed edges
                                Incompatible with indicate_novel
                                Default: False (no highlighting)
                        indicate_novel (bool): Highlight novel nodes and edges by 
                                outlining them and dashing them respectively
                                Incompatible with indicate_dataset
                                Default: False
                        browser (bool): Plot transcript models in genome browser-
                                style format. Incompatible with indicate_dataset and
                                indicate_novel
        &#34;&#34;&#34;

        self.check_plotting_args(indicate_dataset, indicate_novel, browser)

        # loop through each transcript in the SwanGraph object
        for tid in tids:
                self.check_transcript(tid)

        for tid in tids:
                self.pg.init_plot_settings(self, tid=tid,
                        indicate_dataset=indicate_dataset,
                        indicate_novel=indicate_novel,
                        browser=browser)
                fname = create_fname(prefix,
                                                         indicate_dataset,
                                                         indicate_novel,
                                                         browser,
                                                         ftype=&#39;path&#39;,
                                                         tid=tid)
                self.pg.plot_graph()
                print(&#39;Saving transcript path graph for {} as {}&#39;.format(tid, fname))
                save_fig(fname)</code></pre>
</details>
</dd>
<dt id="swan_vis.swangraph.SwanGraph.plot_each_transcript_in_gene"><code class="name flex">
<span>def <span class="ident">plot_each_transcript_in_gene</span></span>(<span>self, gid, prefix, indicate_dataset=False, indicate_novel=False, browser=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Plot each transcript in a given gene and automatically save figures</p>
<pre><code>    Parameters:

            gid (str): Gene id or gene name to plot transcripts from
            prefix (str): Path and file prefix to automatically save
                    the plotted figures
            indicate_dataset (str): Dataset name from SwanGraph to
                    highlight with outlined nodes and dashed edges
                    Incompatible with indicate_novel
                    Default: False (no highlighting)
            indicate_novel (bool): Highlight novel nodes and edges by 
                    outlining them and dashing them respectively
                    Incompatible with indicate_dataset
                    Default: False
            browser (bool): Plot transcript models in genome browser-
                    style format. Incompatible with indicate_dataset and
                    indicate_novel
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_each_transcript_in_gene(self, gid, prefix,
                                                 indicate_dataset=False,
                                                 indicate_novel=False,
                                                 browser=False):
        &#34;&#34;&#34;
        Plot each transcript in a given gene and automatically save figures

                Parameters:

                        gid (str): Gene id or gene name to plot transcripts from
                        prefix (str): Path and file prefix to automatically save
                                the plotted figures
                        indicate_dataset (str): Dataset name from SwanGraph to
                                highlight with outlined nodes and dashed edges
                                Incompatible with indicate_novel
                                Default: False (no highlighting)
                        indicate_novel (bool): Highlight novel nodes and edges by 
                                outlining them and dashing them respectively
                                Incompatible with indicate_dataset
                                Default: False
                        browser (bool): Plot transcript models in genome browser-
                                style format. Incompatible with indicate_dataset and
                                indicate_novel
        &#34;&#34;&#34;

        if gid not in self.t_df.gid.tolist():
                gid = self.get_gid_from_gname(gid)
        self.check_gene(gid)

        self.check_plotting_args(indicate_dataset, indicate_novel, browser)

        # loop through each transcript in the SwanGraph object
        tids = self.t_df.loc[self.t_df.gid == gid, &#39;tid&#39;].tolist()
        print()
        print(&#39;Plotting {} transcripts for {}&#39;.format(len(tids), gid))
        for tid in tids:
                self.pg.init_plot_settings(self, tid=tid,
                        indicate_dataset=indicate_dataset,
                        indicate_novel=indicate_novel,
                        browser=browser)
                fname = create_fname(prefix,
                                                         indicate_dataset,
                                                         indicate_novel,
                                                         browser,
                                                         ftype=&#39;path&#39;,
                                                         tid=tid)
                self.pg.plot_graph()
                print(&#39;Saving transcript path graph for {} as {}&#39;.format(tid, fname))
                save_fig(fname)</code></pre>
</details>
</dd>
<dt id="swan_vis.swangraph.SwanGraph.plot_graph"><code class="name flex">
<span>def <span class="ident">plot_graph</span></span>(<span>self, gid, indicate_dataset=False, indicate_novel=False, prefix=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Plots a gene summary SwanGraph for an input gene.
Does not automatically save the figure by default!</p>
<pre><code>    Parameters:

            gid (str): Gene ID to plot for (can also be gene name but 
                    we've seen non-unique gene names so use at your own risk!)
            indicate_dataset (str): Dataset name from SwanGraph to
                    highlight with outlined nodes and dashed edges
                    Incompatible with indicate_novel
                    Default: False (no highlighting)
            indicate_novel (bool): Highlight novel nodes and edges by 
                    outlining them and dashing them respectively
                    Incompatible with indicate_dataset
                    Default: False
            prefix (str): Path and file prefix to automatically save
                    the plotted figure
                    Default: None, won't automatically save
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_graph(self, gid,
                           indicate_dataset=False,
                           indicate_novel=False,
                           prefix=None):
        &#34;&#34;&#34;
        Plots a gene summary SwanGraph for an input gene.
        Does not automatically save the figure by default!

                Parameters:

                        gid (str): Gene ID to plot for (can also be gene name but 
                                we&#39;ve seen non-unique gene names so use at your own risk!)
                        indicate_dataset (str): Dataset name from SwanGraph to
                                highlight with outlined nodes and dashed edges
                                Incompatible with indicate_novel
                                Default: False (no highlighting)
                        indicate_novel (bool): Highlight novel nodes and edges by 
                                outlining them and dashing them respectively
                                Incompatible with indicate_dataset
                                Default: False
                        prefix (str): Path and file prefix to automatically save
                                the plotted figure
                                Default: None, won&#39;t automatically save 
        &#34;&#34;&#34;

        if gid not in self.t_df.gid.tolist():
                gid = self.get_gid_from_gname(gid)

        self.check_plotting_args(indicate_dataset, indicate_novel)
        self.check_gene(gid)

        # reinit PlottedGraph object and plot
        self.pg.init_plot_settings(self, gid=gid,
                indicate_dataset=indicate_dataset, 
                indicate_novel=indicate_novel)
        self.pg.plot_graph()

        # if the user has provided a place to save
        if prefix:
                browser = False # can&#39;t plot browser for entire gene
                fname = create_fname(prefix,
                                                        indicate_dataset,
                                                        indicate_novel,
                                                        browser,
                                                        ftype=&#39;summary&#39;,
                                                        gid=gid)
                self.pg.plot_graph()
                print(&#39;Saving summary graph for {} as {}&#39;.format(gid, fname))
                save_fig(fname)</code></pre>
</details>
</dd>
<dt id="swan_vis.swangraph.SwanGraph.plot_transcript_path"><code class="name flex">
<span>def <span class="ident">plot_transcript_path</span></span>(<span>self, tid, indicate_dataset=False, indicate_novel=False, browser=False, prefix=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Plots a path of a single transcript isoform through a gene summary
SwanGraph.</p>
<pre><code>    Parameters:

            tid (str): Transcript id of transcript to plot
            indicate_dataset (str): Dataset name from SwanGraph to
                    highlight with outlined nodes and dashed edges
                    Incompatible with indicate_novel
                    Default: False (no highlighting)
            indicate_novel (bool): Highlight novel nodes and edges by 
                    outlining them and dashing them respectively
                    Incompatible with indicate_dataset
                    Default: False
            browser (bool): Plot transcript models in genome browser-
                    style format. Incompatible with indicate_dataset and
                    indicate_novel
            prefix (str): Path and file prefix to automatically save
                    the plotted figure
                    Default: None, won't automatically save
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_transcript_path(self, tid,
                                                 indicate_dataset=False,
                                                 indicate_novel=False,
                                                 browser=False,
                                                 prefix=None):
        &#34;&#34;&#34;
        Plots a path of a single transcript isoform through a gene summary 
        SwanGraph.

                Parameters:

                        tid (str): Transcript id of transcript to plot
                        indicate_dataset (str): Dataset name from SwanGraph to
                                highlight with outlined nodes and dashed edges
                                Incompatible with indicate_novel
                                Default: False (no highlighting)
                        indicate_novel (bool): Highlight novel nodes and edges by 
                                outlining them and dashing them respectively
                                Incompatible with indicate_dataset
                                Default: False
                        browser (bool): Plot transcript models in genome browser-
                                style format. Incompatible with indicate_dataset and
                                indicate_novel
                        prefix (str): Path and file prefix to automatically save
                                the plotted figure
                                Default: None, won&#39;t automatically save
        &#34;&#34;&#34;

        self.check_plotting_args(indicate_dataset, indicate_novel, browser)
        self.check_transcript(tid)

        # reinit PlottedGraph object and plot
        self.pg.init_plot_settings(self, tid=tid, 
                indicate_dataset=indicate_dataset,
                indicate_novel=indicate_novel,
                browser=browser)
        self.pg.plot_graph()

        # if the user has provided a place to save
        if prefix:
                fname = create_fname(prefix,
                                                        indicate_dataset,
                                                        indicate_novel,
                                                        browser,
                                                        ftype=&#39;path&#39;,
                                                        tid=tid)
                self.pg.plot_graph()
                print(&#39;Saving transcript path graph for {} as {}&#39;.format(tid, fname))
                save_fig(fname)</code></pre>
</details>
</dd>
<dt id="swan_vis.swangraph.SwanGraph.save_graph"><code class="name flex">
<span>def <span class="ident">save_graph</span></span>(<span>self, prefix)</span>
</code></dt>
<dd>
<div class="desc"><p>Saves the current SwanGraph in pickle format with the .p extension</p>
<pre><code>    Parameters:

            prefix (str): Path and filename prefix. Resulting file will 
                    be saved as prefix.p
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save_graph(self, prefix):
        &#34;&#34;&#34;
        Saves the current SwanGraph in pickle format with the .p extension

                Parameters: 

                        prefix (str): Path and filename prefix. Resulting file will 
                                be saved as prefix.p
        &#34;&#34;&#34;
        print(&#39;Saving graph as &#39;+prefix+&#39;.p&#39;)
        picklefile = open(prefix+&#39;.p&#39;, &#39;wb&#39;)
        pickle.dump(self, picklefile)
        picklefile.close()</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<li><h3>Classes</h3>
<ul>
<li>
<h4><code><a title="swan_vis.swangraph.SwanGraph" href="#swan_vis.swangraph.SwanGraph">SwanGraph</a></code></h4>
<ul class="">
<li><code><a title="swan_vis.swangraph.SwanGraph.add_abundance" href="#swan_vis.swangraph.SwanGraph.add_abundance">add_abundance</a></code></li>
<li><code><a title="swan_vis.swangraph.SwanGraph.add_annotation" href="#swan_vis.swangraph.SwanGraph.add_annotation">add_annotation</a></code></li>
<li><code><a title="swan_vis.swangraph.SwanGraph.add_dataset" href="#swan_vis.swangraph.SwanGraph.add_dataset">add_dataset</a></code></li>
<li><code><a title="swan_vis.swangraph.SwanGraph.de_gene_test" href="#swan_vis.swangraph.SwanGraph.de_gene_test">de_gene_test</a></code></li>
<li><code><a title="swan_vis.swangraph.SwanGraph.de_transcript_test" href="#swan_vis.swangraph.SwanGraph.de_transcript_test">de_transcript_test</a></code></li>
<li><code><a title="swan_vis.swangraph.SwanGraph.find_es_genes" href="#swan_vis.swangraph.SwanGraph.find_es_genes">find_es_genes</a></code></li>
<li><code><a title="swan_vis.swangraph.SwanGraph.find_ir_genes" href="#swan_vis.swangraph.SwanGraph.find_ir_genes">find_ir_genes</a></code></li>
<li><code><a title="swan_vis.swangraph.SwanGraph.find_isoform_switching_genes" href="#swan_vis.swangraph.SwanGraph.find_isoform_switching_genes">find_isoform_switching_genes</a></code></li>
<li><code><a title="swan_vis.swangraph.SwanGraph.gen_report" href="#swan_vis.swangraph.SwanGraph.gen_report">gen_report</a></code></li>
<li><code><a title="swan_vis.swangraph.SwanGraph.get_de_genes" href="#swan_vis.swangraph.SwanGraph.get_de_genes">get_de_genes</a></code></li>
<li><code><a title="swan_vis.swangraph.SwanGraph.get_de_transcripts" href="#swan_vis.swangraph.SwanGraph.get_de_transcripts">get_de_transcripts</a></code></li>
<li><code><a title="swan_vis.swangraph.SwanGraph.plot_each_transcript" href="#swan_vis.swangraph.SwanGraph.plot_each_transcript">plot_each_transcript</a></code></li>
<li><code><a title="swan_vis.swangraph.SwanGraph.plot_each_transcript_in_gene" href="#swan_vis.swangraph.SwanGraph.plot_each_transcript_in_gene">plot_each_transcript_in_gene</a></code></li>
<li><code><a title="swan_vis.swangraph.SwanGraph.plot_graph" href="#swan_vis.swangraph.SwanGraph.plot_graph">plot_graph</a></code></li>
<li><code><a title="swan_vis.swangraph.SwanGraph.plot_transcript_path" href="#swan_vis.swangraph.SwanGraph.plot_transcript_path">plot_transcript_path</a></code></li>
<li><code><a title="swan_vis.swangraph.SwanGraph.save_graph" href="#swan_vis.swangraph.SwanGraph.save_graph">save_graph</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.8.1</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>